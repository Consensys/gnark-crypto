//go:build !purego

// Code generated by gnark-crypto/generator. DO NOT EDIT.
// Refer to the generator for more documentation.

#include "textflag.h"
#include "funcdata.h"
#include "go_asm.h"

TEXT ·permutation24_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R14
	MOVQ         roundKeys+24(FP), R13
	VMOVDQU32    0(R14), Z2
	VMOVDQU32    64(R14), Y3
	MOVQ         ·diag24+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VMOVDQU32    64(CX), Y20
	VPSRLQ       $32, Z18, Z19
	VPSRLQ       $32, Y20, Y21

#define ADD(in0, in1, in2, in3, in4) \
	VPADDD  in0, in1, in4 \
	VPSUBD  in2, in4, in3 \
	VPMINUD in4, in3, in4 \

#define MAT_MUL_M4(in0, in1, in2, in3, in4, in5) \
	VPSHUFD $0x000000000000004e, in0, in1 \
	ADD(in1, in0, in4, in5, in1)          \
	VPSHUFD $0x00000000000000b1, in1, in2 \
	ADD(in1, in2, in4, in5, in1)          \
	VPSHUFD $0x0000000000000039, in0, in3 \
	VPSLLD  $1, in3, in3                  \
	VPSUBD  in4, in3, in5                 \
	VPMINUD in3, in5, in3                 \
	ADD(in0, in1, in4, in5, in0)          \
	ADD(in0, in3, in4, in5, in0)          \

#define MAT_MUL_EXTERNAL() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	MAT_MUL_M4(Y3, Y6, Y7, Y8, Y0, Y11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	ADD(Y16, Y3, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Y3, Y16, Y0, Y9, Y3)            \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define MULD(in0, in1, in2, in3, in4, in5, in6, in7, in8, in9, in10) \
	VPSRLQ    $32, in0, in2  \
	VPSRLQ    $32, in1, in3  \
	VPMULUDQ  in0, in1, in4  \
	VPMULUDQ  in2, in3, in5  \
	VPMULUDQ  in4, in9, in6  \
	VPMULUDQ  in5, in9, in7  \
	VPMULUDQ  in6, in8, in6  \
	VPADDQ    in4, in6, in4  \
	VPMULUDQ  in7, in8, in7  \
	VPADDQ    in5, in7, in10 \
	VMOVSHDUP in4, K3, in10  \

#define REDUCE1Q(in0, in1, in2) \
	VPSUBD  in0, in1, in2 \
	VPMINUD in1, in2, in1 \

#define SBOX_FULL() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \
	MULD(Y3, Y3, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y7) \
	MULD(Y3, Y7, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y3) \
	REDUCE1Q(Y0, Y3, Y15)                                \

#define SBOX_PARTIAL() \
	VPMULUDQ X5, X5, X6   \
	VPMULUDQ X6, X1, X14  \
	VPMULUDQ X14, X0, X14 \
	VPADDQ   X6, X14, X6  \
	VPSRLQ   $32, X6, X8  \
	VPMULUDQ X5, X8, X6   \
	VPMULUDQ X6, X1, X14  \
	VPMULUDQ X14, X0, X14 \
	VPADDQ   X6, X14, X6  \
	VPSRLQ   $32, X6, X5  \
	VPSUBD   X0, X5, X14  \
	VPMINUD  X5, X14, X5  \

#define SUM_STATE() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y3, Y0, Y11, Y16)                  \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND() \
	VMOVDQU32 0(BX), Z4      \
	VMOVDQU32 64(BX), Y5     \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	ADD(Y3, Y5, Y0, Y8, Y3)  \
	SBOX_FULL()              \
	MAT_MUL_EXTERNAL()       \

	MAT_MUL_EXTERNAL()
	MOVQ 0(R13), BX
	FULL_ROUND()
	MOVQ 24(R13), BX
	FULL_ROUND()
	MOVQ 48(R13), BX
	FULL_ROUND()

	// loop over the partial rounds
	MOVQ $0x0000000000000015, SI // nb partial rounds --> 21
	MOVQ R13, DI
	ADDQ $0x0000000000000048, DI

loop_1:
	TESTQ     SI, SI
	JEQ       done_2
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Y3, Y12
	VPMULUDQ  Y3, Y20, Y6
	VPMULUDQ  Y12, Y21, Y7
	VPMULUDQ  Y6, Y1, Y14
	VPMULUDQ  Y7, Y1, Y15
	VPMULUDQ  Y14, Y0, Y14
	VPADDQ    Y6, Y14, Y6
	VPMULUDQ  Y15, Y0, Y15
	VPADDQ    Y7, Y15, Y9
	VMOVSHDUP Y6, K3, Y9
	VPSUBD    Y0, Y9, Y11
	VPMINUD   Y9, Y11, Y9
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADD(Y9, Y16, Y0, Y5, Y3)
	ADDQ      $24, DI
	JMP       loop_1

done_2:
	MOVQ      576(R13), BX
	FULL_ROUND()
	MOVQ      600(R13), BX
	FULL_ROUND()
	MOVQ      624(R13), BX
	FULL_ROUND()
	VMOVDQU32 Z2, 0(R14)
	VMOVDQU32 Y3, 64(R14)
	RET

TEXT ·permutation16x24_avx512(SB), NOSPLIT, $0-32
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z24
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z25
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         input+0(FP), R14
	MOVQ         roundKeys+8(FP), R13
	VMOVDQU32    0(R14), Z0
	VMOVDQU32    64(R14), Z1
	VMOVDQU32    128(R14), Z2
	VMOVDQU32    192(R14), Z3
	VMOVDQU32    256(R14), Z4
	VMOVDQU32    320(R14), Z5
	VMOVDQU32    384(R14), Z6
	VMOVDQU32    448(R14), Z7
	VMOVDQU32    512(R14), Z8
	VMOVDQU32    576(R14), Z9
	VMOVDQU32    640(R14), Z10
	VMOVDQU32    704(R14), Z11
	VMOVDQU32    768(R14), Z12
	VMOVDQU32    832(R14), Z13
	VMOVDQU32    896(R14), Z14
	VMOVDQU32    960(R14), Z15
	VMOVDQU32    1024(R14), Z16
	VMOVDQU32    1088(R14), Z17
	VMOVDQU32    1152(R14), Z18
	VMOVDQU32    1216(R14), Z19
	VMOVDQU32    1280(R14), Z20
	VMOVDQU32    1344(R14), Z21
	VMOVDQU32    1408(R14), Z22
	VMOVDQU32    1472(R14), Z23
	ADD(Z0, Z1, Z24, Z31, Z26)
	ADD(Z2, Z3, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z1, Z24, Z31, Z29)
	ADD(Z28, Z3, Z24, Z31, Z30)

#define DOUBLE(in0, in1, in2, in3) \
	VPSLLD  $1, in0, in3  \
	VPSUBD  in1, in3, in2 \
	VPMINUD in3, in2, in3 \

	DOUBLE(Z0, Z24, Z31, Z3)
	ADD(Z3, Z30, Z24, Z31, Z3)
	DOUBLE(Z2, Z24, Z31, Z1)
	ADD(Z1, Z29, Z24, Z31, Z1)
	ADD(Z26, Z29, Z24, Z31, Z0)
	ADD(Z27, Z30, Z24, Z31, Z2)
	ADD(Z4, Z5, Z24, Z31, Z26)
	ADD(Z6, Z7, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z5, Z24, Z31, Z29)
	ADD(Z28, Z7, Z24, Z31, Z30)
	DOUBLE(Z4, Z24, Z31, Z7)
	ADD(Z7, Z30, Z24, Z31, Z7)
	DOUBLE(Z6, Z24, Z31, Z5)
	ADD(Z5, Z29, Z24, Z31, Z5)
	ADD(Z26, Z29, Z24, Z31, Z4)
	ADD(Z27, Z30, Z24, Z31, Z6)
	ADD(Z8, Z9, Z24, Z31, Z26)
	ADD(Z10, Z11, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z9, Z24, Z31, Z29)
	ADD(Z28, Z11, Z24, Z31, Z30)
	DOUBLE(Z8, Z24, Z31, Z11)
	ADD(Z11, Z30, Z24, Z31, Z11)
	DOUBLE(Z10, Z24, Z31, Z9)
	ADD(Z9, Z29, Z24, Z31, Z9)
	ADD(Z26, Z29, Z24, Z31, Z8)
	ADD(Z27, Z30, Z24, Z31, Z10)
	ADD(Z12, Z13, Z24, Z31, Z26)
	ADD(Z14, Z15, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z13, Z24, Z31, Z29)
	ADD(Z28, Z15, Z24, Z31, Z30)
	DOUBLE(Z12, Z24, Z31, Z15)
	ADD(Z15, Z30, Z24, Z31, Z15)
	DOUBLE(Z14, Z24, Z31, Z13)
	ADD(Z13, Z29, Z24, Z31, Z13)
	ADD(Z26, Z29, Z24, Z31, Z12)
	ADD(Z27, Z30, Z24, Z31, Z14)
	ADD(Z16, Z17, Z24, Z31, Z26)
	ADD(Z18, Z19, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z17, Z24, Z31, Z29)
	ADD(Z28, Z19, Z24, Z31, Z30)
	DOUBLE(Z16, Z24, Z31, Z19)
	ADD(Z19, Z30, Z24, Z31, Z19)
	DOUBLE(Z18, Z24, Z31, Z17)
	ADD(Z17, Z29, Z24, Z31, Z17)
	ADD(Z26, Z29, Z24, Z31, Z16)
	ADD(Z27, Z30, Z24, Z31, Z18)
	ADD(Z20, Z21, Z24, Z31, Z26)
	ADD(Z22, Z23, Z24, Z31, Z27)
	ADD(Z26, Z27, Z24, Z31, Z28)
	ADD(Z28, Z21, Z24, Z31, Z29)
	ADD(Z28, Z23, Z24, Z31, Z30)
	DOUBLE(Z20, Z24, Z31, Z23)
	ADD(Z23, Z30, Z24, Z31, Z23)
	DOUBLE(Z22, Z24, Z31, Z21)
	ADD(Z21, Z29, Z24, Z31, Z21)
	ADD(Z26, Z29, Z24, Z31, Z20)
	ADD(Z27, Z30, Z24, Z31, Z22)
	ADD(Z0, Z4, Z24, Z29, Z31)
	ADD(Z1, Z5, Z24, Z30, Z26)
	ADD(Z2, Z6, Z24, Z29, Z27)
	ADD(Z3, Z7, Z24, Z30, Z28)
	ADD(Z8, Z31, Z24, Z29, Z31)
	ADD(Z9, Z26, Z24, Z30, Z26)
	ADD(Z10, Z27, Z24, Z29, Z27)
	ADD(Z11, Z28, Z24, Z30, Z28)
	ADD(Z12, Z31, Z24, Z29, Z31)
	ADD(Z13, Z26, Z24, Z30, Z26)
	ADD(Z14, Z27, Z24, Z29, Z27)
	ADD(Z15, Z28, Z24, Z30, Z28)
	ADD(Z16, Z31, Z24, Z29, Z31)
	ADD(Z17, Z26, Z24, Z30, Z26)
	ADD(Z18, Z27, Z24, Z29, Z27)
	ADD(Z19, Z28, Z24, Z30, Z28)
	ADD(Z20, Z31, Z24, Z29, Z31)
	ADD(Z21, Z26, Z24, Z30, Z26)
	ADD(Z22, Z27, Z24, Z29, Z27)
	ADD(Z23, Z28, Z24, Z30, Z28)
	ADD(Z0, Z31, Z24, Z29, Z0)
	ADD(Z1, Z26, Z24, Z30, Z1)
	ADD(Z2, Z27, Z24, Z29, Z2)
	ADD(Z3, Z28, Z24, Z30, Z3)
	ADD(Z4, Z31, Z24, Z29, Z4)
	ADD(Z5, Z26, Z24, Z30, Z5)
	ADD(Z6, Z27, Z24, Z29, Z6)
	ADD(Z7, Z28, Z24, Z30, Z7)
	ADD(Z8, Z31, Z24, Z29, Z8)
	ADD(Z9, Z26, Z24, Z30, Z9)
	ADD(Z10, Z27, Z24, Z29, Z10)
	ADD(Z11, Z28, Z24, Z30, Z11)
	ADD(Z12, Z31, Z24, Z29, Z12)
	ADD(Z13, Z26, Z24, Z30, Z13)
	ADD(Z14, Z27, Z24, Z29, Z14)
	ADD(Z15, Z28, Z24, Z30, Z15)
	ADD(Z16, Z31, Z24, Z29, Z16)
	ADD(Z17, Z26, Z24, Z30, Z17)
	ADD(Z18, Z27, Z24, Z29, Z18)
	ADD(Z19, Z28, Z24, Z30, Z19)
	ADD(Z20, Z31, Z24, Z29, Z20)
	ADD(Z21, Z26, Z24, Z30, Z21)
	ADD(Z22, Z27, Z24, Z29, Z22)
	ADD(Z23, Z28, Z24, Z30, Z23)

	// loop over the first full rounds
	MOVQ $0x0000000000000003, BX

loop_3:
	TESTQ        BX, BX
	JEQ          done_4
	DECQ         BX
	MOVQ         0(R13), CX
	VPBROADCASTD 0(CX), Z29
	ADD(Z0, Z29, Z24, Z30, Z0)

#define MUL_5W(in0, in1, in2, in3, in4, in5, in6, in7, in8, in9) \
	VPSRLQ    $32, in0, in2 \
	VPSRLQ    $32, in1, in3 \
	VPMULUDQ  in0, in1, in4 \
	VPMULUDQ  in2, in3, in5 \
	VPMULUDQ  in4, in9, in6 \
	VPMULUDQ  in5, in9, in3 \
	VPMULUDQ  in6, in8, in6 \
	VPADDQ    in4, in6, in4 \
	VPMULUDQ  in3, in8, in3 \
	VPADDQ    in5, in3, in7 \
	VMOVSHDUP in4, K3, in7  \

	MUL_5W(Z0, Z0, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z0, Z31, Z26, Z27, Z28, Z30, Z29, Z0, Z24, Z25)
	REDUCE1Q(Z24, Z0, Z26)
	VPBROADCASTD 4(CX), Z27
	ADD(Z1, Z27, Z24, Z28, Z1)
	MUL_5W(Z1, Z1, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z1, Z30, Z29, Z26, Z31, Z28, Z27, Z1, Z24, Z25)
	REDUCE1Q(Z24, Z1, Z29)
	VPBROADCASTD 8(CX), Z26
	ADD(Z2, Z26, Z24, Z31, Z2)
	MUL_5W(Z2, Z2, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z2, Z28, Z27, Z29, Z30, Z31, Z26, Z2, Z24, Z25)
	REDUCE1Q(Z24, Z2, Z27)
	VPBROADCASTD 12(CX), Z29
	ADD(Z3, Z29, Z24, Z30, Z3)
	MUL_5W(Z3, Z3, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z3, Z31, Z26, Z27, Z28, Z30, Z29, Z3, Z24, Z25)
	REDUCE1Q(Z24, Z3, Z26)
	VPBROADCASTD 16(CX), Z27
	ADD(Z4, Z27, Z24, Z28, Z4)
	MUL_5W(Z4, Z4, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z4, Z30, Z29, Z26, Z31, Z28, Z27, Z4, Z24, Z25)
	REDUCE1Q(Z24, Z4, Z29)
	VPBROADCASTD 20(CX), Z26
	ADD(Z5, Z26, Z24, Z31, Z5)
	MUL_5W(Z5, Z5, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z5, Z28, Z27, Z29, Z30, Z31, Z26, Z5, Z24, Z25)
	REDUCE1Q(Z24, Z5, Z27)
	VPBROADCASTD 24(CX), Z29
	ADD(Z6, Z29, Z24, Z30, Z6)
	MUL_5W(Z6, Z6, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z6, Z31, Z26, Z27, Z28, Z30, Z29, Z6, Z24, Z25)
	REDUCE1Q(Z24, Z6, Z26)
	VPBROADCASTD 28(CX), Z27
	ADD(Z7, Z27, Z24, Z28, Z7)
	MUL_5W(Z7, Z7, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z7, Z30, Z29, Z26, Z31, Z28, Z27, Z7, Z24, Z25)
	REDUCE1Q(Z24, Z7, Z29)
	VPBROADCASTD 32(CX), Z26
	ADD(Z8, Z26, Z24, Z31, Z8)
	MUL_5W(Z8, Z8, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z8, Z28, Z27, Z29, Z30, Z31, Z26, Z8, Z24, Z25)
	REDUCE1Q(Z24, Z8, Z27)
	VPBROADCASTD 36(CX), Z29
	ADD(Z9, Z29, Z24, Z30, Z9)
	MUL_5W(Z9, Z9, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z9, Z31, Z26, Z27, Z28, Z30, Z29, Z9, Z24, Z25)
	REDUCE1Q(Z24, Z9, Z26)
	VPBROADCASTD 40(CX), Z27
	ADD(Z10, Z27, Z24, Z28, Z10)
	MUL_5W(Z10, Z10, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z10, Z30, Z29, Z26, Z31, Z28, Z27, Z10, Z24, Z25)
	REDUCE1Q(Z24, Z10, Z29)
	VPBROADCASTD 44(CX), Z26
	ADD(Z11, Z26, Z24, Z31, Z11)
	MUL_5W(Z11, Z11, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z11, Z28, Z27, Z29, Z30, Z31, Z26, Z11, Z24, Z25)
	REDUCE1Q(Z24, Z11, Z27)
	VPBROADCASTD 48(CX), Z29
	ADD(Z12, Z29, Z24, Z30, Z12)
	MUL_5W(Z12, Z12, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z12, Z31, Z26, Z27, Z28, Z30, Z29, Z12, Z24, Z25)
	REDUCE1Q(Z24, Z12, Z26)
	VPBROADCASTD 52(CX), Z27
	ADD(Z13, Z27, Z24, Z28, Z13)
	MUL_5W(Z13, Z13, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z13, Z30, Z29, Z26, Z31, Z28, Z27, Z13, Z24, Z25)
	REDUCE1Q(Z24, Z13, Z29)
	VPBROADCASTD 56(CX), Z26
	ADD(Z14, Z26, Z24, Z31, Z14)
	MUL_5W(Z14, Z14, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z14, Z28, Z27, Z29, Z30, Z31, Z26, Z14, Z24, Z25)
	REDUCE1Q(Z24, Z14, Z27)
	VPBROADCASTD 60(CX), Z29
	ADD(Z15, Z29, Z24, Z30, Z15)
	MUL_5W(Z15, Z15, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z15, Z31, Z26, Z27, Z28, Z30, Z29, Z15, Z24, Z25)
	REDUCE1Q(Z24, Z15, Z26)
	VPBROADCASTD 64(CX), Z27
	ADD(Z16, Z27, Z24, Z28, Z16)
	MUL_5W(Z16, Z16, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z16, Z30, Z29, Z26, Z31, Z28, Z27, Z16, Z24, Z25)
	REDUCE1Q(Z24, Z16, Z29)
	VPBROADCASTD 68(CX), Z26
	ADD(Z17, Z26, Z24, Z31, Z17)
	MUL_5W(Z17, Z17, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z17, Z28, Z27, Z29, Z30, Z31, Z26, Z17, Z24, Z25)
	REDUCE1Q(Z24, Z17, Z27)
	VPBROADCASTD 72(CX), Z29
	ADD(Z18, Z29, Z24, Z30, Z18)
	MUL_5W(Z18, Z18, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z18, Z31, Z26, Z27, Z28, Z30, Z29, Z18, Z24, Z25)
	REDUCE1Q(Z24, Z18, Z26)
	VPBROADCASTD 76(CX), Z27
	ADD(Z19, Z27, Z24, Z28, Z19)
	MUL_5W(Z19, Z19, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z19, Z30, Z29, Z26, Z31, Z28, Z27, Z19, Z24, Z25)
	REDUCE1Q(Z24, Z19, Z29)
	VPBROADCASTD 80(CX), Z26
	ADD(Z20, Z26, Z24, Z31, Z20)
	MUL_5W(Z20, Z20, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z20, Z28, Z27, Z29, Z30, Z31, Z26, Z20, Z24, Z25)
	REDUCE1Q(Z24, Z20, Z27)
	VPBROADCASTD 84(CX), Z29
	ADD(Z21, Z29, Z24, Z30, Z21)
	MUL_5W(Z21, Z21, Z26, Z27, Z28, Z30, Z29, Z31, Z24, Z25)
	MUL_5W(Z21, Z31, Z26, Z27, Z28, Z30, Z29, Z21, Z24, Z25)
	REDUCE1Q(Z24, Z21, Z26)
	VPBROADCASTD 88(CX), Z27
	ADD(Z22, Z27, Z24, Z28, Z22)
	MUL_5W(Z22, Z22, Z29, Z26, Z31, Z28, Z27, Z30, Z24, Z25)
	MUL_5W(Z22, Z30, Z29, Z26, Z31, Z28, Z27, Z22, Z24, Z25)
	REDUCE1Q(Z24, Z22, Z29)
	VPBROADCASTD 92(CX), Z26
	ADD(Z23, Z26, Z24, Z31, Z23)
	MUL_5W(Z23, Z23, Z27, Z29, Z30, Z31, Z26, Z28, Z24, Z25)
	MUL_5W(Z23, Z28, Z27, Z29, Z30, Z31, Z26, Z23, Z24, Z25)
	REDUCE1Q(Z24, Z23, Z27)
	ADD(Z0, Z1, Z24, Z28, Z29)
	ADD(Z2, Z3, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z1, Z24, Z28, Z26)
	ADD(Z31, Z3, Z24, Z28, Z27)
	DOUBLE(Z0, Z24, Z28, Z3)
	ADD(Z3, Z27, Z24, Z28, Z3)
	DOUBLE(Z2, Z24, Z28, Z1)
	ADD(Z1, Z26, Z24, Z28, Z1)
	ADD(Z29, Z26, Z24, Z28, Z0)
	ADD(Z30, Z27, Z24, Z28, Z2)
	ADD(Z4, Z5, Z24, Z28, Z29)
	ADD(Z6, Z7, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z5, Z24, Z28, Z26)
	ADD(Z31, Z7, Z24, Z28, Z27)
	DOUBLE(Z4, Z24, Z28, Z7)
	ADD(Z7, Z27, Z24, Z28, Z7)
	DOUBLE(Z6, Z24, Z28, Z5)
	ADD(Z5, Z26, Z24, Z28, Z5)
	ADD(Z29, Z26, Z24, Z28, Z4)
	ADD(Z30, Z27, Z24, Z28, Z6)
	ADD(Z8, Z9, Z24, Z28, Z29)
	ADD(Z10, Z11, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z9, Z24, Z28, Z26)
	ADD(Z31, Z11, Z24, Z28, Z27)
	DOUBLE(Z8, Z24, Z28, Z11)
	ADD(Z11, Z27, Z24, Z28, Z11)
	DOUBLE(Z10, Z24, Z28, Z9)
	ADD(Z9, Z26, Z24, Z28, Z9)
	ADD(Z29, Z26, Z24, Z28, Z8)
	ADD(Z30, Z27, Z24, Z28, Z10)
	ADD(Z12, Z13, Z24, Z28, Z29)
	ADD(Z14, Z15, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z13, Z24, Z28, Z26)
	ADD(Z31, Z15, Z24, Z28, Z27)
	DOUBLE(Z12, Z24, Z28, Z15)
	ADD(Z15, Z27, Z24, Z28, Z15)
	DOUBLE(Z14, Z24, Z28, Z13)
	ADD(Z13, Z26, Z24, Z28, Z13)
	ADD(Z29, Z26, Z24, Z28, Z12)
	ADD(Z30, Z27, Z24, Z28, Z14)
	ADD(Z16, Z17, Z24, Z28, Z29)
	ADD(Z18, Z19, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z17, Z24, Z28, Z26)
	ADD(Z31, Z19, Z24, Z28, Z27)
	DOUBLE(Z16, Z24, Z28, Z19)
	ADD(Z19, Z27, Z24, Z28, Z19)
	DOUBLE(Z18, Z24, Z28, Z17)
	ADD(Z17, Z26, Z24, Z28, Z17)
	ADD(Z29, Z26, Z24, Z28, Z16)
	ADD(Z30, Z27, Z24, Z28, Z18)
	ADD(Z20, Z21, Z24, Z28, Z29)
	ADD(Z22, Z23, Z24, Z28, Z30)
	ADD(Z29, Z30, Z24, Z28, Z31)
	ADD(Z31, Z21, Z24, Z28, Z26)
	ADD(Z31, Z23, Z24, Z28, Z27)
	DOUBLE(Z20, Z24, Z28, Z23)
	ADD(Z23, Z27, Z24, Z28, Z23)
	DOUBLE(Z22, Z24, Z28, Z21)
	ADD(Z21, Z26, Z24, Z28, Z21)
	ADD(Z29, Z26, Z24, Z28, Z20)
	ADD(Z30, Z27, Z24, Z28, Z22)
	ADD(Z0, Z4, Z24, Z26, Z28)
	ADD(Z1, Z5, Z24, Z27, Z29)
	ADD(Z2, Z6, Z24, Z26, Z30)
	ADD(Z3, Z7, Z24, Z27, Z31)
	ADD(Z8, Z28, Z24, Z26, Z28)
	ADD(Z9, Z29, Z24, Z27, Z29)
	ADD(Z10, Z30, Z24, Z26, Z30)
	ADD(Z11, Z31, Z24, Z27, Z31)
	ADD(Z12, Z28, Z24, Z26, Z28)
	ADD(Z13, Z29, Z24, Z27, Z29)
	ADD(Z14, Z30, Z24, Z26, Z30)
	ADD(Z15, Z31, Z24, Z27, Z31)
	ADD(Z16, Z28, Z24, Z26, Z28)
	ADD(Z17, Z29, Z24, Z27, Z29)
	ADD(Z18, Z30, Z24, Z26, Z30)
	ADD(Z19, Z31, Z24, Z27, Z31)
	ADD(Z20, Z28, Z24, Z26, Z28)
	ADD(Z21, Z29, Z24, Z27, Z29)
	ADD(Z22, Z30, Z24, Z26, Z30)
	ADD(Z23, Z31, Z24, Z27, Z31)
	ADD(Z0, Z28, Z24, Z26, Z0)
	ADD(Z1, Z29, Z24, Z27, Z1)
	ADD(Z2, Z30, Z24, Z26, Z2)
	ADD(Z3, Z31, Z24, Z27, Z3)
	ADD(Z4, Z28, Z24, Z26, Z4)
	ADD(Z5, Z29, Z24, Z27, Z5)
	ADD(Z6, Z30, Z24, Z26, Z6)
	ADD(Z7, Z31, Z24, Z27, Z7)
	ADD(Z8, Z28, Z24, Z26, Z8)
	ADD(Z9, Z29, Z24, Z27, Z9)
	ADD(Z10, Z30, Z24, Z26, Z10)
	ADD(Z11, Z31, Z24, Z27, Z11)
	ADD(Z12, Z28, Z24, Z26, Z12)
	ADD(Z13, Z29, Z24, Z27, Z13)
	ADD(Z14, Z30, Z24, Z26, Z14)
	ADD(Z15, Z31, Z24, Z27, Z15)
	ADD(Z16, Z28, Z24, Z26, Z16)
	ADD(Z17, Z29, Z24, Z27, Z17)
	ADD(Z18, Z30, Z24, Z26, Z18)
	ADD(Z19, Z31, Z24, Z27, Z19)
	ADD(Z20, Z28, Z24, Z26, Z20)
	ADD(Z21, Z29, Z24, Z27, Z21)
	ADD(Z22, Z30, Z24, Z26, Z22)
	ADD(Z23, Z31, Z24, Z27, Z23)
	ADDQ         $24, R13
	JMP          loop_3

done_4:
	// loop over the partial rounds
	MOVQ $0x0000000000000015, SI

loop_5:
	TESTQ        SI, SI
	JEQ          done_6
	DECQ         SI
	MOVQ         0(R13), CX
	VPBROADCASTD 0(CX), Z26
	ADD(Z0, Z26, Z24, Z27, Z0)
	MUL_5W(Z0, Z0, Z29, Z30, Z31, Z27, Z26, Z28, Z24, Z25)
	MUL_5W(Z0, Z28, Z29, Z30, Z31, Z27, Z26, Z0, Z24, Z25)
	REDUCE1Q(Z24, Z0, Z29)
	ADD(Z0, Z1, Z24, Z28, Z27)
	ADD(Z2, Z3, Z24, Z28, Z26)
	ADD(Z4, Z5, Z24, Z28, Z29)
	ADD(Z6, Z7, Z24, Z28, Z30)
	ADD(Z8, Z27, Z24, Z28, Z27)
	ADD(Z9, Z26, Z24, Z28, Z26)
	ADD(Z10, Z29, Z24, Z28, Z29)
	ADD(Z11, Z30, Z24, Z28, Z30)
	ADD(Z12, Z27, Z24, Z28, Z27)
	ADD(Z13, Z26, Z24, Z28, Z26)
	ADD(Z14, Z29, Z24, Z28, Z29)
	ADD(Z15, Z30, Z24, Z28, Z30)
	ADD(Z16, Z27, Z24, Z28, Z27)
	ADD(Z17, Z26, Z24, Z28, Z26)
	ADD(Z18, Z29, Z24, Z28, Z29)
	ADD(Z19, Z30, Z24, Z28, Z30)
	ADD(Z20, Z27, Z24, Z28, Z27)
	ADD(Z21, Z26, Z24, Z28, Z26)
	ADD(Z22, Z29, Z24, Z28, Z29)
	ADD(Z23, Z30, Z24, Z28, Z30)
	ADD(Z27, Z26, Z24, Z28, Z27)
	ADD(Z29, Z30, Z24, Z28, Z29)
	ADD(Z27, Z29, Z24, Z28, Z30)
	DOUBLE(Z0, Z24, Z28, Z0)
	DOUBLE(Z2, Z24, Z28, Z2)

#define HALVE(in0, in1, in2) \
	MOVD         $1, AX            \
	VPBROADCASTD AX, in1           \
	VPTESTMD     in0, in1, K4      \
	VPADDD       in0, in2, K4, in0 \
	VPSRLD       $1, in0, in0      \

	HALVE(Z3, Z28, Z24)
	HALVE(Z6, Z28, Z24)
	DOUBLE(Z4, Z24, Z28, Z27)
	ADD(Z4, Z27, Z24, Z28, Z4)
	DOUBLE(Z5, Z24, Z28, Z5)
	DOUBLE(Z5, Z24, Z28, Z5)
	DOUBLE(Z7, Z24, Z28, Z31)
	ADD(Z7, Z31, Z24, Z28, Z7)
	DOUBLE(Z8, Z24, Z28, Z8)
	DOUBLE(Z8, Z24, Z28, Z8)

#define MUL_2_EXP_NEG_N(in0, in1, in2, in3, in4, in5, in6, in7, in8, in9, in10) \
	VPSRLQ    $32, in0, in6  \
	VPSLLQ    $32, in0, in0  \
	VPSRLQ    in2, in0, in4  \
	VPSLLQ    in3, in6, in5  \
	VPMULUDQ  in4, in10, in7 \
	VPMULUDQ  in5, in10, in8 \
	VPMULUDQ  in7, in9, in7  \
	VPADDQ    in4, in7, in4  \
	VPMULUDQ  in8, in9, in8  \
	VPADDQ    in5, in8, in1  \
	VMOVSHDUP in4, K3, in1   \
	VPSUBD    in9, in1, in8  \
	VPMINUD   in1, in8, in1  \

	MUL_2_EXP_NEG_N(Z9, Z9, $8, $24, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z10, Z10, $2, $30, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z11, Z11, $3, $29, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z12, Z12, $4, $28, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z13, Z13, $5, $27, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z14, Z14, $6, $26, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z15, Z15, $24, $8, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z16, Z16, $8, $24, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z17, Z17, $3, $29, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z18, Z18, $4, $28, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z19, Z19, $5, $27, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z20, Z20, $6, $26, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z21, Z21, $7, $25, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z22, Z22, $9, $23, Z28, Z31, Z27, Z26, Z29, Z24, Z25)
	MUL_2_EXP_NEG_N(Z23, Z23, $24, $8, Z28, Z31, Z27, Z26, Z29, Z24, Z25)

#define SUB(in0, in1, in2, in3, in4) \
	VPSUBD  in1, in0, in4 \
	VPADDD  in2, in4, in3 \
	VPMINUD in4, in3, in4 \

	SUB(Z30, Z0, Z24, Z28, Z0)
	ADD(Z30, Z1, Z24, Z31, Z1)
	ADD(Z2, Z30, Z24, Z27, Z2)
	ADD(Z3, Z30, Z24, Z26, Z3)
	ADD(Z4, Z30, Z24, Z29, Z4)
	ADD(Z5, Z30, Z24, Z28, Z5)
	SUB(Z30, Z6, Z24, Z31, Z6)
	SUB(Z30, Z7, Z24, Z27, Z7)
	SUB(Z30, Z8, Z24, Z26, Z8)
	ADD(Z9, Z30, Z24, Z29, Z9)
	ADD(Z10, Z30, Z24, Z28, Z10)
	ADD(Z11, Z30, Z24, Z31, Z11)
	ADD(Z12, Z30, Z24, Z27, Z12)
	ADD(Z13, Z30, Z24, Z26, Z13)
	ADD(Z14, Z30, Z24, Z29, Z14)
	ADD(Z15, Z30, Z24, Z28, Z15)
	SUB(Z30, Z16, Z24, Z31, Z16)
	SUB(Z30, Z17, Z24, Z27, Z17)
	SUB(Z30, Z18, Z24, Z26, Z18)
	SUB(Z30, Z19, Z24, Z29, Z19)
	SUB(Z30, Z20, Z24, Z28, Z20)
	SUB(Z30, Z21, Z24, Z31, Z21)
	SUB(Z30, Z22, Z24, Z27, Z22)
	SUB(Z30, Z23, Z24, Z26, Z23)
	ADDQ $24, R13
	JMP  loop_5

done_6:
	// loop over the final full rounds
	MOVQ $0x0000000000000003, DI

loop_7:
	TESTQ        DI, DI
	JEQ          done_8
	DECQ         DI
	MOVQ         0(R13), CX
	VPBROADCASTD 0(CX), Z29
	ADD(Z0, Z29, Z24, Z28, Z0)
	MUL_5W(Z0, Z0, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z0, Z31, Z27, Z26, Z30, Z28, Z29, Z0, Z24, Z25)
	REDUCE1Q(Z24, Z0, Z27)
	VPBROADCASTD 4(CX), Z26
	ADD(Z1, Z26, Z24, Z30, Z1)
	MUL_5W(Z1, Z1, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z1, Z28, Z29, Z27, Z31, Z30, Z26, Z1, Z24, Z25)
	REDUCE1Q(Z24, Z1, Z29)
	VPBROADCASTD 8(CX), Z27
	ADD(Z2, Z27, Z24, Z31, Z2)
	MUL_5W(Z2, Z2, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z2, Z30, Z26, Z29, Z28, Z31, Z27, Z2, Z24, Z25)
	REDUCE1Q(Z24, Z2, Z26)
	VPBROADCASTD 12(CX), Z29
	ADD(Z3, Z29, Z24, Z28, Z3)
	MUL_5W(Z3, Z3, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z3, Z31, Z27, Z26, Z30, Z28, Z29, Z3, Z24, Z25)
	REDUCE1Q(Z24, Z3, Z27)
	VPBROADCASTD 16(CX), Z26
	ADD(Z4, Z26, Z24, Z30, Z4)
	MUL_5W(Z4, Z4, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z4, Z28, Z29, Z27, Z31, Z30, Z26, Z4, Z24, Z25)
	REDUCE1Q(Z24, Z4, Z29)
	VPBROADCASTD 20(CX), Z27
	ADD(Z5, Z27, Z24, Z31, Z5)
	MUL_5W(Z5, Z5, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z5, Z30, Z26, Z29, Z28, Z31, Z27, Z5, Z24, Z25)
	REDUCE1Q(Z24, Z5, Z26)
	VPBROADCASTD 24(CX), Z29
	ADD(Z6, Z29, Z24, Z28, Z6)
	MUL_5W(Z6, Z6, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z6, Z31, Z27, Z26, Z30, Z28, Z29, Z6, Z24, Z25)
	REDUCE1Q(Z24, Z6, Z27)
	VPBROADCASTD 28(CX), Z26
	ADD(Z7, Z26, Z24, Z30, Z7)
	MUL_5W(Z7, Z7, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z7, Z28, Z29, Z27, Z31, Z30, Z26, Z7, Z24, Z25)
	REDUCE1Q(Z24, Z7, Z29)
	VPBROADCASTD 32(CX), Z27
	ADD(Z8, Z27, Z24, Z31, Z8)
	MUL_5W(Z8, Z8, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z8, Z30, Z26, Z29, Z28, Z31, Z27, Z8, Z24, Z25)
	REDUCE1Q(Z24, Z8, Z26)
	VPBROADCASTD 36(CX), Z29
	ADD(Z9, Z29, Z24, Z28, Z9)
	MUL_5W(Z9, Z9, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z9, Z31, Z27, Z26, Z30, Z28, Z29, Z9, Z24, Z25)
	REDUCE1Q(Z24, Z9, Z27)
	VPBROADCASTD 40(CX), Z26
	ADD(Z10, Z26, Z24, Z30, Z10)
	MUL_5W(Z10, Z10, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z10, Z28, Z29, Z27, Z31, Z30, Z26, Z10, Z24, Z25)
	REDUCE1Q(Z24, Z10, Z29)
	VPBROADCASTD 44(CX), Z27
	ADD(Z11, Z27, Z24, Z31, Z11)
	MUL_5W(Z11, Z11, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z11, Z30, Z26, Z29, Z28, Z31, Z27, Z11, Z24, Z25)
	REDUCE1Q(Z24, Z11, Z26)
	VPBROADCASTD 48(CX), Z29
	ADD(Z12, Z29, Z24, Z28, Z12)
	MUL_5W(Z12, Z12, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z12, Z31, Z27, Z26, Z30, Z28, Z29, Z12, Z24, Z25)
	REDUCE1Q(Z24, Z12, Z27)
	VPBROADCASTD 52(CX), Z26
	ADD(Z13, Z26, Z24, Z30, Z13)
	MUL_5W(Z13, Z13, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z13, Z28, Z29, Z27, Z31, Z30, Z26, Z13, Z24, Z25)
	REDUCE1Q(Z24, Z13, Z29)
	VPBROADCASTD 56(CX), Z27
	ADD(Z14, Z27, Z24, Z31, Z14)
	MUL_5W(Z14, Z14, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z14, Z30, Z26, Z29, Z28, Z31, Z27, Z14, Z24, Z25)
	REDUCE1Q(Z24, Z14, Z26)
	VPBROADCASTD 60(CX), Z29
	ADD(Z15, Z29, Z24, Z28, Z15)
	MUL_5W(Z15, Z15, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z15, Z31, Z27, Z26, Z30, Z28, Z29, Z15, Z24, Z25)
	REDUCE1Q(Z24, Z15, Z27)
	VPBROADCASTD 64(CX), Z26
	ADD(Z16, Z26, Z24, Z30, Z16)
	MUL_5W(Z16, Z16, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z16, Z28, Z29, Z27, Z31, Z30, Z26, Z16, Z24, Z25)
	REDUCE1Q(Z24, Z16, Z29)
	VPBROADCASTD 68(CX), Z27
	ADD(Z17, Z27, Z24, Z31, Z17)
	MUL_5W(Z17, Z17, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z17, Z30, Z26, Z29, Z28, Z31, Z27, Z17, Z24, Z25)
	REDUCE1Q(Z24, Z17, Z26)
	VPBROADCASTD 72(CX), Z29
	ADD(Z18, Z29, Z24, Z28, Z18)
	MUL_5W(Z18, Z18, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z18, Z31, Z27, Z26, Z30, Z28, Z29, Z18, Z24, Z25)
	REDUCE1Q(Z24, Z18, Z27)
	VPBROADCASTD 76(CX), Z26
	ADD(Z19, Z26, Z24, Z30, Z19)
	MUL_5W(Z19, Z19, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z19, Z28, Z29, Z27, Z31, Z30, Z26, Z19, Z24, Z25)
	REDUCE1Q(Z24, Z19, Z29)
	VPBROADCASTD 80(CX), Z27
	ADD(Z20, Z27, Z24, Z31, Z20)
	MUL_5W(Z20, Z20, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z20, Z30, Z26, Z29, Z28, Z31, Z27, Z20, Z24, Z25)
	REDUCE1Q(Z24, Z20, Z26)
	VPBROADCASTD 84(CX), Z29
	ADD(Z21, Z29, Z24, Z28, Z21)
	MUL_5W(Z21, Z21, Z27, Z26, Z30, Z28, Z29, Z31, Z24, Z25)
	MUL_5W(Z21, Z31, Z27, Z26, Z30, Z28, Z29, Z21, Z24, Z25)
	REDUCE1Q(Z24, Z21, Z27)
	VPBROADCASTD 88(CX), Z26
	ADD(Z22, Z26, Z24, Z30, Z22)
	MUL_5W(Z22, Z22, Z29, Z27, Z31, Z30, Z26, Z28, Z24, Z25)
	MUL_5W(Z22, Z28, Z29, Z27, Z31, Z30, Z26, Z22, Z24, Z25)
	REDUCE1Q(Z24, Z22, Z29)
	VPBROADCASTD 92(CX), Z27
	ADD(Z23, Z27, Z24, Z31, Z23)
	MUL_5W(Z23, Z23, Z26, Z29, Z28, Z31, Z27, Z30, Z24, Z25)
	MUL_5W(Z23, Z30, Z26, Z29, Z28, Z31, Z27, Z23, Z24, Z25)
	REDUCE1Q(Z24, Z23, Z26)
	ADD(Z0, Z1, Z24, Z30, Z29)
	ADD(Z2, Z3, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z1, Z24, Z30, Z27)
	ADD(Z31, Z3, Z24, Z30, Z26)
	DOUBLE(Z0, Z24, Z30, Z3)
	ADD(Z3, Z26, Z24, Z30, Z3)
	DOUBLE(Z2, Z24, Z30, Z1)
	ADD(Z1, Z27, Z24, Z30, Z1)
	ADD(Z29, Z27, Z24, Z30, Z0)
	ADD(Z28, Z26, Z24, Z30, Z2)
	ADD(Z4, Z5, Z24, Z30, Z29)
	ADD(Z6, Z7, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z5, Z24, Z30, Z27)
	ADD(Z31, Z7, Z24, Z30, Z26)
	DOUBLE(Z4, Z24, Z30, Z7)
	ADD(Z7, Z26, Z24, Z30, Z7)
	DOUBLE(Z6, Z24, Z30, Z5)
	ADD(Z5, Z27, Z24, Z30, Z5)
	ADD(Z29, Z27, Z24, Z30, Z4)
	ADD(Z28, Z26, Z24, Z30, Z6)
	ADD(Z8, Z9, Z24, Z30, Z29)
	ADD(Z10, Z11, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z9, Z24, Z30, Z27)
	ADD(Z31, Z11, Z24, Z30, Z26)
	DOUBLE(Z8, Z24, Z30, Z11)
	ADD(Z11, Z26, Z24, Z30, Z11)
	DOUBLE(Z10, Z24, Z30, Z9)
	ADD(Z9, Z27, Z24, Z30, Z9)
	ADD(Z29, Z27, Z24, Z30, Z8)
	ADD(Z28, Z26, Z24, Z30, Z10)
	ADD(Z12, Z13, Z24, Z30, Z29)
	ADD(Z14, Z15, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z13, Z24, Z30, Z27)
	ADD(Z31, Z15, Z24, Z30, Z26)
	DOUBLE(Z12, Z24, Z30, Z15)
	ADD(Z15, Z26, Z24, Z30, Z15)
	DOUBLE(Z14, Z24, Z30, Z13)
	ADD(Z13, Z27, Z24, Z30, Z13)
	ADD(Z29, Z27, Z24, Z30, Z12)
	ADD(Z28, Z26, Z24, Z30, Z14)
	ADD(Z16, Z17, Z24, Z30, Z29)
	ADD(Z18, Z19, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z17, Z24, Z30, Z27)
	ADD(Z31, Z19, Z24, Z30, Z26)
	DOUBLE(Z16, Z24, Z30, Z19)
	ADD(Z19, Z26, Z24, Z30, Z19)
	DOUBLE(Z18, Z24, Z30, Z17)
	ADD(Z17, Z27, Z24, Z30, Z17)
	ADD(Z29, Z27, Z24, Z30, Z16)
	ADD(Z28, Z26, Z24, Z30, Z18)
	ADD(Z20, Z21, Z24, Z30, Z29)
	ADD(Z22, Z23, Z24, Z30, Z28)
	ADD(Z29, Z28, Z24, Z30, Z31)
	ADD(Z31, Z21, Z24, Z30, Z27)
	ADD(Z31, Z23, Z24, Z30, Z26)
	DOUBLE(Z20, Z24, Z30, Z23)
	ADD(Z23, Z26, Z24, Z30, Z23)
	DOUBLE(Z22, Z24, Z30, Z21)
	ADD(Z21, Z27, Z24, Z30, Z21)
	ADD(Z29, Z27, Z24, Z30, Z20)
	ADD(Z28, Z26, Z24, Z30, Z22)
	ADD(Z0, Z4, Z24, Z27, Z30)
	ADD(Z1, Z5, Z24, Z26, Z29)
	ADD(Z2, Z6, Z24, Z27, Z28)
	ADD(Z3, Z7, Z24, Z26, Z31)
	ADD(Z8, Z30, Z24, Z27, Z30)
	ADD(Z9, Z29, Z24, Z26, Z29)
	ADD(Z10, Z28, Z24, Z27, Z28)
	ADD(Z11, Z31, Z24, Z26, Z31)
	ADD(Z12, Z30, Z24, Z27, Z30)
	ADD(Z13, Z29, Z24, Z26, Z29)
	ADD(Z14, Z28, Z24, Z27, Z28)
	ADD(Z15, Z31, Z24, Z26, Z31)
	ADD(Z16, Z30, Z24, Z27, Z30)
	ADD(Z17, Z29, Z24, Z26, Z29)
	ADD(Z18, Z28, Z24, Z27, Z28)
	ADD(Z19, Z31, Z24, Z26, Z31)
	ADD(Z20, Z30, Z24, Z27, Z30)
	ADD(Z21, Z29, Z24, Z26, Z29)
	ADD(Z22, Z28, Z24, Z27, Z28)
	ADD(Z23, Z31, Z24, Z26, Z31)
	ADD(Z0, Z30, Z24, Z27, Z0)
	ADD(Z1, Z29, Z24, Z26, Z1)
	ADD(Z2, Z28, Z24, Z27, Z2)
	ADD(Z3, Z31, Z24, Z26, Z3)
	ADD(Z4, Z30, Z24, Z27, Z4)
	ADD(Z5, Z29, Z24, Z26, Z5)
	ADD(Z6, Z28, Z24, Z27, Z6)
	ADD(Z7, Z31, Z24, Z26, Z7)
	ADD(Z8, Z30, Z24, Z27, Z8)
	ADD(Z9, Z29, Z24, Z26, Z9)
	ADD(Z10, Z28, Z24, Z27, Z10)
	ADD(Z11, Z31, Z24, Z26, Z11)
	ADD(Z12, Z30, Z24, Z27, Z12)
	ADD(Z13, Z29, Z24, Z26, Z13)
	ADD(Z14, Z28, Z24, Z27, Z14)
	ADD(Z15, Z31, Z24, Z26, Z15)
	ADD(Z16, Z30, Z24, Z27, Z16)
	ADD(Z17, Z29, Z24, Z26, Z17)
	ADD(Z18, Z28, Z24, Z27, Z18)
	ADD(Z19, Z31, Z24, Z26, Z19)
	ADD(Z20, Z30, Z24, Z27, Z20)
	ADD(Z21, Z29, Z24, Z26, Z21)
	ADD(Z22, Z28, Z24, Z27, Z22)
	ADD(Z23, Z31, Z24, Z26, Z23)
	ADDQ         $24, R13
	JMP          loop_7

done_8:
	VMOVDQU32 Z0, 0(R14)
	VMOVDQU32 Z1, 64(R14)
	VMOVDQU32 Z2, 128(R14)
	VMOVDQU32 Z3, 192(R14)
	VMOVDQU32 Z4, 256(R14)
	VMOVDQU32 Z5, 320(R14)
	VMOVDQU32 Z6, 384(R14)
	VMOVDQU32 Z7, 448(R14)
	VMOVDQU32 Z8, 512(R14)
	VMOVDQU32 Z9, 576(R14)
	VMOVDQU32 Z10, 640(R14)
	VMOVDQU32 Z11, 704(R14)
	VMOVDQU32 Z12, 768(R14)
	VMOVDQU32 Z13, 832(R14)
	VMOVDQU32 Z14, 896(R14)
	VMOVDQU32 Z15, 960(R14)
	VMOVDQU32 Z16, 1024(R14)
	VMOVDQU32 Z17, 1088(R14)
	VMOVDQU32 Z18, 1152(R14)
	VMOVDQU32 Z19, 1216(R14)
	VMOVDQU32 Z20, 1280(R14)
	VMOVDQU32 Z21, 1344(R14)
	VMOVDQU32 Z22, 1408(R14)
	VMOVDQU32 Z23, 1472(R14)
	RET

TEXT ·permutation16_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R14
	MOVQ         roundKeys+24(FP), R13
	VMOVDQU32    0(R14), Z2
	MOVQ         ·diag16+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VPSRLQ       $32, Z18, Z19

#define MAT_MUL_EXTERNAL_16() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define SBOX_FULL_16() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \

#define SUM_STATE_16() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND_16() \
	VMOVDQU32 0(BX), Z4      \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	SBOX_FULL_16()           \
	MAT_MUL_EXTERNAL_16()    \

	MAT_MUL_EXTERNAL_16()
	MOVQ 0(R13), BX
	FULL_ROUND_16()
	MOVQ 24(R13), BX
	FULL_ROUND_16()
	MOVQ 48(R13), BX
	FULL_ROUND_16()

	// loop over the partial rounds
	MOVQ $0x0000000000000015, SI // nb partial rounds --> 21
	MOVQ R13, DI
	ADDQ $0x0000000000000048, DI

loop_9:
	TESTQ     SI, SI
	JEQ       done_10
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE_16()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADDQ      $24, DI
	JMP       loop_9

done_10:
	MOVQ      576(R13), BX
	FULL_ROUND_16()
	MOVQ      600(R13), BX
	FULL_ROUND_16()
	MOVQ      624(R13), BX
	FULL_ROUND_16()
	VMOVDQU32 Z2, 0(R14)
	RET

TEXT ·permutation16x16xN_avx512(SB), NOSPLIT, $0-40
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z16
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z17
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         matrix+0(FP), R14
	MOVQ         roundKeys+8(FP), CX
	MOVQ         result+32(FP), R13
	VXORPS       Z0, Z0, Z0
	VXORPS       Z1, Z1, Z1
	VXORPS       Z2, Z2, Z2
	VXORPS       Z3, Z3, Z3
	VXORPS       Z4, Z4, Z4
	VXORPS       Z5, Z5, Z5
	VXORPS       Z6, Z6, Z6
	VXORPS       Z7, Z7, Z7
	VXORPS       Z8, Z8, Z8
	VXORPS       Z9, Z9, Z9
	VXORPS       Z10, Z10, Z10
	VXORPS       Z11, Z11, Z11
	VXORPS       Z12, Z12, Z12
	VXORPS       Z13, Z13, Z13
	VXORPS       Z14, Z14, Z14
	VXORPS       Z15, Z15, Z15
	MOVQ         $0x0000000000000040, SI   // number of steps (sisKeySize / 8) --> 64
	MOVQ         $0xffffffffffffffff, DI
	MOVQ         ·indexGather512+0(SB), R8
	VMOVDQU32    0(R8), Z18

loop_11:
	TESTQ      SI, SI
	JEQ        done_12
	DECQ       SI
	KMOVD      DI, K1
	VPGATHERDD 0(R14)(Z18*4), K1, Z8
	KMOVD      DI, K1
	VPGATHERDD 4(R14)(Z18*4), K1, Z9
	KMOVD      DI, K1
	VPGATHERDD 8(R14)(Z18*4), K1, Z10
	KMOVD      DI, K1
	VPGATHERDD 12(R14)(Z18*4), K1, Z11
	KMOVD      DI, K1
	VPGATHERDD 16(R14)(Z18*4), K1, Z12
	KMOVD      DI, K1
	VPGATHERDD 20(R14)(Z18*4), K1, Z13
	KMOVD      DI, K1
	VPGATHERDD 24(R14)(Z18*4), K1, Z14
	KMOVD      DI, K1
	VPGATHERDD 28(R14)(Z18*4), K1, Z15
	ADD(Z0, Z1, Z16, Z24, Z19)
	ADD(Z2, Z3, Z16, Z25, Z20)
	ADD(Z19, Z20, Z16, Z26, Z21)
	ADD(Z21, Z1, Z16, Z27, Z22)
	ADD(Z21, Z3, Z16, Z28, Z23)
	DOUBLE(Z0, Z16, Z29, Z3)
	ADD(Z3, Z23, Z16, Z30, Z3)
	DOUBLE(Z2, Z16, Z31, Z1)
	ADD(Z1, Z22, Z16, Z24, Z1)
	ADD(Z19, Z22, Z16, Z25, Z0)
	ADD(Z20, Z23, Z16, Z26, Z2)
	ADD(Z4, Z5, Z16, Z27, Z19)
	ADD(Z6, Z7, Z16, Z28, Z20)
	ADD(Z19, Z20, Z16, Z29, Z21)
	ADD(Z21, Z5, Z16, Z30, Z22)
	ADD(Z21, Z7, Z16, Z31, Z23)
	DOUBLE(Z4, Z16, Z24, Z7)
	ADD(Z7, Z23, Z16, Z25, Z7)
	DOUBLE(Z6, Z16, Z26, Z5)
	ADD(Z5, Z22, Z16, Z27, Z5)
	ADD(Z19, Z22, Z16, Z28, Z4)
	ADD(Z20, Z23, Z16, Z29, Z6)
	ADD(Z8, Z9, Z16, Z30, Z19)
	ADD(Z10, Z11, Z16, Z31, Z20)
	ADD(Z19, Z20, Z16, Z24, Z21)
	ADD(Z21, Z9, Z16, Z25, Z22)
	ADD(Z21, Z11, Z16, Z26, Z23)
	DOUBLE(Z8, Z16, Z27, Z11)
	ADD(Z11, Z23, Z16, Z28, Z11)
	DOUBLE(Z10, Z16, Z29, Z9)
	ADD(Z9, Z22, Z16, Z30, Z9)
	ADD(Z19, Z22, Z16, Z31, Z8)
	ADD(Z20, Z23, Z16, Z24, Z10)
	ADD(Z12, Z13, Z16, Z25, Z19)
	ADD(Z14, Z15, Z16, Z26, Z20)
	ADD(Z19, Z20, Z16, Z27, Z21)
	ADD(Z21, Z13, Z16, Z28, Z22)
	ADD(Z21, Z15, Z16, Z29, Z23)
	DOUBLE(Z12, Z16, Z30, Z15)
	ADD(Z15, Z23, Z16, Z31, Z15)
	DOUBLE(Z14, Z16, Z24, Z13)
	ADD(Z13, Z22, Z16, Z25, Z13)
	ADD(Z19, Z22, Z16, Z26, Z12)
	ADD(Z20, Z23, Z16, Z27, Z14)
	ADD(Z0, Z4, Z16, Z24, Z28)
	ADD(Z1, Z5, Z16, Z25, Z29)
	ADD(Z2, Z6, Z16, Z26, Z30)
	ADD(Z3, Z7, Z16, Z27, Z31)
	ADD(Z8, Z28, Z16, Z19, Z28)
	ADD(Z9, Z29, Z16, Z20, Z29)
	ADD(Z10, Z30, Z16, Z21, Z30)
	ADD(Z11, Z31, Z16, Z22, Z31)
	ADD(Z12, Z28, Z16, Z23, Z28)
	ADD(Z13, Z29, Z16, Z24, Z29)
	ADD(Z14, Z30, Z16, Z25, Z30)
	ADD(Z15, Z31, Z16, Z26, Z31)
	ADD(Z0, Z28, Z16, Z27, Z0)
	ADD(Z1, Z29, Z16, Z19, Z1)
	ADD(Z2, Z30, Z16, Z20, Z2)
	ADD(Z3, Z31, Z16, Z21, Z3)
	ADD(Z4, Z28, Z16, Z22, Z4)
	ADD(Z5, Z29, Z16, Z23, Z5)
	ADD(Z6, Z30, Z16, Z24, Z6)
	ADD(Z7, Z31, Z16, Z25, Z7)
	ADD(Z8, Z28, Z16, Z26, Z8)
	ADD(Z9, Z29, Z16, Z27, Z9)
	ADD(Z10, Z30, Z16, Z19, Z10)
	ADD(Z11, Z31, Z16, Z20, Z11)
	ADD(Z12, Z28, Z16, Z21, Z12)
	ADD(Z13, Z29, Z16, Z22, Z13)
	ADD(Z14, Z30, Z16, Z23, Z14)
	ADD(Z15, Z31, Z16, Z24, Z15)

	// loop over the first full rounds
	MOVQ $0x0000000000000003, R9

loop_13:
	TESTQ        R9, R9
	JEQ          done_14
	DECQ         R9
	MOVQ         0(CX), BX
	VPBROADCASTD 0(BX), Z25
	ADD(Z0, Z25, Z16, Z26, Z0)
	MUL_5W(Z0, Z0, Z19, Z20, Z21, Z22, Z23, Z27, Z16, Z17)
	MUL_5W(Z0, Z27, Z24, Z28, Z29, Z30, Z31, Z0, Z16, Z17)
	REDUCE1Q(Z16, Z0, Z26)
	VPBROADCASTD 4(BX), Z25
	ADD(Z1, Z25, Z16, Z19, Z1)
	MUL_5W(Z1, Z1, Z21, Z22, Z23, Z24, Z28, Z20, Z16, Z17)
	MUL_5W(Z1, Z20, Z29, Z30, Z31, Z26, Z27, Z1, Z16, Z17)
	REDUCE1Q(Z16, Z1, Z19)
	VPBROADCASTD 8(BX), Z25
	ADD(Z2, Z25, Z16, Z21, Z2)
	MUL_5W(Z2, Z2, Z23, Z24, Z28, Z29, Z30, Z22, Z16, Z17)
	MUL_5W(Z2, Z22, Z31, Z26, Z27, Z19, Z20, Z2, Z16, Z17)
	REDUCE1Q(Z16, Z2, Z21)
	VPBROADCASTD 12(BX), Z25
	ADD(Z3, Z25, Z16, Z23, Z3)
	MUL_5W(Z3, Z3, Z28, Z29, Z30, Z31, Z26, Z24, Z16, Z17)
	MUL_5W(Z3, Z24, Z27, Z19, Z20, Z21, Z22, Z3, Z16, Z17)
	REDUCE1Q(Z16, Z3, Z23)
	VPBROADCASTD 16(BX), Z25
	ADD(Z4, Z25, Z16, Z28, Z4)
	MUL_5W(Z4, Z4, Z30, Z31, Z26, Z27, Z19, Z29, Z16, Z17)
	MUL_5W(Z4, Z29, Z20, Z21, Z22, Z23, Z24, Z4, Z16, Z17)
	REDUCE1Q(Z16, Z4, Z28)
	VPBROADCASTD 20(BX), Z25
	ADD(Z5, Z25, Z16, Z30, Z5)
	MUL_5W(Z5, Z5, Z26, Z27, Z19, Z20, Z21, Z31, Z16, Z17)
	MUL_5W(Z5, Z31, Z22, Z23, Z24, Z28, Z29, Z5, Z16, Z17)
	REDUCE1Q(Z16, Z5, Z30)
	VPBROADCASTD 24(BX), Z25
	ADD(Z6, Z25, Z16, Z26, Z6)
	MUL_5W(Z6, Z6, Z19, Z20, Z21, Z22, Z23, Z27, Z16, Z17)
	MUL_5W(Z6, Z27, Z24, Z28, Z29, Z30, Z31, Z6, Z16, Z17)
	REDUCE1Q(Z16, Z6, Z26)
	VPBROADCASTD 28(BX), Z25
	ADD(Z7, Z25, Z16, Z19, Z7)
	MUL_5W(Z7, Z7, Z21, Z22, Z23, Z24, Z28, Z20, Z16, Z17)
	MUL_5W(Z7, Z20, Z29, Z30, Z31, Z26, Z27, Z7, Z16, Z17)
	REDUCE1Q(Z16, Z7, Z19)
	VPBROADCASTD 32(BX), Z25
	ADD(Z8, Z25, Z16, Z21, Z8)
	MUL_5W(Z8, Z8, Z23, Z24, Z28, Z29, Z30, Z22, Z16, Z17)
	MUL_5W(Z8, Z22, Z31, Z26, Z27, Z19, Z20, Z8, Z16, Z17)
	REDUCE1Q(Z16, Z8, Z21)
	VPBROADCASTD 36(BX), Z25
	ADD(Z9, Z25, Z16, Z23, Z9)
	MUL_5W(Z9, Z9, Z28, Z29, Z30, Z31, Z26, Z24, Z16, Z17)
	MUL_5W(Z9, Z24, Z27, Z19, Z20, Z21, Z22, Z9, Z16, Z17)
	REDUCE1Q(Z16, Z9, Z23)
	VPBROADCASTD 40(BX), Z25
	ADD(Z10, Z25, Z16, Z28, Z10)
	MUL_5W(Z10, Z10, Z30, Z31, Z26, Z27, Z19, Z29, Z16, Z17)
	MUL_5W(Z10, Z29, Z20, Z21, Z22, Z23, Z24, Z10, Z16, Z17)
	REDUCE1Q(Z16, Z10, Z28)
	VPBROADCASTD 44(BX), Z25
	ADD(Z11, Z25, Z16, Z30, Z11)
	MUL_5W(Z11, Z11, Z26, Z27, Z19, Z20, Z21, Z31, Z16, Z17)
	MUL_5W(Z11, Z31, Z22, Z23, Z24, Z28, Z29, Z11, Z16, Z17)
	REDUCE1Q(Z16, Z11, Z30)
	VPBROADCASTD 48(BX), Z25
	ADD(Z12, Z25, Z16, Z26, Z12)
	MUL_5W(Z12, Z12, Z19, Z20, Z21, Z22, Z23, Z27, Z16, Z17)
	MUL_5W(Z12, Z27, Z24, Z28, Z29, Z30, Z31, Z12, Z16, Z17)
	REDUCE1Q(Z16, Z12, Z26)
	VPBROADCASTD 52(BX), Z25
	ADD(Z13, Z25, Z16, Z19, Z13)
	MUL_5W(Z13, Z13, Z21, Z22, Z23, Z24, Z28, Z20, Z16, Z17)
	MUL_5W(Z13, Z20, Z29, Z30, Z31, Z26, Z27, Z13, Z16, Z17)
	REDUCE1Q(Z16, Z13, Z19)
	VPBROADCASTD 56(BX), Z25
	ADD(Z14, Z25, Z16, Z21, Z14)
	MUL_5W(Z14, Z14, Z23, Z24, Z28, Z29, Z30, Z22, Z16, Z17)
	MUL_5W(Z14, Z22, Z31, Z26, Z27, Z19, Z20, Z14, Z16, Z17)
	REDUCE1Q(Z16, Z14, Z21)
	VPBROADCASTD 60(BX), Z25
	ADD(Z15, Z25, Z16, Z23, Z15)
	MUL_5W(Z15, Z15, Z28, Z29, Z30, Z31, Z26, Z24, Z16, Z17)
	MUL_5W(Z15, Z24, Z27, Z19, Z20, Z21, Z22, Z15, Z16, Z17)
	REDUCE1Q(Z16, Z15, Z23)
	ADD(Z0, Z1, Z16, Z26, Z25)
	ADD(Z2, Z3, Z16, Z27, Z28)
	ADD(Z25, Z28, Z16, Z19, Z29)
	ADD(Z29, Z1, Z16, Z20, Z30)
	ADD(Z29, Z3, Z16, Z21, Z31)
	DOUBLE(Z0, Z16, Z22, Z3)
	ADD(Z3, Z31, Z16, Z23, Z3)
	DOUBLE(Z2, Z16, Z24, Z1)
	ADD(Z1, Z30, Z16, Z26, Z1)
	ADD(Z25, Z30, Z16, Z27, Z0)
	ADD(Z28, Z31, Z16, Z19, Z2)
	ADD(Z4, Z5, Z16, Z20, Z25)
	ADD(Z6, Z7, Z16, Z21, Z28)
	ADD(Z25, Z28, Z16, Z22, Z29)
	ADD(Z29, Z5, Z16, Z23, Z30)
	ADD(Z29, Z7, Z16, Z24, Z31)
	DOUBLE(Z4, Z16, Z26, Z7)
	ADD(Z7, Z31, Z16, Z27, Z7)
	DOUBLE(Z6, Z16, Z19, Z5)
	ADD(Z5, Z30, Z16, Z20, Z5)
	ADD(Z25, Z30, Z16, Z21, Z4)
	ADD(Z28, Z31, Z16, Z22, Z6)
	ADD(Z8, Z9, Z16, Z23, Z25)
	ADD(Z10, Z11, Z16, Z24, Z28)
	ADD(Z25, Z28, Z16, Z26, Z29)
	ADD(Z29, Z9, Z16, Z27, Z30)
	ADD(Z29, Z11, Z16, Z19, Z31)
	DOUBLE(Z8, Z16, Z20, Z11)
	ADD(Z11, Z31, Z16, Z21, Z11)
	DOUBLE(Z10, Z16, Z22, Z9)
	ADD(Z9, Z30, Z16, Z23, Z9)
	ADD(Z25, Z30, Z16, Z24, Z8)
	ADD(Z28, Z31, Z16, Z26, Z10)
	ADD(Z12, Z13, Z16, Z27, Z25)
	ADD(Z14, Z15, Z16, Z19, Z28)
	ADD(Z25, Z28, Z16, Z20, Z29)
	ADD(Z29, Z13, Z16, Z21, Z30)
	ADD(Z29, Z15, Z16, Z22, Z31)
	DOUBLE(Z12, Z16, Z23, Z15)
	ADD(Z15, Z31, Z16, Z24, Z15)
	DOUBLE(Z14, Z16, Z26, Z13)
	ADD(Z13, Z30, Z16, Z27, Z13)
	ADD(Z25, Z30, Z16, Z19, Z12)
	ADD(Z28, Z31, Z16, Z20, Z14)
	ADD(Z0, Z4, Z16, Z26, Z21)
	ADD(Z1, Z5, Z16, Z27, Z22)
	ADD(Z2, Z6, Z16, Z19, Z23)
	ADD(Z3, Z7, Z16, Z20, Z24)
	ADD(Z8, Z21, Z16, Z25, Z21)
	ADD(Z9, Z22, Z16, Z28, Z22)
	ADD(Z10, Z23, Z16, Z29, Z23)
	ADD(Z11, Z24, Z16, Z30, Z24)
	ADD(Z12, Z21, Z16, Z31, Z21)
	ADD(Z13, Z22, Z16, Z26, Z22)
	ADD(Z14, Z23, Z16, Z27, Z23)
	ADD(Z15, Z24, Z16, Z19, Z24)
	ADD(Z0, Z21, Z16, Z20, Z0)
	ADD(Z1, Z22, Z16, Z25, Z1)
	ADD(Z2, Z23, Z16, Z28, Z2)
	ADD(Z3, Z24, Z16, Z29, Z3)
	ADD(Z4, Z21, Z16, Z30, Z4)
	ADD(Z5, Z22, Z16, Z31, Z5)
	ADD(Z6, Z23, Z16, Z26, Z6)
	ADD(Z7, Z24, Z16, Z27, Z7)
	ADD(Z8, Z21, Z16, Z19, Z8)
	ADD(Z9, Z22, Z16, Z20, Z9)
	ADD(Z10, Z23, Z16, Z25, Z10)
	ADD(Z11, Z24, Z16, Z28, Z11)
	ADD(Z12, Z21, Z16, Z29, Z12)
	ADD(Z13, Z22, Z16, Z30, Z13)
	ADD(Z14, Z23, Z16, Z31, Z14)
	ADD(Z15, Z24, Z16, Z26, Z15)
	ADDQ         $24, CX
	JMP          loop_13

done_14:
	// loop over the partial rounds
	MOVQ $0x0000000000000015, R10

loop_15:
	TESTQ        R10, R10
	JEQ          done_16
	DECQ         R10
	MOVQ         0(CX), BX
	VPBROADCASTD 0(BX), Z27
	ADD(Z0, Z27, Z16, Z19, Z0)
	MUL_5W(Z0, Z0, Z25, Z28, Z29, Z30, Z31, Z20, Z16, Z17)
	MUL_5W(Z0, Z20, Z26, Z21, Z22, Z23, Z24, Z0, Z16, Z17)
	REDUCE1Q(Z16, Z0, Z19)
	ADD(Z0, Z1, Z16, Z31, Z28)
	ADD(Z2, Z3, Z16, Z26, Z29)
	ADD(Z4, Z5, Z16, Z21, Z30)
	ADD(Z6, Z7, Z16, Z22, Z27)
	ADD(Z8, Z28, Z16, Z23, Z28)
	ADD(Z9, Z29, Z16, Z24, Z29)
	ADD(Z10, Z30, Z16, Z19, Z30)
	ADD(Z11, Z27, Z16, Z20, Z27)
	ADD(Z12, Z28, Z16, Z31, Z28)
	ADD(Z13, Z29, Z16, Z26, Z29)
	ADD(Z14, Z30, Z16, Z21, Z30)
	ADD(Z15, Z27, Z16, Z22, Z27)
	ADD(Z28, Z29, Z16, Z23, Z28)
	ADD(Z30, Z27, Z16, Z24, Z30)
	ADD(Z28, Z30, Z16, Z19, Z27)
	DOUBLE(Z0, Z16, Z20, Z0)
	DOUBLE(Z2, Z16, Z31, Z2)
	HALVE(Z3, Z26, Z16)
	DOUBLE(Z4, Z16, Z21, Z28)
	ADD(Z4, Z28, Z16, Z22, Z4)
	DOUBLE(Z5, Z16, Z23, Z5)
	DOUBLE(Z5, Z16, Z24, Z5)
	HALVE(Z6, Z19, Z16)
	DOUBLE(Z7, Z16, Z20, Z25)
	ADD(Z7, Z25, Z16, Z31, Z7)
	DOUBLE(Z8, Z16, Z26, Z8)
	DOUBLE(Z8, Z16, Z21, Z8)
	MUL_2_EXP_NEG_N(Z9, Z9, $8, $24, Z22, Z23, Z24, Z19, Z20, Z16, Z17)
	MUL_2_EXP_NEG_N(Z10, Z10, $3, $29, Z31, Z26, Z21, Z25, Z28, Z16, Z17)
	MUL_2_EXP_NEG_N(Z11, Z11, $24, $8, Z29, Z30, Z22, Z23, Z24, Z16, Z17)
	MUL_2_EXP_NEG_N(Z12, Z12, $8, $24, Z19, Z20, Z31, Z26, Z21, Z16, Z17)
	MUL_2_EXP_NEG_N(Z13, Z13, $3, $29, Z25, Z28, Z29, Z30, Z22, Z16, Z17)
	MUL_2_EXP_NEG_N(Z14, Z14, $4, $28, Z23, Z24, Z19, Z20, Z31, Z16, Z17)
	MUL_2_EXP_NEG_N(Z15, Z15, $24, $8, Z26, Z21, Z25, Z28, Z29, Z16, Z17)
	SUB(Z27, Z0, Z16, Z30, Z0)
	ADD(Z27, Z1, Z16, Z22, Z1)
	ADD(Z2, Z27, Z16, Z23, Z2)
	ADD(Z3, Z27, Z16, Z24, Z3)
	ADD(Z4, Z27, Z16, Z19, Z4)
	ADD(Z5, Z27, Z16, Z20, Z5)
	SUB(Z27, Z6, Z16, Z31, Z6)
	SUB(Z27, Z7, Z16, Z26, Z7)
	SUB(Z27, Z8, Z16, Z21, Z8)
	ADD(Z9, Z27, Z16, Z25, Z9)
	ADD(Z10, Z27, Z16, Z28, Z10)
	ADD(Z11, Z27, Z16, Z29, Z11)
	SUB(Z27, Z12, Z16, Z30, Z12)
	SUB(Z27, Z13, Z16, Z22, Z13)
	SUB(Z27, Z14, Z16, Z23, Z14)
	SUB(Z27, Z15, Z16, Z24, Z15)
	ADDQ         $24, CX
	JMP          loop_15

done_16:
	// loop over the final full rounds
	MOVQ $0x0000000000000003, R11

loop_17:
	TESTQ        R11, R11
	JEQ          done_18
	DECQ         R11
	MOVQ         0(CX), BX
	VPBROADCASTD 0(BX), Z19
	ADD(Z0, Z19, Z16, Z20, Z0)
	MUL_5W(Z0, Z0, Z26, Z21, Z25, Z28, Z29, Z31, Z16, Z17)
	MUL_5W(Z0, Z31, Z30, Z22, Z23, Z24, Z27, Z0, Z16, Z17)
	REDUCE1Q(Z16, Z0, Z20)
	VPBROADCASTD 4(BX), Z19
	ADD(Z1, Z19, Z16, Z26, Z1)
	MUL_5W(Z1, Z1, Z25, Z28, Z29, Z30, Z22, Z21, Z16, Z17)
	MUL_5W(Z1, Z21, Z23, Z24, Z27, Z20, Z31, Z1, Z16, Z17)
	REDUCE1Q(Z16, Z1, Z26)
	VPBROADCASTD 8(BX), Z19
	ADD(Z2, Z19, Z16, Z25, Z2)
	MUL_5W(Z2, Z2, Z29, Z30, Z22, Z23, Z24, Z28, Z16, Z17)
	MUL_5W(Z2, Z28, Z27, Z20, Z31, Z26, Z21, Z2, Z16, Z17)
	REDUCE1Q(Z16, Z2, Z25)
	VPBROADCASTD 12(BX), Z19
	ADD(Z3, Z19, Z16, Z29, Z3)
	MUL_5W(Z3, Z3, Z22, Z23, Z24, Z27, Z20, Z30, Z16, Z17)
	MUL_5W(Z3, Z30, Z31, Z26, Z21, Z25, Z28, Z3, Z16, Z17)
	REDUCE1Q(Z16, Z3, Z29)
	VPBROADCASTD 16(BX), Z19
	ADD(Z4, Z19, Z16, Z22, Z4)
	MUL_5W(Z4, Z4, Z24, Z27, Z20, Z31, Z26, Z23, Z16, Z17)
	MUL_5W(Z4, Z23, Z21, Z25, Z28, Z29, Z30, Z4, Z16, Z17)
	REDUCE1Q(Z16, Z4, Z22)
	VPBROADCASTD 20(BX), Z19
	ADD(Z5, Z19, Z16, Z24, Z5)
	MUL_5W(Z5, Z5, Z20, Z31, Z26, Z21, Z25, Z27, Z16, Z17)
	MUL_5W(Z5, Z27, Z28, Z29, Z30, Z22, Z23, Z5, Z16, Z17)
	REDUCE1Q(Z16, Z5, Z24)
	VPBROADCASTD 24(BX), Z19
	ADD(Z6, Z19, Z16, Z20, Z6)
	MUL_5W(Z6, Z6, Z26, Z21, Z25, Z28, Z29, Z31, Z16, Z17)
	MUL_5W(Z6, Z31, Z30, Z22, Z23, Z24, Z27, Z6, Z16, Z17)
	REDUCE1Q(Z16, Z6, Z20)
	VPBROADCASTD 28(BX), Z19
	ADD(Z7, Z19, Z16, Z26, Z7)
	MUL_5W(Z7, Z7, Z25, Z28, Z29, Z30, Z22, Z21, Z16, Z17)
	MUL_5W(Z7, Z21, Z23, Z24, Z27, Z20, Z31, Z7, Z16, Z17)
	REDUCE1Q(Z16, Z7, Z26)
	VPBROADCASTD 32(BX), Z19
	ADD(Z8, Z19, Z16, Z25, Z8)
	MUL_5W(Z8, Z8, Z29, Z30, Z22, Z23, Z24, Z28, Z16, Z17)
	MUL_5W(Z8, Z28, Z27, Z20, Z31, Z26, Z21, Z8, Z16, Z17)
	REDUCE1Q(Z16, Z8, Z25)
	VPBROADCASTD 36(BX), Z19
	ADD(Z9, Z19, Z16, Z29, Z9)
	MUL_5W(Z9, Z9, Z22, Z23, Z24, Z27, Z20, Z30, Z16, Z17)
	MUL_5W(Z9, Z30, Z31, Z26, Z21, Z25, Z28, Z9, Z16, Z17)
	REDUCE1Q(Z16, Z9, Z29)
	VPBROADCASTD 40(BX), Z19
	ADD(Z10, Z19, Z16, Z22, Z10)
	MUL_5W(Z10, Z10, Z24, Z27, Z20, Z31, Z26, Z23, Z16, Z17)
	MUL_5W(Z10, Z23, Z21, Z25, Z28, Z29, Z30, Z10, Z16, Z17)
	REDUCE1Q(Z16, Z10, Z22)
	VPBROADCASTD 44(BX), Z19
	ADD(Z11, Z19, Z16, Z24, Z11)
	MUL_5W(Z11, Z11, Z20, Z31, Z26, Z21, Z25, Z27, Z16, Z17)
	MUL_5W(Z11, Z27, Z28, Z29, Z30, Z22, Z23, Z11, Z16, Z17)
	REDUCE1Q(Z16, Z11, Z24)
	VPBROADCASTD 48(BX), Z19
	ADD(Z12, Z19, Z16, Z20, Z12)
	MUL_5W(Z12, Z12, Z26, Z21, Z25, Z28, Z29, Z31, Z16, Z17)
	MUL_5W(Z12, Z31, Z30, Z22, Z23, Z24, Z27, Z12, Z16, Z17)
	REDUCE1Q(Z16, Z12, Z20)
	VPBROADCASTD 52(BX), Z19
	ADD(Z13, Z19, Z16, Z26, Z13)
	MUL_5W(Z13, Z13, Z25, Z28, Z29, Z30, Z22, Z21, Z16, Z17)
	MUL_5W(Z13, Z21, Z23, Z24, Z27, Z20, Z31, Z13, Z16, Z17)
	REDUCE1Q(Z16, Z13, Z26)
	VPBROADCASTD 56(BX), Z19
	ADD(Z14, Z19, Z16, Z25, Z14)
	MUL_5W(Z14, Z14, Z29, Z30, Z22, Z23, Z24, Z28, Z16, Z17)
	MUL_5W(Z14, Z28, Z27, Z20, Z31, Z26, Z21, Z14, Z16, Z17)
	REDUCE1Q(Z16, Z14, Z25)
	VPBROADCASTD 60(BX), Z19
	ADD(Z15, Z19, Z16, Z29, Z15)
	MUL_5W(Z15, Z15, Z22, Z23, Z24, Z27, Z20, Z30, Z16, Z17)
	MUL_5W(Z15, Z30, Z31, Z26, Z21, Z25, Z28, Z15, Z16, Z17)
	REDUCE1Q(Z16, Z15, Z29)
	ADD(Z0, Z1, Z16, Z20, Z19)
	ADD(Z2, Z3, Z16, Z31, Z22)
	ADD(Z19, Z22, Z16, Z26, Z23)
	ADD(Z23, Z1, Z16, Z21, Z24)
	ADD(Z23, Z3, Z16, Z25, Z27)
	DOUBLE(Z0, Z16, Z28, Z3)
	ADD(Z3, Z27, Z16, Z29, Z3)
	DOUBLE(Z2, Z16, Z30, Z1)
	ADD(Z1, Z24, Z16, Z20, Z1)
	ADD(Z19, Z24, Z16, Z31, Z0)
	ADD(Z22, Z27, Z16, Z26, Z2)
	ADD(Z4, Z5, Z16, Z21, Z19)
	ADD(Z6, Z7, Z16, Z25, Z22)
	ADD(Z19, Z22, Z16, Z28, Z23)
	ADD(Z23, Z5, Z16, Z29, Z24)
	ADD(Z23, Z7, Z16, Z30, Z27)
	DOUBLE(Z4, Z16, Z20, Z7)
	ADD(Z7, Z27, Z16, Z31, Z7)
	DOUBLE(Z6, Z16, Z26, Z5)
	ADD(Z5, Z24, Z16, Z21, Z5)
	ADD(Z19, Z24, Z16, Z25, Z4)
	ADD(Z22, Z27, Z16, Z28, Z6)
	ADD(Z8, Z9, Z16, Z29, Z19)
	ADD(Z10, Z11, Z16, Z30, Z22)
	ADD(Z19, Z22, Z16, Z20, Z23)
	ADD(Z23, Z9, Z16, Z31, Z24)
	ADD(Z23, Z11, Z16, Z26, Z27)
	DOUBLE(Z8, Z16, Z21, Z11)
	ADD(Z11, Z27, Z16, Z25, Z11)
	DOUBLE(Z10, Z16, Z28, Z9)
	ADD(Z9, Z24, Z16, Z29, Z9)
	ADD(Z19, Z24, Z16, Z30, Z8)
	ADD(Z22, Z27, Z16, Z20, Z10)
	ADD(Z12, Z13, Z16, Z31, Z19)
	ADD(Z14, Z15, Z16, Z26, Z22)
	ADD(Z19, Z22, Z16, Z21, Z23)
	ADD(Z23, Z13, Z16, Z25, Z24)
	ADD(Z23, Z15, Z16, Z28, Z27)
	DOUBLE(Z12, Z16, Z29, Z15)
	ADD(Z15, Z27, Z16, Z30, Z15)
	DOUBLE(Z14, Z16, Z20, Z13)
	ADD(Z13, Z24, Z16, Z31, Z13)
	ADD(Z19, Z24, Z16, Z26, Z12)
	ADD(Z22, Z27, Z16, Z21, Z14)
	ADD(Z0, Z4, Z16, Z20, Z25)
	ADD(Z1, Z5, Z16, Z31, Z28)
	ADD(Z2, Z6, Z16, Z26, Z29)
	ADD(Z3, Z7, Z16, Z21, Z30)
	ADD(Z8, Z25, Z16, Z19, Z25)
	ADD(Z9, Z28, Z16, Z22, Z28)
	ADD(Z10, Z29, Z16, Z23, Z29)
	ADD(Z11, Z30, Z16, Z24, Z30)
	ADD(Z12, Z25, Z16, Z27, Z25)
	ADD(Z13, Z28, Z16, Z20, Z28)
	ADD(Z14, Z29, Z16, Z31, Z29)
	ADD(Z15, Z30, Z16, Z26, Z30)
	ADD(Z0, Z25, Z16, Z21, Z0)
	ADD(Z1, Z28, Z16, Z19, Z1)
	ADD(Z2, Z29, Z16, Z22, Z2)
	ADD(Z3, Z30, Z16, Z23, Z3)
	ADD(Z4, Z25, Z16, Z24, Z4)
	ADD(Z5, Z28, Z16, Z27, Z5)
	ADD(Z6, Z29, Z16, Z20, Z6)
	ADD(Z7, Z30, Z16, Z31, Z7)
	ADD(Z8, Z25, Z16, Z26, Z8)
	ADD(Z9, Z28, Z16, Z21, Z9)
	ADD(Z10, Z29, Z16, Z19, Z10)
	ADD(Z11, Z30, Z16, Z22, Z11)
	ADD(Z12, Z25, Z16, Z23, Z12)
	ADD(Z13, Z28, Z16, Z24, Z13)
	ADD(Z14, Z29, Z16, Z27, Z14)
	ADD(Z15, Z30, Z16, Z20, Z15)
	ADDQ         $24, CX
	JMP          loop_17

done_18:
	KMOVD      DI, K1
	VPGATHERDD 0(R14)(Z18*4), K1, Z0
	ADD(Z0, Z8, Z16, Z31, Z0)
	KMOVD      DI, K1
	VPGATHERDD 4(R14)(Z18*4), K1, Z1
	ADD(Z1, Z9, Z16, Z26, Z1)
	KMOVD      DI, K1
	VPGATHERDD 8(R14)(Z18*4), K1, Z2
	ADD(Z2, Z10, Z16, Z21, Z2)
	KMOVD      DI, K1
	VPGATHERDD 12(R14)(Z18*4), K1, Z3
	ADD(Z3, Z11, Z16, Z19, Z3)
	KMOVD      DI, K1
	VPGATHERDD 16(R14)(Z18*4), K1, Z4
	ADD(Z4, Z12, Z16, Z22, Z4)
	KMOVD      DI, K1
	VPGATHERDD 20(R14)(Z18*4), K1, Z5
	ADD(Z5, Z13, Z16, Z23, Z5)
	KMOVD      DI, K1
	VPGATHERDD 24(R14)(Z18*4), K1, Z6
	ADD(Z6, Z14, Z16, Z24, Z6)
	KMOVD      DI, K1
	VPGATHERDD 28(R14)(Z18*4), K1, Z7
	ADD(Z7, Z15, Z16, Z27, Z7)
	ADDQ       $0x0000000000000020, R14
	MOVQ       roundKeys+8(FP), CX
	JMP        loop_11

done_12:
	MOVQ        ·indexScatter8+0(SB), R8
	VMOVDQU32   0(R8), Z18
	KMOVD       DI, K1
	VPSCATTERDD Z0, K1, 0(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z1, K1, 4(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z2, K1, 8(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z3, K1, 12(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z4, K1, 16(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z5, K1, 20(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z6, K1, 24(R13)(Z18*4)
	KMOVD       DI, K1
	VPSCATTERDD Z7, K1, 28(R13)(Z18*4)
	RET
