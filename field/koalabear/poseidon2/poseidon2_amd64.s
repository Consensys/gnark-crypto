//go:build !purego

// Code generated by gnark-crypto/generator. DO NOT EDIT.
// Refer to the generator for more documentation.

#include "textflag.h"
#include "funcdata.h"
#include "go_asm.h"

TEXT ·permutation24_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R15
	MOVQ         roundKeys+24(FP), R14
	VMOVDQU32    0(R15), Z2
	VMOVDQU32    64(R15), Y3
	MOVQ         ·diag24+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VMOVDQU32    64(CX), Y20
	VPSRLQ       $32, Z18, Z19
	VPSRLQ       $32, Y20, Y21

#define ADD(in0, in1, in2, in3, in4) \
	VPADDD  in0, in1, in4 \
	VPSUBD  in2, in4, in3 \
	VPMINUD in4, in3, in4 \

#define MAT_MUL_M4(in0, in1, in2, in3, in4, in5) \
	VPSHUFD $0x000000000000004e, in0, in1 \
	ADD(in1, in0, in4, in5, in1)          \
	VPSHUFD $0x00000000000000b1, in1, in2 \
	ADD(in1, in2, in4, in5, in1)          \
	VPSHUFD $0x0000000000000039, in0, in3 \
	VPSLLD  $1, in3, in3                  \
	VPSUBD  in4, in3, in5                 \
	VPMINUD in3, in5, in3                 \
	ADD(in0, in1, in4, in5, in0)          \
	ADD(in0, in3, in4, in5, in0)          \

#define MAT_MUL_EXTERNAL() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	MAT_MUL_M4(Y3, Y6, Y7, Y8, Y0, Y11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	ADD(Y16, Y3, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Y3, Y16, Y0, Y9, Y3)            \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define MULD(in0, in1, in2, in3, in4, in5, in6, in7, in8, in9, in10) \
	VPSRLQ    $32, in0, in2  \
	VPSRLQ    $32, in1, in3  \
	VPMULUDQ  in0, in1, in4  \
	VPMULUDQ  in2, in3, in5  \
	VPMULUDQ  in4, in9, in6  \
	VPMULUDQ  in5, in9, in7  \
	VPMULUDQ  in6, in8, in6  \
	VPADDQ    in4, in6, in4  \
	VPMULUDQ  in7, in8, in7  \
	VPADDQ    in5, in7, in10 \
	VMOVSHDUP in4, K3, in10  \

#define REDUCE1Q(in0, in1, in2) \
	VPSUBD  in0, in1, in2 \
	VPMINUD in1, in2, in1 \

#define SBOX_FULL() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \
	MULD(Y3, Y3, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y7) \
	MULD(Y3, Y7, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y3) \
	REDUCE1Q(Y0, Y3, Y15)                                \

#define SBOX_PARTIAL() \
	VPMULUDQ X5, X5, X6   \
	VPMULUDQ X6, X1, X14  \
	VPMULUDQ X14, X0, X14 \
	VPADDQ   X6, X14, X6  \
	VPSRLQ   $32, X6, X8  \
	VPMULUDQ X5, X8, X6   \
	VPMULUDQ X6, X1, X14  \
	VPMULUDQ X14, X0, X14 \
	VPADDQ   X6, X14, X6  \
	VPSRLQ   $32, X6, X5  \
	VPSUBD   X0, X5, X14  \
	VPMINUD  X5, X14, X5  \

#define SUM_STATE() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y3, Y0, Y11, Y16)                  \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND() \
	VMOVDQU32 0(BX), Z4      \
	VMOVDQU32 64(BX), Y5     \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	ADD(Y3, Y5, Y0, Y8, Y3)  \
	SBOX_FULL()              \
	MAT_MUL_EXTERNAL()       \

	MAT_MUL_EXTERNAL()
	MOVQ 0(R14), BX
	FULL_ROUND()
	MOVQ 24(R14), BX
	FULL_ROUND()
	MOVQ 48(R14), BX
	FULL_ROUND()

	// loop over the partial rounds
	MOVQ $0x0000000000000015, SI // nb partial rounds --> 21
	MOVQ R14, DI
	ADDQ $0x0000000000000048, DI

loop_1:
	TESTQ     SI, SI
	JEQ       done_2
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Y3, Y12
	VPMULUDQ  Y3, Y20, Y6
	VPMULUDQ  Y12, Y21, Y7
	VPMULUDQ  Y6, Y1, Y14
	VPMULUDQ  Y7, Y1, Y15
	VPMULUDQ  Y14, Y0, Y14
	VPADDQ    Y6, Y14, Y6
	VPMULUDQ  Y15, Y0, Y15
	VPADDQ    Y7, Y15, Y9
	VMOVSHDUP Y6, K3, Y9
	VPSUBD    Y0, Y9, Y11
	VPMINUD   Y9, Y11, Y9
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADD(Y9, Y16, Y0, Y5, Y3)
	ADDQ      $24, DI
	JMP       loop_1

done_2:
	MOVQ      576(R14), BX
	FULL_ROUND()
	MOVQ      600(R14), BX
	FULL_ROUND()
	MOVQ      624(R14), BX
	FULL_ROUND()
	VMOVDQU32 Z2, 0(R15)
	VMOVDQU32 Y3, 64(R15)
	RET

TEXT ·permutation16x24_avx512(SB), NOSPLIT, $0-48
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z24
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z25
	MOVQ         $0xffffffffffffffff, R14
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         ·indexScatter8+0(SB), DI
	MOVQ         ·indexGather512+0(SB), R8
	MOVQ         input+0(FP), R15
	MOVQ         nbBlocks+8(FP), CX
	MOVQ         res+16(FP), BX
	MOVQ         roundKeys+24(FP), SI
	VXORPS       Z0, Z0, Z0
	VXORPS       Z1, Z1, Z1
	VXORPS       Z2, Z2, Z2
	VXORPS       Z3, Z3, Z3
	VXORPS       Z4, Z4, Z4
	VXORPS       Z5, Z5, Z5
	VXORPS       Z6, Z6, Z6
	VXORPS       Z7, Z7, Z7

#define DOUBLE(in0, in1, in2, in3) \
	VPSLLD  $1, in0, in3  \
	VPSUBD  in1, in3, in2 \
	VPMINUD in3, in2, in3 \

#define SUB(in0, in1, in2, in3, in4) \
	VPSUBD  in1, in0, in4 \
	VPADDD  in2, in4, in3 \
	VPMINUD in4, in3, in4 \

#define MUL_W(in0, in1, in2, in3, in4, in5, in6, in7) \
	VPSRLQ    $32, in0, in2 \
	VPSRLQ    $32, in1, in3 \
	VPMULUDQ  in0, in1, in4 \
	VPMULUDQ  in2, in3, in5 \
	VPMULUDQ  in4, Z25, in6 \
	VPMULUDQ  in5, Z25, in3 \
	VPMULUDQ  in6, Z24, in6 \
	VPADDQ    in4, in6, in4 \
	VPMULUDQ  in3, Z24, in3 \
	VPADDQ    in5, in3, in7 \
	VMOVSHDUP in4, K3, in7  \

#define MUL2EXPNEGN(in0, in1, in2, in3, in4, in5, in6, in7, in8) \
	VPSRLQ    $32, in0, in5 \
	VPSLLQ    $32, in0, in0 \
	VPSRLQ    in3, in0, in1 \
	VPSLLQ    in4, in5, in6 \
	VPMULUDQ  in1, Z25, in7 \
	VPMULUDQ  in6, Z25, in8 \
	VPMULUDQ  in7, Z24, in7 \
	VPADDQ    in1, in7, in1 \
	VPMULUDQ  in8, Z24, in8 \
	VPADDQ    in6, in8, in2 \
	VMOVSHDUP in1, K3, in2  \
	REDUCE1Q(Z24, in2, in1) \

#define MAT_MUL_4_W(in0, in1, in2, in3, in4, in5) \
ADD(Z0, Z1, Z24, in5, in0)   \
ADD(in0, Z2, Z24, in5, in0)  \
ADD(in0, Z3, Z24, in5, in0)  \
DOUBLE(Z0, Z24, in5, in1)    \
DOUBLE(Z1, Z24, in5, in2)    \
DOUBLE(Z2, Z24, in5, in3)    \
DOUBLE(Z3, Z24, in5, in4)    \
ADD(Z0, in0, Z24, in5, Z0)   \
ADD(Z0, in2, Z24, in5, Z0)   \
ADD(Z1, in0, Z24, in5, Z1)   \
ADD(Z1, in3, Z24, in5, Z1)   \
ADD(Z2, in0, Z24, in5, Z2)   \
ADD(Z2, in4, Z24, in5, Z2)   \
ADD(Z3, in0, Z24, in5, Z3)   \
ADD(Z3, in1, Z24, in5, Z3)   \
ADD(Z4, Z5, Z24, in5, in0)   \
ADD(in0, Z6, Z24, in5, in0)  \
ADD(in0, Z7, Z24, in5, in0)  \
DOUBLE(Z4, Z24, in5, in1)    \
DOUBLE(Z5, Z24, in5, in2)    \
DOUBLE(Z6, Z24, in5, in3)    \
DOUBLE(Z7, Z24, in5, in4)    \
ADD(Z4, in0, Z24, in5, Z4)   \
ADD(Z4, in2, Z24, in5, Z4)   \
ADD(Z5, in0, Z24, in5, Z5)   \
ADD(Z5, in3, Z24, in5, Z5)   \
ADD(Z6, in0, Z24, in5, Z6)   \
ADD(Z6, in4, Z24, in5, Z6)   \
ADD(Z7, in0, Z24, in5, Z7)   \
ADD(Z7, in1, Z24, in5, Z7)   \
ADD(Z8, Z9, Z24, in5, in0)   \
ADD(in0, Z10, Z24, in5, in0) \
ADD(in0, Z11, Z24, in5, in0) \
DOUBLE(Z8, Z24, in5, in1)    \
DOUBLE(Z9, Z24, in5, in2)    \
DOUBLE(Z10, Z24, in5, in3)   \
DOUBLE(Z11, Z24, in5, in4)   \
ADD(Z8, in0, Z24, in5, Z8)   \
ADD(Z8, in2, Z24, in5, Z8)   \
ADD(Z9, in0, Z24, in5, Z9)   \
ADD(Z9, in3, Z24, in5, Z9)   \
ADD(Z10, in0, Z24, in5, Z10) \
ADD(Z10, in4, Z24, in5, Z10) \
ADD(Z11, in0, Z24, in5, Z11) \
ADD(Z11, in1, Z24, in5, Z11) \
ADD(Z12, Z13, Z24, in5, in0) \
ADD(in0, Z14, Z24, in5, in0) \
ADD(in0, Z15, Z24, in5, in0) \
DOUBLE(Z12, Z24, in5, in1)   \
DOUBLE(Z13, Z24, in5, in2)   \
DOUBLE(Z14, Z24, in5, in3)   \
DOUBLE(Z15, Z24, in5, in4)   \
ADD(Z12, in0, Z24, in5, Z12) \
ADD(Z12, in2, Z24, in5, Z12) \
ADD(Z13, in0, Z24, in5, Z13) \
ADD(Z13, in3, Z24, in5, Z13) \
ADD(Z14, in0, Z24, in5, Z14) \
ADD(Z14, in4, Z24, in5, Z14) \
ADD(Z15, in0, Z24, in5, Z15) \
ADD(Z15, in1, Z24, in5, Z15) \
ADD(Z16, Z17, Z24, in5, in0) \
ADD(in0, Z18, Z24, in5, in0) \
ADD(in0, Z19, Z24, in5, in0) \
DOUBLE(Z16, Z24, in5, in1)   \
DOUBLE(Z17, Z24, in5, in2)   \
DOUBLE(Z18, Z24, in5, in3)   \
DOUBLE(Z19, Z24, in5, in4)   \
ADD(Z16, in0, Z24, in5, Z16) \
ADD(Z16, in2, Z24, in5, Z16) \
ADD(Z17, in0, Z24, in5, Z17) \
ADD(Z17, in3, Z24, in5, Z17) \
ADD(Z18, in0, Z24, in5, Z18) \
ADD(Z18, in4, Z24, in5, Z18) \
ADD(Z19, in0, Z24, in5, Z19) \
ADD(Z19, in1, Z24, in5, Z19) \
ADD(Z20, Z21, Z24, in5, in0) \
ADD(in0, Z22, Z24, in5, in0) \
ADD(in0, Z23, Z24, in5, in0) \
DOUBLE(Z20, Z24, in5, in1)   \
DOUBLE(Z21, Z24, in5, in2)   \
DOUBLE(Z22, Z24, in5, in3)   \
DOUBLE(Z23, Z24, in5, in4)   \
ADD(Z20, in0, Z24, in5, Z20) \
ADD(Z20, in2, Z24, in5, Z20) \
ADD(Z21, in0, Z24, in5, Z21) \
ADD(Z21, in3, Z24, in5, Z21) \
ADD(Z22, in0, Z24, in5, Z22) \
ADD(Z22, in4, Z24, in5, Z22) \
ADD(Z23, in0, Z24, in5, Z23) \
ADD(Z23, in1, Z24, in5, Z23) \

#define MAT_MUL_EXTERNAL_W(in0, in1, in2, in3, in4, in5) \
MAT_MUL_4_W(in0, in1, in2, in3, in4, in5) \
ADD(Z0, Z4, Z24, in5, in1)                \
ADD(Z1, Z5, Z24, in5, in2)                \
ADD(Z2, Z6, Z24, in5, in3)                \
ADD(Z3, Z7, Z24, in5, in4)                \
ADD(Z8, in1, Z24, in5, in1)               \
ADD(Z9, in2, Z24, in5, in2)               \
ADD(Z10, in3, Z24, in5, in3)              \
ADD(Z11, in4, Z24, in5, in4)              \
ADD(Z12, in1, Z24, in5, in1)              \
ADD(Z13, in2, Z24, in5, in2)              \
ADD(Z14, in3, Z24, in5, in3)              \
ADD(Z15, in4, Z24, in5, in4)              \
ADD(Z16, in1, Z24, in5, in1)              \
ADD(Z17, in2, Z24, in5, in2)              \
ADD(Z18, in3, Z24, in5, in3)              \
ADD(Z19, in4, Z24, in5, in4)              \
ADD(Z20, in1, Z24, in5, in1)              \
ADD(Z21, in2, Z24, in5, in2)              \
ADD(Z22, in3, Z24, in5, in3)              \
ADD(Z23, in4, Z24, in5, in4)              \
ADD(Z0, in1, Z24, in5, Z0)                \
ADD(Z1, in2, Z24, in5, Z1)                \
ADD(Z2, in3, Z24, in5, Z2)                \
ADD(Z3, in4, Z24, in5, Z3)                \
ADD(Z4, in1, Z24, in5, Z4)                \
ADD(Z5, in2, Z24, in5, Z5)                \
ADD(Z6, in3, Z24, in5, Z6)                \
ADD(Z7, in4, Z24, in5, Z7)                \
ADD(Z8, in1, Z24, in5, Z8)                \
ADD(Z9, in2, Z24, in5, Z9)                \
ADD(Z10, in3, Z24, in5, Z10)              \
ADD(Z11, in4, Z24, in5, Z11)              \
ADD(Z12, in1, Z24, in5, Z12)              \
ADD(Z13, in2, Z24, in5, Z13)              \
ADD(Z14, in3, Z24, in5, Z14)              \
ADD(Z15, in4, Z24, in5, Z15)              \
ADD(Z16, in1, Z24, in5, Z16)              \
ADD(Z17, in2, Z24, in5, Z17)              \
ADD(Z18, in3, Z24, in5, Z18)              \
ADD(Z19, in4, Z24, in5, Z19)              \
ADD(Z20, in1, Z24, in5, Z20)              \
ADD(Z21, in2, Z24, in5, Z21)              \
ADD(Z22, in3, Z24, in5, Z22)              \
ADD(Z23, in4, Z24, in5, Z23)              \

outer_loop_3:
	TESTQ        CX, CX
	JEQ          outer_loop_end_4
	VMOVDQU32    0(R8), Z26
	KMOVD        R14, K1
	VPGATHERDD   0(R15)(Z26*4), K1, Z8
	KMOVD        R14, K1
	VPGATHERDD   4(R15)(Z26*4), K1, Z9
	KMOVD        R14, K1
	VPGATHERDD   8(R15)(Z26*4), K1, Z10
	KMOVD        R14, K1
	VPGATHERDD   12(R15)(Z26*4), K1, Z11
	KMOVD        R14, K1
	VPGATHERDD   16(R15)(Z26*4), K1, Z12
	KMOVD        R14, K1
	VPGATHERDD   20(R15)(Z26*4), K1, Z13
	KMOVD        R14, K1
	VPGATHERDD   24(R15)(Z26*4), K1, Z14
	KMOVD        R14, K1
	VPGATHERDD   28(R15)(Z26*4), K1, Z15
	KMOVD        R14, K1
	VPGATHERDD   32(R15)(Z26*4), K1, Z16
	KMOVD        R14, K1
	VPGATHERDD   36(R15)(Z26*4), K1, Z17
	KMOVD        R14, K1
	VPGATHERDD   40(R15)(Z26*4), K1, Z18
	KMOVD        R14, K1
	VPGATHERDD   44(R15)(Z26*4), K1, Z19
	KMOVD        R14, K1
	VPGATHERDD   48(R15)(Z26*4), K1, Z20
	KMOVD        R14, K1
	VPGATHERDD   52(R15)(Z26*4), K1, Z21
	KMOVD        R14, K1
	VPGATHERDD   56(R15)(Z26*4), K1, Z22
	KMOVD        R14, K1
	VPGATHERDD   60(R15)(Z26*4), K1, Z23
	ADDQ         $0x0000000000000040, R15
	MAT_MUL_EXTERNAL_W(Z27, Z28, Z29, Z30, Z31, Z26)
	MOVQ         0(SI), R9
	VPBROADCASTD 0(R9), Z27
	ADD(Z0, Z27, Z24, Z27, Z0)
	MUL_W(Z0, Z0, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z0, Z28, Z29, Z30, Z31, Z26, Z27, Z0)
	REDUCE1Q(Z24, Z0, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 4(R9), Z29
	ADD(Z1, Z29, Z24, Z29, Z1)
	MUL_W(Z1, Z1, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z1, Z30, Z31, Z26, Z27, Z28, Z29, Z1)
	REDUCE1Q(Z24, Z1, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 8(R9), Z31
	ADD(Z2, Z31, Z24, Z31, Z2)
	MUL_W(Z2, Z2, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z2, Z26, Z27, Z28, Z29, Z30, Z31, Z2)
	REDUCE1Q(Z24, Z2, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 12(R9), Z27
	ADD(Z3, Z27, Z24, Z27, Z3)
	MUL_W(Z3, Z3, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z3, Z28, Z29, Z30, Z31, Z26, Z27, Z3)
	REDUCE1Q(Z24, Z3, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 16(R9), Z29
	ADD(Z4, Z29, Z24, Z29, Z4)
	MUL_W(Z4, Z4, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z4, Z30, Z31, Z26, Z27, Z28, Z29, Z4)
	REDUCE1Q(Z24, Z4, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 20(R9), Z31
	ADD(Z5, Z31, Z24, Z31, Z5)
	MUL_W(Z5, Z5, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z5, Z26, Z27, Z28, Z29, Z30, Z31, Z5)
	REDUCE1Q(Z24, Z5, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 24(R9), Z27
	ADD(Z6, Z27, Z24, Z27, Z6)
	MUL_W(Z6, Z6, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z6, Z28, Z29, Z30, Z31, Z26, Z27, Z6)
	REDUCE1Q(Z24, Z6, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 28(R9), Z29
	ADD(Z7, Z29, Z24, Z29, Z7)
	MUL_W(Z7, Z7, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z7, Z30, Z31, Z26, Z27, Z28, Z29, Z7)
	REDUCE1Q(Z24, Z7, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 32(R9), Z31
	ADD(Z8, Z31, Z24, Z31, Z8)
	MUL_W(Z8, Z8, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z8, Z26, Z27, Z28, Z29, Z30, Z31, Z8)
	REDUCE1Q(Z24, Z8, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 36(R9), Z27
	ADD(Z9, Z27, Z24, Z27, Z9)
	MUL_W(Z9, Z9, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z9, Z28, Z29, Z30, Z31, Z26, Z27, Z9)
	REDUCE1Q(Z24, Z9, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 40(R9), Z29
	ADD(Z10, Z29, Z24, Z29, Z10)
	MUL_W(Z10, Z10, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z10, Z30, Z31, Z26, Z27, Z28, Z29, Z10)
	REDUCE1Q(Z24, Z10, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 44(R9), Z31
	ADD(Z11, Z31, Z24, Z31, Z11)
	MUL_W(Z11, Z11, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z11, Z26, Z27, Z28, Z29, Z30, Z31, Z11)
	REDUCE1Q(Z24, Z11, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 48(R9), Z27
	ADD(Z12, Z27, Z24, Z27, Z12)
	MUL_W(Z12, Z12, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z12, Z28, Z29, Z30, Z31, Z26, Z27, Z12)
	REDUCE1Q(Z24, Z12, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 52(R9), Z29
	ADD(Z13, Z29, Z24, Z29, Z13)
	MUL_W(Z13, Z13, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z13, Z30, Z31, Z26, Z27, Z28, Z29, Z13)
	REDUCE1Q(Z24, Z13, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 56(R9), Z31
	ADD(Z14, Z31, Z24, Z31, Z14)
	MUL_W(Z14, Z14, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z14, Z26, Z27, Z28, Z29, Z30, Z31, Z14)
	REDUCE1Q(Z24, Z14, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 60(R9), Z27
	ADD(Z15, Z27, Z24, Z27, Z15)
	MUL_W(Z15, Z15, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z15, Z28, Z29, Z30, Z31, Z26, Z27, Z15)
	REDUCE1Q(Z24, Z15, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 64(R9), Z29
	ADD(Z16, Z29, Z24, Z29, Z16)
	MUL_W(Z16, Z16, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z16, Z30, Z31, Z26, Z27, Z28, Z29, Z16)
	REDUCE1Q(Z24, Z16, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 68(R9), Z31
	ADD(Z17, Z31, Z24, Z31, Z17)
	MUL_W(Z17, Z17, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z17, Z26, Z27, Z28, Z29, Z30, Z31, Z17)
	REDUCE1Q(Z24, Z17, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 72(R9), Z27
	ADD(Z18, Z27, Z24, Z27, Z18)
	MUL_W(Z18, Z18, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z18, Z28, Z29, Z30, Z31, Z26, Z27, Z18)
	REDUCE1Q(Z24, Z18, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 76(R9), Z29
	ADD(Z19, Z29, Z24, Z29, Z19)
	MUL_W(Z19, Z19, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z19, Z30, Z31, Z26, Z27, Z28, Z29, Z19)
	REDUCE1Q(Z24, Z19, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 80(R9), Z31
	ADD(Z20, Z31, Z24, Z31, Z20)
	MUL_W(Z20, Z20, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z20, Z26, Z27, Z28, Z29, Z30, Z31, Z20)
	REDUCE1Q(Z24, Z20, Z29)
	MOVQ         0(SI), R9
	VPBROADCASTD 84(R9), Z27
	ADD(Z21, Z27, Z24, Z27, Z21)
	MUL_W(Z21, Z21, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z21, Z28, Z29, Z30, Z31, Z26, Z27, Z21)
	REDUCE1Q(Z24, Z21, Z31)
	MOVQ         0(SI), R9
	VPBROADCASTD 88(R9), Z29
	ADD(Z22, Z29, Z24, Z29, Z22)
	MUL_W(Z22, Z22, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z22, Z30, Z31, Z26, Z27, Z28, Z29, Z22)
	REDUCE1Q(Z24, Z22, Z27)
	MOVQ         0(SI), R9
	VPBROADCASTD 92(R9), Z31
	ADD(Z23, Z31, Z24, Z31, Z23)
	MUL_W(Z23, Z23, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z23, Z26, Z27, Z28, Z29, Z30, Z31, Z23)
	REDUCE1Q(Z24, Z23, Z29)
	MAT_MUL_EXTERNAL_W(Z27, Z28, Z29, Z30, Z31, Z26)
	MOVQ         24(SI), R9
	VPBROADCASTD 0(R9), Z27
	ADD(Z0, Z27, Z24, Z27, Z0)
	MUL_W(Z0, Z0, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z0, Z28, Z29, Z30, Z31, Z26, Z27, Z0)
	REDUCE1Q(Z24, Z0, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 4(R9), Z29
	ADD(Z1, Z29, Z24, Z29, Z1)
	MUL_W(Z1, Z1, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z1, Z30, Z31, Z26, Z27, Z28, Z29, Z1)
	REDUCE1Q(Z24, Z1, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 8(R9), Z31
	ADD(Z2, Z31, Z24, Z31, Z2)
	MUL_W(Z2, Z2, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z2, Z26, Z27, Z28, Z29, Z30, Z31, Z2)
	REDUCE1Q(Z24, Z2, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 12(R9), Z27
	ADD(Z3, Z27, Z24, Z27, Z3)
	MUL_W(Z3, Z3, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z3, Z28, Z29, Z30, Z31, Z26, Z27, Z3)
	REDUCE1Q(Z24, Z3, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 16(R9), Z29
	ADD(Z4, Z29, Z24, Z29, Z4)
	MUL_W(Z4, Z4, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z4, Z30, Z31, Z26, Z27, Z28, Z29, Z4)
	REDUCE1Q(Z24, Z4, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 20(R9), Z31
	ADD(Z5, Z31, Z24, Z31, Z5)
	MUL_W(Z5, Z5, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z5, Z26, Z27, Z28, Z29, Z30, Z31, Z5)
	REDUCE1Q(Z24, Z5, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 24(R9), Z27
	ADD(Z6, Z27, Z24, Z27, Z6)
	MUL_W(Z6, Z6, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z6, Z28, Z29, Z30, Z31, Z26, Z27, Z6)
	REDUCE1Q(Z24, Z6, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 28(R9), Z29
	ADD(Z7, Z29, Z24, Z29, Z7)
	MUL_W(Z7, Z7, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z7, Z30, Z31, Z26, Z27, Z28, Z29, Z7)
	REDUCE1Q(Z24, Z7, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 32(R9), Z31
	ADD(Z8, Z31, Z24, Z31, Z8)
	MUL_W(Z8, Z8, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z8, Z26, Z27, Z28, Z29, Z30, Z31, Z8)
	REDUCE1Q(Z24, Z8, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 36(R9), Z27
	ADD(Z9, Z27, Z24, Z27, Z9)
	MUL_W(Z9, Z9, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z9, Z28, Z29, Z30, Z31, Z26, Z27, Z9)
	REDUCE1Q(Z24, Z9, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 40(R9), Z29
	ADD(Z10, Z29, Z24, Z29, Z10)
	MUL_W(Z10, Z10, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z10, Z30, Z31, Z26, Z27, Z28, Z29, Z10)
	REDUCE1Q(Z24, Z10, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 44(R9), Z31
	ADD(Z11, Z31, Z24, Z31, Z11)
	MUL_W(Z11, Z11, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z11, Z26, Z27, Z28, Z29, Z30, Z31, Z11)
	REDUCE1Q(Z24, Z11, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 48(R9), Z27
	ADD(Z12, Z27, Z24, Z27, Z12)
	MUL_W(Z12, Z12, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z12, Z28, Z29, Z30, Z31, Z26, Z27, Z12)
	REDUCE1Q(Z24, Z12, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 52(R9), Z29
	ADD(Z13, Z29, Z24, Z29, Z13)
	MUL_W(Z13, Z13, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z13, Z30, Z31, Z26, Z27, Z28, Z29, Z13)
	REDUCE1Q(Z24, Z13, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 56(R9), Z31
	ADD(Z14, Z31, Z24, Z31, Z14)
	MUL_W(Z14, Z14, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z14, Z26, Z27, Z28, Z29, Z30, Z31, Z14)
	REDUCE1Q(Z24, Z14, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 60(R9), Z27
	ADD(Z15, Z27, Z24, Z27, Z15)
	MUL_W(Z15, Z15, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z15, Z28, Z29, Z30, Z31, Z26, Z27, Z15)
	REDUCE1Q(Z24, Z15, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 64(R9), Z29
	ADD(Z16, Z29, Z24, Z29, Z16)
	MUL_W(Z16, Z16, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z16, Z30, Z31, Z26, Z27, Z28, Z29, Z16)
	REDUCE1Q(Z24, Z16, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 68(R9), Z31
	ADD(Z17, Z31, Z24, Z31, Z17)
	MUL_W(Z17, Z17, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z17, Z26, Z27, Z28, Z29, Z30, Z31, Z17)
	REDUCE1Q(Z24, Z17, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 72(R9), Z27
	ADD(Z18, Z27, Z24, Z27, Z18)
	MUL_W(Z18, Z18, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z18, Z28, Z29, Z30, Z31, Z26, Z27, Z18)
	REDUCE1Q(Z24, Z18, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 76(R9), Z29
	ADD(Z19, Z29, Z24, Z29, Z19)
	MUL_W(Z19, Z19, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z19, Z30, Z31, Z26, Z27, Z28, Z29, Z19)
	REDUCE1Q(Z24, Z19, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 80(R9), Z31
	ADD(Z20, Z31, Z24, Z31, Z20)
	MUL_W(Z20, Z20, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z20, Z26, Z27, Z28, Z29, Z30, Z31, Z20)
	REDUCE1Q(Z24, Z20, Z29)
	MOVQ         24(SI), R9
	VPBROADCASTD 84(R9), Z27
	ADD(Z21, Z27, Z24, Z27, Z21)
	MUL_W(Z21, Z21, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z21, Z28, Z29, Z30, Z31, Z26, Z27, Z21)
	REDUCE1Q(Z24, Z21, Z31)
	MOVQ         24(SI), R9
	VPBROADCASTD 88(R9), Z29
	ADD(Z22, Z29, Z24, Z29, Z22)
	MUL_W(Z22, Z22, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z22, Z30, Z31, Z26, Z27, Z28, Z29, Z22)
	REDUCE1Q(Z24, Z22, Z27)
	MOVQ         24(SI), R9
	VPBROADCASTD 92(R9), Z31
	ADD(Z23, Z31, Z24, Z31, Z23)
	MUL_W(Z23, Z23, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z23, Z26, Z27, Z28, Z29, Z30, Z31, Z23)
	REDUCE1Q(Z24, Z23, Z29)
	MAT_MUL_EXTERNAL_W(Z27, Z28, Z29, Z30, Z31, Z26)
	MOVQ         48(SI), R9
	VPBROADCASTD 0(R9), Z27
	ADD(Z0, Z27, Z24, Z27, Z0)
	MUL_W(Z0, Z0, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z0, Z28, Z29, Z30, Z31, Z26, Z27, Z0)
	REDUCE1Q(Z24, Z0, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 4(R9), Z29
	ADD(Z1, Z29, Z24, Z29, Z1)
	MUL_W(Z1, Z1, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z1, Z30, Z31, Z26, Z27, Z28, Z29, Z1)
	REDUCE1Q(Z24, Z1, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 8(R9), Z31
	ADD(Z2, Z31, Z24, Z31, Z2)
	MUL_W(Z2, Z2, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z2, Z26, Z27, Z28, Z29, Z30, Z31, Z2)
	REDUCE1Q(Z24, Z2, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 12(R9), Z27
	ADD(Z3, Z27, Z24, Z27, Z3)
	MUL_W(Z3, Z3, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z3, Z28, Z29, Z30, Z31, Z26, Z27, Z3)
	REDUCE1Q(Z24, Z3, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 16(R9), Z29
	ADD(Z4, Z29, Z24, Z29, Z4)
	MUL_W(Z4, Z4, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z4, Z30, Z31, Z26, Z27, Z28, Z29, Z4)
	REDUCE1Q(Z24, Z4, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 20(R9), Z31
	ADD(Z5, Z31, Z24, Z31, Z5)
	MUL_W(Z5, Z5, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z5, Z26, Z27, Z28, Z29, Z30, Z31, Z5)
	REDUCE1Q(Z24, Z5, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 24(R9), Z27
	ADD(Z6, Z27, Z24, Z27, Z6)
	MUL_W(Z6, Z6, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z6, Z28, Z29, Z30, Z31, Z26, Z27, Z6)
	REDUCE1Q(Z24, Z6, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 28(R9), Z29
	ADD(Z7, Z29, Z24, Z29, Z7)
	MUL_W(Z7, Z7, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z7, Z30, Z31, Z26, Z27, Z28, Z29, Z7)
	REDUCE1Q(Z24, Z7, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 32(R9), Z31
	ADD(Z8, Z31, Z24, Z31, Z8)
	MUL_W(Z8, Z8, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z8, Z26, Z27, Z28, Z29, Z30, Z31, Z8)
	REDUCE1Q(Z24, Z8, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 36(R9), Z27
	ADD(Z9, Z27, Z24, Z27, Z9)
	MUL_W(Z9, Z9, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z9, Z28, Z29, Z30, Z31, Z26, Z27, Z9)
	REDUCE1Q(Z24, Z9, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 40(R9), Z29
	ADD(Z10, Z29, Z24, Z29, Z10)
	MUL_W(Z10, Z10, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z10, Z30, Z31, Z26, Z27, Z28, Z29, Z10)
	REDUCE1Q(Z24, Z10, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 44(R9), Z31
	ADD(Z11, Z31, Z24, Z31, Z11)
	MUL_W(Z11, Z11, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z11, Z26, Z27, Z28, Z29, Z30, Z31, Z11)
	REDUCE1Q(Z24, Z11, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 48(R9), Z27
	ADD(Z12, Z27, Z24, Z27, Z12)
	MUL_W(Z12, Z12, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z12, Z28, Z29, Z30, Z31, Z26, Z27, Z12)
	REDUCE1Q(Z24, Z12, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 52(R9), Z29
	ADD(Z13, Z29, Z24, Z29, Z13)
	MUL_W(Z13, Z13, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z13, Z30, Z31, Z26, Z27, Z28, Z29, Z13)
	REDUCE1Q(Z24, Z13, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 56(R9), Z31
	ADD(Z14, Z31, Z24, Z31, Z14)
	MUL_W(Z14, Z14, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z14, Z26, Z27, Z28, Z29, Z30, Z31, Z14)
	REDUCE1Q(Z24, Z14, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 60(R9), Z27
	ADD(Z15, Z27, Z24, Z27, Z15)
	MUL_W(Z15, Z15, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z15, Z28, Z29, Z30, Z31, Z26, Z27, Z15)
	REDUCE1Q(Z24, Z15, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 64(R9), Z29
	ADD(Z16, Z29, Z24, Z29, Z16)
	MUL_W(Z16, Z16, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z16, Z30, Z31, Z26, Z27, Z28, Z29, Z16)
	REDUCE1Q(Z24, Z16, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 68(R9), Z31
	ADD(Z17, Z31, Z24, Z31, Z17)
	MUL_W(Z17, Z17, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z17, Z26, Z27, Z28, Z29, Z30, Z31, Z17)
	REDUCE1Q(Z24, Z17, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 72(R9), Z27
	ADD(Z18, Z27, Z24, Z27, Z18)
	MUL_W(Z18, Z18, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z18, Z28, Z29, Z30, Z31, Z26, Z27, Z18)
	REDUCE1Q(Z24, Z18, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 76(R9), Z29
	ADD(Z19, Z29, Z24, Z29, Z19)
	MUL_W(Z19, Z19, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z19, Z30, Z31, Z26, Z27, Z28, Z29, Z19)
	REDUCE1Q(Z24, Z19, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 80(R9), Z31
	ADD(Z20, Z31, Z24, Z31, Z20)
	MUL_W(Z20, Z20, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z20, Z26, Z27, Z28, Z29, Z30, Z31, Z20)
	REDUCE1Q(Z24, Z20, Z29)
	MOVQ         48(SI), R9
	VPBROADCASTD 84(R9), Z27
	ADD(Z21, Z27, Z24, Z27, Z21)
	MUL_W(Z21, Z21, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z21, Z28, Z29, Z30, Z31, Z26, Z27, Z21)
	REDUCE1Q(Z24, Z21, Z31)
	MOVQ         48(SI), R9
	VPBROADCASTD 88(R9), Z29
	ADD(Z22, Z29, Z24, Z29, Z22)
	MUL_W(Z22, Z22, Z31, Z26, Z27, Z28, Z29, Z30)
	MUL_W(Z22, Z30, Z31, Z26, Z27, Z28, Z29, Z22)
	REDUCE1Q(Z24, Z22, Z27)
	MOVQ         48(SI), R9
	VPBROADCASTD 92(R9), Z31
	ADD(Z23, Z31, Z24, Z31, Z23)
	MUL_W(Z23, Z23, Z27, Z28, Z29, Z30, Z31, Z26)
	MUL_W(Z23, Z26, Z27, Z28, Z29, Z30, Z31, Z23)
	REDUCE1Q(Z24, Z23, Z29)
	MAT_MUL_EXTERNAL_W(Z27, Z28, Z29, Z30, Z31, Z26)

	// loop over the partial rounds
	MOVQ $0x0000000000000015, R10 // nb partial rounds --> 21
	MOVQ SI, R11
	ADDQ $0x0000000000000048, R11

loop_5:
	TESTQ        R10, R10
	JEQ          done_6
	DECQ         R10
	MOVQ         0(R11), R9
	VPBROADCASTD 0(R9), Z27
	ADD(Z0, Z27, Z24, Z27, Z0)
	MUL_W(Z0, Z0, Z29, Z30, Z31, Z26, Z27, Z28)
	MUL_W(Z0, Z28, Z29, Z30, Z31, Z26, Z27, Z0)
	REDUCE1Q(Z24, Z0, Z31)
	ADD(Z0, Z1, Z24, Z30, Z29)
	ADD(Z2, Z29, Z24, Z30, Z29)
	ADD(Z3, Z29, Z24, Z30, Z29)
	ADD(Z4, Z29, Z24, Z30, Z29)
	ADD(Z5, Z29, Z24, Z30, Z29)
	ADD(Z6, Z29, Z24, Z30, Z29)
	ADD(Z7, Z29, Z24, Z30, Z29)
	ADD(Z8, Z29, Z24, Z30, Z29)
	ADD(Z9, Z29, Z24, Z30, Z29)
	ADD(Z10, Z29, Z24, Z30, Z29)
	ADD(Z11, Z29, Z24, Z30, Z29)
	ADD(Z12, Z29, Z24, Z30, Z29)
	ADD(Z13, Z29, Z24, Z30, Z29)
	ADD(Z14, Z29, Z24, Z30, Z29)
	ADD(Z15, Z29, Z24, Z30, Z29)
	ADD(Z16, Z29, Z24, Z30, Z29)
	ADD(Z17, Z29, Z24, Z30, Z29)
	ADD(Z18, Z29, Z24, Z30, Z29)
	ADD(Z19, Z29, Z24, Z30, Z29)
	ADD(Z20, Z29, Z24, Z30, Z29)
	ADD(Z21, Z29, Z24, Z30, Z29)
	ADD(Z22, Z29, Z24, Z30, Z29)
	ADD(Z23, Z29, Z24, Z30, Z29)
	DOUBLE(Z0, Z24, Z30, Z31)
	SUB(Z29, Z31, Z24, Z30, Z0)
	ADD(Z29, Z1, Z24, Z30, Z1)
	DOUBLE(Z2, Z24, Z30, Z2)
	ADD(Z2, Z29, Z24, Z30, Z2)
	MOVQ         $1, AX
	VPBROADCASTD AX, Z26
	VPTESTMD     Z3, Z26, K4
	VPADDD       Z3, Z24, K4, Z3
	VPSRLD       $1, Z3, Z3
	ADD(Z29, Z3, Z24, Z30, Z3)
	DOUBLE(Z4, Z24, Z30, Z31)
	ADD(Z4, Z31, Z24, Z30, Z4)
	ADD(Z4, Z29, Z24, Z30, Z4)
	DOUBLE(Z5, Z24, Z30, Z5)
	ADD(Z5, Z5, Z24, Z30, Z5)
	ADD(Z5, Z29, Z24, Z30, Z5)
	MOVQ         $1, AX
	VPBROADCASTD AX, Z27
	VPTESTMD     Z6, Z27, K4
	VPADDD       Z6, Z24, K4, Z6
	VPSRLD       $1, Z6, Z6
	SUB(Z29, Z6, Z24, Z30, Z6)
	DOUBLE(Z7, Z24, Z30, Z31)
	ADD(Z7, Z31, Z24, Z30, Z7)
	SUB(Z29, Z7, Z24, Z30, Z7)
	DOUBLE(Z8, Z24, Z30, Z8)
	DOUBLE(Z8, Z24, Z30, Z8)
	SUB(Z29, Z8, Z24, Z30, Z8)
	MUL2EXPNEGN(Z9, Z30, Z9, $8, $24, Z28, Z26, Z27, Z31)
	ADD(Z9, Z29, Z24, Z30, Z9)
	MUL2EXPNEGN(Z10, Z30, Z10, $2, $30, Z28, Z26, Z27, Z31)
	ADD(Z10, Z29, Z24, Z30, Z10)
	MUL2EXPNEGN(Z11, Z30, Z11, $3, $29, Z28, Z26, Z27, Z31)
	ADD(Z11, Z29, Z24, Z30, Z11)
	MUL2EXPNEGN(Z12, Z30, Z12, $4, $28, Z28, Z26, Z27, Z31)
	ADD(Z12, Z29, Z24, Z30, Z12)
	MUL2EXPNEGN(Z13, Z30, Z13, $5, $27, Z28, Z26, Z27, Z31)
	ADD(Z13, Z29, Z24, Z30, Z13)
	MUL2EXPNEGN(Z14, Z30, Z14, $6, $26, Z28, Z26, Z27, Z31)
	ADD(Z14, Z29, Z24, Z30, Z14)
	MUL2EXPNEGN(Z15, Z30, Z15, $24, $8, Z28, Z26, Z27, Z31)
	ADD(Z15, Z29, Z24, Z30, Z15)
	MUL2EXPNEGN(Z16, Z30, Z16, $8, $24, Z28, Z26, Z27, Z31)
	SUB(Z29, Z16, Z24, Z30, Z16)
	MUL2EXPNEGN(Z17, Z30, Z17, $3, $29, Z28, Z26, Z27, Z31)
	SUB(Z29, Z17, Z24, Z30, Z17)
	MUL2EXPNEGN(Z18, Z30, Z18, $4, $28, Z28, Z26, Z27, Z31)
	SUB(Z29, Z18, Z24, Z30, Z18)
	MUL2EXPNEGN(Z19, Z30, Z19, $5, $27, Z28, Z26, Z27, Z31)
	SUB(Z29, Z19, Z24, Z30, Z19)
	MUL2EXPNEGN(Z20, Z30, Z20, $6, $26, Z28, Z26, Z27, Z31)
	SUB(Z29, Z20, Z24, Z30, Z20)
	MUL2EXPNEGN(Z21, Z30, Z21, $7, $25, Z28, Z26, Z27, Z31)
	SUB(Z29, Z21, Z24, Z30, Z21)
	MUL2EXPNEGN(Z22, Z30, Z22, $9, $23, Z28, Z26, Z27, Z31)
	SUB(Z29, Z22, Z24, Z30, Z22)
	MUL2EXPNEGN(Z23, Z30, Z23, $24, $8, Z28, Z26, Z27, Z31)
	SUB(Z29, Z23, Z24, Z30, Z23)
	ADDQ         $24, R11
	JMP          loop_5

done_6:
	MOVQ         576(SI), R9
	VPBROADCASTD 0(R9), Z28
	ADD(Z0, Z28, Z24, Z28, Z0)
	MUL_W(Z0, Z0, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z0, Z26, Z27, Z31, Z29, Z30, Z28, Z0)
	REDUCE1Q(Z24, Z0, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 4(R9), Z27
	ADD(Z1, Z27, Z24, Z27, Z1)
	MUL_W(Z1, Z1, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z1, Z31, Z29, Z30, Z28, Z26, Z27, Z1)
	REDUCE1Q(Z24, Z1, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 8(R9), Z29
	ADD(Z2, Z29, Z24, Z29, Z2)
	MUL_W(Z2, Z2, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z2, Z30, Z28, Z26, Z27, Z31, Z29, Z2)
	REDUCE1Q(Z24, Z2, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 12(R9), Z28
	ADD(Z3, Z28, Z24, Z28, Z3)
	MUL_W(Z3, Z3, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z3, Z26, Z27, Z31, Z29, Z30, Z28, Z3)
	REDUCE1Q(Z24, Z3, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 16(R9), Z27
	ADD(Z4, Z27, Z24, Z27, Z4)
	MUL_W(Z4, Z4, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z4, Z31, Z29, Z30, Z28, Z26, Z27, Z4)
	REDUCE1Q(Z24, Z4, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 20(R9), Z29
	ADD(Z5, Z29, Z24, Z29, Z5)
	MUL_W(Z5, Z5, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z5, Z30, Z28, Z26, Z27, Z31, Z29, Z5)
	REDUCE1Q(Z24, Z5, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 24(R9), Z28
	ADD(Z6, Z28, Z24, Z28, Z6)
	MUL_W(Z6, Z6, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z6, Z26, Z27, Z31, Z29, Z30, Z28, Z6)
	REDUCE1Q(Z24, Z6, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 28(R9), Z27
	ADD(Z7, Z27, Z24, Z27, Z7)
	MUL_W(Z7, Z7, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z7, Z31, Z29, Z30, Z28, Z26, Z27, Z7)
	REDUCE1Q(Z24, Z7, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 32(R9), Z29
	ADD(Z8, Z29, Z24, Z29, Z8)
	MUL_W(Z8, Z8, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z8, Z30, Z28, Z26, Z27, Z31, Z29, Z8)
	REDUCE1Q(Z24, Z8, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 36(R9), Z28
	ADD(Z9, Z28, Z24, Z28, Z9)
	MUL_W(Z9, Z9, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z9, Z26, Z27, Z31, Z29, Z30, Z28, Z9)
	REDUCE1Q(Z24, Z9, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 40(R9), Z27
	ADD(Z10, Z27, Z24, Z27, Z10)
	MUL_W(Z10, Z10, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z10, Z31, Z29, Z30, Z28, Z26, Z27, Z10)
	REDUCE1Q(Z24, Z10, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 44(R9), Z29
	ADD(Z11, Z29, Z24, Z29, Z11)
	MUL_W(Z11, Z11, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z11, Z30, Z28, Z26, Z27, Z31, Z29, Z11)
	REDUCE1Q(Z24, Z11, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 48(R9), Z28
	ADD(Z12, Z28, Z24, Z28, Z12)
	MUL_W(Z12, Z12, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z12, Z26, Z27, Z31, Z29, Z30, Z28, Z12)
	REDUCE1Q(Z24, Z12, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 52(R9), Z27
	ADD(Z13, Z27, Z24, Z27, Z13)
	MUL_W(Z13, Z13, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z13, Z31, Z29, Z30, Z28, Z26, Z27, Z13)
	REDUCE1Q(Z24, Z13, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 56(R9), Z29
	ADD(Z14, Z29, Z24, Z29, Z14)
	MUL_W(Z14, Z14, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z14, Z30, Z28, Z26, Z27, Z31, Z29, Z14)
	REDUCE1Q(Z24, Z14, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 60(R9), Z28
	ADD(Z15, Z28, Z24, Z28, Z15)
	MUL_W(Z15, Z15, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z15, Z26, Z27, Z31, Z29, Z30, Z28, Z15)
	REDUCE1Q(Z24, Z15, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 64(R9), Z27
	ADD(Z16, Z27, Z24, Z27, Z16)
	MUL_W(Z16, Z16, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z16, Z31, Z29, Z30, Z28, Z26, Z27, Z16)
	REDUCE1Q(Z24, Z16, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 68(R9), Z29
	ADD(Z17, Z29, Z24, Z29, Z17)
	MUL_W(Z17, Z17, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z17, Z30, Z28, Z26, Z27, Z31, Z29, Z17)
	REDUCE1Q(Z24, Z17, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 72(R9), Z28
	ADD(Z18, Z28, Z24, Z28, Z18)
	MUL_W(Z18, Z18, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z18, Z26, Z27, Z31, Z29, Z30, Z28, Z18)
	REDUCE1Q(Z24, Z18, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 76(R9), Z27
	ADD(Z19, Z27, Z24, Z27, Z19)
	MUL_W(Z19, Z19, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z19, Z31, Z29, Z30, Z28, Z26, Z27, Z19)
	REDUCE1Q(Z24, Z19, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 80(R9), Z29
	ADD(Z20, Z29, Z24, Z29, Z20)
	MUL_W(Z20, Z20, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z20, Z30, Z28, Z26, Z27, Z31, Z29, Z20)
	REDUCE1Q(Z24, Z20, Z27)
	MOVQ         576(SI), R9
	VPBROADCASTD 84(R9), Z28
	ADD(Z21, Z28, Z24, Z28, Z21)
	MUL_W(Z21, Z21, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z21, Z26, Z27, Z31, Z29, Z30, Z28, Z21)
	REDUCE1Q(Z24, Z21, Z29)
	MOVQ         576(SI), R9
	VPBROADCASTD 88(R9), Z27
	ADD(Z22, Z27, Z24, Z27, Z22)
	MUL_W(Z22, Z22, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z22, Z31, Z29, Z30, Z28, Z26, Z27, Z22)
	REDUCE1Q(Z24, Z22, Z28)
	MOVQ         576(SI), R9
	VPBROADCASTD 92(R9), Z29
	ADD(Z23, Z29, Z24, Z29, Z23)
	MUL_W(Z23, Z23, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z23, Z30, Z28, Z26, Z27, Z31, Z29, Z23)
	REDUCE1Q(Z24, Z23, Z27)
	MAT_MUL_EXTERNAL_W(Z28, Z26, Z27, Z31, Z29, Z30)
	MOVQ         600(SI), R9
	VPBROADCASTD 0(R9), Z28
	ADD(Z0, Z28, Z24, Z28, Z0)
	MUL_W(Z0, Z0, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z0, Z26, Z27, Z31, Z29, Z30, Z28, Z0)
	REDUCE1Q(Z24, Z0, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 4(R9), Z27
	ADD(Z1, Z27, Z24, Z27, Z1)
	MUL_W(Z1, Z1, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z1, Z31, Z29, Z30, Z28, Z26, Z27, Z1)
	REDUCE1Q(Z24, Z1, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 8(R9), Z29
	ADD(Z2, Z29, Z24, Z29, Z2)
	MUL_W(Z2, Z2, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z2, Z30, Z28, Z26, Z27, Z31, Z29, Z2)
	REDUCE1Q(Z24, Z2, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 12(R9), Z28
	ADD(Z3, Z28, Z24, Z28, Z3)
	MUL_W(Z3, Z3, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z3, Z26, Z27, Z31, Z29, Z30, Z28, Z3)
	REDUCE1Q(Z24, Z3, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 16(R9), Z27
	ADD(Z4, Z27, Z24, Z27, Z4)
	MUL_W(Z4, Z4, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z4, Z31, Z29, Z30, Z28, Z26, Z27, Z4)
	REDUCE1Q(Z24, Z4, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 20(R9), Z29
	ADD(Z5, Z29, Z24, Z29, Z5)
	MUL_W(Z5, Z5, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z5, Z30, Z28, Z26, Z27, Z31, Z29, Z5)
	REDUCE1Q(Z24, Z5, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 24(R9), Z28
	ADD(Z6, Z28, Z24, Z28, Z6)
	MUL_W(Z6, Z6, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z6, Z26, Z27, Z31, Z29, Z30, Z28, Z6)
	REDUCE1Q(Z24, Z6, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 28(R9), Z27
	ADD(Z7, Z27, Z24, Z27, Z7)
	MUL_W(Z7, Z7, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z7, Z31, Z29, Z30, Z28, Z26, Z27, Z7)
	REDUCE1Q(Z24, Z7, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 32(R9), Z29
	ADD(Z8, Z29, Z24, Z29, Z8)
	MUL_W(Z8, Z8, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z8, Z30, Z28, Z26, Z27, Z31, Z29, Z8)
	REDUCE1Q(Z24, Z8, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 36(R9), Z28
	ADD(Z9, Z28, Z24, Z28, Z9)
	MUL_W(Z9, Z9, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z9, Z26, Z27, Z31, Z29, Z30, Z28, Z9)
	REDUCE1Q(Z24, Z9, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 40(R9), Z27
	ADD(Z10, Z27, Z24, Z27, Z10)
	MUL_W(Z10, Z10, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z10, Z31, Z29, Z30, Z28, Z26, Z27, Z10)
	REDUCE1Q(Z24, Z10, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 44(R9), Z29
	ADD(Z11, Z29, Z24, Z29, Z11)
	MUL_W(Z11, Z11, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z11, Z30, Z28, Z26, Z27, Z31, Z29, Z11)
	REDUCE1Q(Z24, Z11, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 48(R9), Z28
	ADD(Z12, Z28, Z24, Z28, Z12)
	MUL_W(Z12, Z12, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z12, Z26, Z27, Z31, Z29, Z30, Z28, Z12)
	REDUCE1Q(Z24, Z12, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 52(R9), Z27
	ADD(Z13, Z27, Z24, Z27, Z13)
	MUL_W(Z13, Z13, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z13, Z31, Z29, Z30, Z28, Z26, Z27, Z13)
	REDUCE1Q(Z24, Z13, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 56(R9), Z29
	ADD(Z14, Z29, Z24, Z29, Z14)
	MUL_W(Z14, Z14, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z14, Z30, Z28, Z26, Z27, Z31, Z29, Z14)
	REDUCE1Q(Z24, Z14, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 60(R9), Z28
	ADD(Z15, Z28, Z24, Z28, Z15)
	MUL_W(Z15, Z15, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z15, Z26, Z27, Z31, Z29, Z30, Z28, Z15)
	REDUCE1Q(Z24, Z15, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 64(R9), Z27
	ADD(Z16, Z27, Z24, Z27, Z16)
	MUL_W(Z16, Z16, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z16, Z31, Z29, Z30, Z28, Z26, Z27, Z16)
	REDUCE1Q(Z24, Z16, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 68(R9), Z29
	ADD(Z17, Z29, Z24, Z29, Z17)
	MUL_W(Z17, Z17, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z17, Z30, Z28, Z26, Z27, Z31, Z29, Z17)
	REDUCE1Q(Z24, Z17, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 72(R9), Z28
	ADD(Z18, Z28, Z24, Z28, Z18)
	MUL_W(Z18, Z18, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z18, Z26, Z27, Z31, Z29, Z30, Z28, Z18)
	REDUCE1Q(Z24, Z18, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 76(R9), Z27
	ADD(Z19, Z27, Z24, Z27, Z19)
	MUL_W(Z19, Z19, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z19, Z31, Z29, Z30, Z28, Z26, Z27, Z19)
	REDUCE1Q(Z24, Z19, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 80(R9), Z29
	ADD(Z20, Z29, Z24, Z29, Z20)
	MUL_W(Z20, Z20, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z20, Z30, Z28, Z26, Z27, Z31, Z29, Z20)
	REDUCE1Q(Z24, Z20, Z27)
	MOVQ         600(SI), R9
	VPBROADCASTD 84(R9), Z28
	ADD(Z21, Z28, Z24, Z28, Z21)
	MUL_W(Z21, Z21, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z21, Z26, Z27, Z31, Z29, Z30, Z28, Z21)
	REDUCE1Q(Z24, Z21, Z29)
	MOVQ         600(SI), R9
	VPBROADCASTD 88(R9), Z27
	ADD(Z22, Z27, Z24, Z27, Z22)
	MUL_W(Z22, Z22, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z22, Z31, Z29, Z30, Z28, Z26, Z27, Z22)
	REDUCE1Q(Z24, Z22, Z28)
	MOVQ         600(SI), R9
	VPBROADCASTD 92(R9), Z29
	ADD(Z23, Z29, Z24, Z29, Z23)
	MUL_W(Z23, Z23, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z23, Z30, Z28, Z26, Z27, Z31, Z29, Z23)
	REDUCE1Q(Z24, Z23, Z27)
	MAT_MUL_EXTERNAL_W(Z28, Z26, Z27, Z31, Z29, Z30)
	MOVQ         624(SI), R9
	VPBROADCASTD 0(R9), Z28
	ADD(Z0, Z28, Z24, Z28, Z0)
	MUL_W(Z0, Z0, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z0, Z26, Z27, Z31, Z29, Z30, Z28, Z0)
	REDUCE1Q(Z24, Z0, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 4(R9), Z27
	ADD(Z1, Z27, Z24, Z27, Z1)
	MUL_W(Z1, Z1, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z1, Z31, Z29, Z30, Z28, Z26, Z27, Z1)
	REDUCE1Q(Z24, Z1, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 8(R9), Z29
	ADD(Z2, Z29, Z24, Z29, Z2)
	MUL_W(Z2, Z2, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z2, Z30, Z28, Z26, Z27, Z31, Z29, Z2)
	REDUCE1Q(Z24, Z2, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 12(R9), Z28
	ADD(Z3, Z28, Z24, Z28, Z3)
	MUL_W(Z3, Z3, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z3, Z26, Z27, Z31, Z29, Z30, Z28, Z3)
	REDUCE1Q(Z24, Z3, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 16(R9), Z27
	ADD(Z4, Z27, Z24, Z27, Z4)
	MUL_W(Z4, Z4, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z4, Z31, Z29, Z30, Z28, Z26, Z27, Z4)
	REDUCE1Q(Z24, Z4, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 20(R9), Z29
	ADD(Z5, Z29, Z24, Z29, Z5)
	MUL_W(Z5, Z5, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z5, Z30, Z28, Z26, Z27, Z31, Z29, Z5)
	REDUCE1Q(Z24, Z5, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 24(R9), Z28
	ADD(Z6, Z28, Z24, Z28, Z6)
	MUL_W(Z6, Z6, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z6, Z26, Z27, Z31, Z29, Z30, Z28, Z6)
	REDUCE1Q(Z24, Z6, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 28(R9), Z27
	ADD(Z7, Z27, Z24, Z27, Z7)
	MUL_W(Z7, Z7, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z7, Z31, Z29, Z30, Z28, Z26, Z27, Z7)
	REDUCE1Q(Z24, Z7, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 32(R9), Z29
	ADD(Z8, Z29, Z24, Z29, Z8)
	MUL_W(Z8, Z8, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z8, Z30, Z28, Z26, Z27, Z31, Z29, Z8)
	REDUCE1Q(Z24, Z8, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 36(R9), Z28
	ADD(Z9, Z28, Z24, Z28, Z9)
	MUL_W(Z9, Z9, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z9, Z26, Z27, Z31, Z29, Z30, Z28, Z9)
	REDUCE1Q(Z24, Z9, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 40(R9), Z27
	ADD(Z10, Z27, Z24, Z27, Z10)
	MUL_W(Z10, Z10, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z10, Z31, Z29, Z30, Z28, Z26, Z27, Z10)
	REDUCE1Q(Z24, Z10, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 44(R9), Z29
	ADD(Z11, Z29, Z24, Z29, Z11)
	MUL_W(Z11, Z11, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z11, Z30, Z28, Z26, Z27, Z31, Z29, Z11)
	REDUCE1Q(Z24, Z11, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 48(R9), Z28
	ADD(Z12, Z28, Z24, Z28, Z12)
	MUL_W(Z12, Z12, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z12, Z26, Z27, Z31, Z29, Z30, Z28, Z12)
	REDUCE1Q(Z24, Z12, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 52(R9), Z27
	ADD(Z13, Z27, Z24, Z27, Z13)
	MUL_W(Z13, Z13, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z13, Z31, Z29, Z30, Z28, Z26, Z27, Z13)
	REDUCE1Q(Z24, Z13, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 56(R9), Z29
	ADD(Z14, Z29, Z24, Z29, Z14)
	MUL_W(Z14, Z14, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z14, Z30, Z28, Z26, Z27, Z31, Z29, Z14)
	REDUCE1Q(Z24, Z14, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 60(R9), Z28
	ADD(Z15, Z28, Z24, Z28, Z15)
	MUL_W(Z15, Z15, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z15, Z26, Z27, Z31, Z29, Z30, Z28, Z15)
	REDUCE1Q(Z24, Z15, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 64(R9), Z27
	ADD(Z16, Z27, Z24, Z27, Z16)
	MUL_W(Z16, Z16, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z16, Z31, Z29, Z30, Z28, Z26, Z27, Z16)
	REDUCE1Q(Z24, Z16, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 68(R9), Z29
	ADD(Z17, Z29, Z24, Z29, Z17)
	MUL_W(Z17, Z17, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z17, Z30, Z28, Z26, Z27, Z31, Z29, Z17)
	REDUCE1Q(Z24, Z17, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 72(R9), Z28
	ADD(Z18, Z28, Z24, Z28, Z18)
	MUL_W(Z18, Z18, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z18, Z26, Z27, Z31, Z29, Z30, Z28, Z18)
	REDUCE1Q(Z24, Z18, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 76(R9), Z27
	ADD(Z19, Z27, Z24, Z27, Z19)
	MUL_W(Z19, Z19, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z19, Z31, Z29, Z30, Z28, Z26, Z27, Z19)
	REDUCE1Q(Z24, Z19, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 80(R9), Z29
	ADD(Z20, Z29, Z24, Z29, Z20)
	MUL_W(Z20, Z20, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z20, Z30, Z28, Z26, Z27, Z31, Z29, Z20)
	REDUCE1Q(Z24, Z20, Z27)
	MOVQ         624(SI), R9
	VPBROADCASTD 84(R9), Z28
	ADD(Z21, Z28, Z24, Z28, Z21)
	MUL_W(Z21, Z21, Z27, Z31, Z29, Z30, Z28, Z26)
	MUL_W(Z21, Z26, Z27, Z31, Z29, Z30, Z28, Z21)
	REDUCE1Q(Z24, Z21, Z29)
	MOVQ         624(SI), R9
	VPBROADCASTD 88(R9), Z27
	ADD(Z22, Z27, Z24, Z27, Z22)
	MUL_W(Z22, Z22, Z29, Z30, Z28, Z26, Z27, Z31)
	MUL_W(Z22, Z31, Z29, Z30, Z28, Z26, Z27, Z22)
	REDUCE1Q(Z24, Z22, Z28)
	MOVQ         624(SI), R9
	VPBROADCASTD 92(R9), Z29
	ADD(Z23, Z29, Z24, Z29, Z23)
	MUL_W(Z23, Z23, Z28, Z26, Z27, Z31, Z29, Z30)
	MUL_W(Z23, Z30, Z28, Z26, Z27, Z31, Z29, Z23)
	REDUCE1Q(Z24, Z23, Z27)
	MAT_MUL_EXTERNAL_W(Z28, Z26, Z27, Z31, Z29, Z30)
	DECQ         CX
	JMP          outer_loop_3

outer_loop_end_4:
	VMOVDQU32   0(DI), Z28
	KMOVD       R14, K1
	VPSCATTERDD Z0, K1, 0(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z1, K1, 4(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z2, K1, 8(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z3, K1, 12(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z4, K1, 16(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z5, K1, 20(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z6, K1, 24(BX)(Z28*4)
	KMOVD       R14, K1
	VPSCATTERDD Z7, K1, 28(BX)(Z28*4)
	RET

TEXT ·permutation16_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R15
	MOVQ         roundKeys+24(FP), R14
	VMOVDQU32    0(R15), Z2
	MOVQ         ·diag16+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VPSRLQ       $32, Z18, Z19

#define MAT_MUL_EXTERNAL_16() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define SBOX_FULL_16() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \

#define SUM_STATE_16() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND_16() \
	VMOVDQU32 0(BX), Z4      \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	SBOX_FULL_16()           \
	MAT_MUL_EXTERNAL_16()    \

	MAT_MUL_EXTERNAL_16()
	MOVQ 0(R14), BX
	FULL_ROUND_16()
	MOVQ 24(R14), BX
	FULL_ROUND_16()
	MOVQ 48(R14), BX
	FULL_ROUND_16()

	// loop over the partial rounds
	MOVQ $0x0000000000000015, SI // nb partial rounds --> 21
	MOVQ R14, DI
	ADDQ $0x0000000000000048, DI

loop_7:
	TESTQ     SI, SI
	JEQ       done_8
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE_16()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADDQ      $24, DI
	JMP       loop_7

done_8:
	MOVQ      576(R14), BX
	FULL_ROUND_16()
	MOVQ      600(R14), BX
	FULL_ROUND_16()
	MOVQ      624(R14), BX
	FULL_ROUND_16()
	VMOVDQU32 Z2, 0(R15)
	RET
