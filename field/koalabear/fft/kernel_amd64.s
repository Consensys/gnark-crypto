//go:build !purego
// Code generated by gnark-crypto/generator. DO NOT EDIT.
#include "textflag.h"
#include "funcdata.h"
#include "go_asm.h"

TEXT 路innerDIFWithTwiddles_avx512(SB), NOSPLIT, $0-72

	// func innerDIFWithTwiddles(a []Element, twiddles []Element, start, end, m int) {
	// 	for i := start; i < end; i++ {
	// 		Butterfly(&a[i], &a[i+m])
	// 		a[i+m].Mul(&a[i+m], &twiddles[i])
	// 	}
	// }

	// prepare constants needed for mul and reduce ops
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z2
	VPBROADCASTQ AX, Z8
	MOVD         $const_qInvNeg, AX
	VPBROADCASTQ AX, Z9
	VPCMPEQB     Y0, Y0, Y0
	VPMOVZXDQ    Y0, Z11

	// load arguments
	MOVQ a+0(FP), R15
	MOVQ twiddles+24(FP), CX
	MOVQ end+56(FP), SI
	MOVQ m+64(FP), BX
	CMPQ BX, $0x0000000000000010
	JL   smallerThan16_1         // m < 16
	SHRQ $4, SI                  // we are processing 16 elements at a time
	SHLQ $2, BX                  // offset = m * 4bytes
	MOVQ R15, DX
	ADDQ BX, DX

	// performs a butterfly between 2 vectors of dwords
	// first vector is in [0, q) and second vector is in [0, 2q)
#define BUTTERFLYD2Q(in0, in1) \
	VPADDD  in0, in1, Z3  \
	VPSUBD  in1, in0, in1 \
	VPSUBD  Z2, Z3, in0   \
	VPMINUD Z3, in0, in0  \
	VPADDD  Z2, in1, in1  \

#define MUL(in0, in1) \
	VPMULUDQ in0, in1, Z12 \
	VPANDQ   Z11, Z12, Z10 \
	VPMULUDQ Z10, Z9, Z10  \
	VPANDQ   Z11, Z10, Z10 \
	VPMULUDQ Z10, Z8, Z10  \
	VPADDQ   Z12, Z10, Z12 \
	VPSRLQ   $32, Z12, Z12 \
	VPSUBQ   Z8, Z12, Z10  \
	VPMINUQ  Z12, Z10, in0 \

loop_3:
	TESTQ         SI, SI
	JEQ           done_2      // n == 0, we are done
	VMOVDQA32     0(R15), Z0  // load a[i]
	VMOVDQA32     0(DX), Z1   // load a[i+m]
	BUTTERFLYD2Q(Z0, Z1)
	VMOVDQA32     Z0, 0(R15)  // store a[i]
	VEXTRACTI32X8 $0, Z1, Y20
	VEXTRACTI32X8 $1, Z1, Y21
	VPMOVZXDQ     Y20, Z13
	VPMOVZXDQ     Y21, Z14
	VPMOVZXDQ     0(CX), Z15
	VPMOVZXDQ     32(CX), Z16
	MUL(Z13, Z15)
	MUL(Z14, Z16)
	VPMOVQD       Z13, 0(DX)
	VPMOVQD       Z14, 32(DX)
	ADDQ          $64, R15
	ADDQ          $64, DX
	ADDQ          $64, CX
	DECQ          SI          // decrement n
	JMP           loop_3

done_2:
	RET

smallerThan16_1:
	// m < 16, we call the generic one
	// note that this should happen only when doing a FFT smaller than the smallest generated kernel
	MOVQ a+0(FP), AX
	MOVQ AX, (SP)
	MOVQ twiddles+24(FP), AX
	MOVQ AX, 24(SP)
	MOVQ start+48(FP), AX
	MOVQ AX, 48(SP)
	MOVQ end+56(FP), AX
	MOVQ AX, 56(SP)
	MOVQ m+64(FP), AX
	MOVQ AX, 64(SP)
	CALL 路innerDIFWithTwiddlesGeneric(SB)
	RET

// kerDIFNP_128_avx512(a []{{ .FF }}.Element, twiddles [][]{{ .FF }}.Element, stage int)
TEXT 路kerDIFNP_128_avx512(SB), NOSPLIT, $0-56
	// prepare constants needed for mul and reduce ops
	MOVD         $const_q, AX
	VPBROADCASTQ AX, Z17
	MOVD         $const_qInvNeg, AX
	VPBROADCASTQ AX, Z18
	VPCMPEQB     Y0, Y0, Y0
	VPMOVZXDQ    Y0, Z20

	// load arguments
	MOVQ  a+0(FP), R15
	MOVQ  twiddles+24(FP), CX
	MOVQ  stage+48(FP), AX
	IMULQ $24, AX
	ADDQ  AX, CX              // we want twiddles[stage] as starting point

	// load a[:128] in registers
	VPMOVZXDQ 0(R15), Z0
	VPMOVZXDQ 32(R15), Z1
	VPMOVZXDQ 64(R15), Z2
	VPMOVZXDQ 96(R15), Z3
	VPMOVZXDQ 128(R15), Z4
	VPMOVZXDQ 160(R15), Z5
	VPMOVZXDQ 192(R15), Z6
	VPMOVZXDQ 224(R15), Z7
	VPMOVZXDQ 256(R15), Z8
	VPMOVZXDQ 288(R15), Z9
	VPMOVZXDQ 320(R15), Z10
	VPMOVZXDQ 352(R15), Z11
	VPMOVZXDQ 384(R15), Z12
	VPMOVZXDQ 416(R15), Z13
	VPMOVZXDQ 448(R15), Z14
	VPMOVZXDQ 480(R15), Z15

	// butterfly computes
	// in0 = in0 + in1 (in [0,q))
	// in1 = in0 - in1 (in [0,2q))
#define BUTTERFLY(in0, in1) \
	VPADDQ  in0, in1, Z21 \
	VPSUBQ  in1, in0, in1 \
	VPSUBQ  Z17, Z21, in0 \
	VPMINUQ Z21, in0, in0 \
	VPADDQ  Z17, in1, in1 \

// mul computes x = x * y
#define MUL_0(in0, in1) \
	VPMULUDQ in0, in1, Z16 \
	VPANDQ   Z20, Z16, Z19 \
	VPMULUDQ Z19, Z18, Z19 \
	VPANDQ   Z20, Z19, Z19 \
	VPMULUDQ Z19, Z17, Z19 \
	VPADDQ   Z16, Z19, Z16 \
	VPSRLQ   $32, Z16, Z16 \
	VPSUBQ   Z17, Z16, Z19 \
	VPMINUQ  Z16, Z19, in0 \

	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), Z23
	VPMOVZXDQ    32(BX), Z24
	VPMOVZXDQ    64(BX), Z25
	VPMOVZXDQ    96(BX), Z26
	VPMOVZXDQ    128(BX), Z27
	VPMOVZXDQ    160(BX), Z28
	VPMOVZXDQ    192(BX), Z29
	VPMOVZXDQ    224(BX), Z30
	BUTTERFLY(Z0, Z8)
	MUL_0(Z8, Z23)
	BUTTERFLY(Z1, Z9)
	MUL_0(Z9, Z24)
	BUTTERFLY(Z2, Z10)
	MUL_0(Z10, Z25)
	BUTTERFLY(Z3, Z11)
	MUL_0(Z11, Z26)
	BUTTERFLY(Z4, Z12)
	MUL_0(Z12, Z27)
	BUTTERFLY(Z5, Z13)
	MUL_0(Z13, Z28)
	BUTTERFLY(Z6, Z14)
	MUL_0(Z14, Z29)
	BUTTERFLY(Z7, Z15)
	MUL_0(Z15, Z30)
	ADDQ         $24, CX
	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), Z23
	VPMOVZXDQ    32(BX), Z24
	VPMOVZXDQ    64(BX), Z25
	VPMOVZXDQ    96(BX), Z26
	BUTTERFLY(Z0, Z4)
	MUL_0(Z4, Z23)
	BUTTERFLY(Z1, Z5)
	MUL_0(Z5, Z24)
	BUTTERFLY(Z2, Z6)
	MUL_0(Z6, Z25)
	BUTTERFLY(Z3, Z7)
	MUL_0(Z7, Z26)
	BUTTERFLY(Z8, Z12)
	MUL_0(Z12, Z23)
	BUTTERFLY(Z9, Z13)
	MUL_0(Z13, Z24)
	BUTTERFLY(Z10, Z14)
	MUL_0(Z14, Z25)
	BUTTERFLY(Z11, Z15)
	MUL_0(Z15, Z26)
	ADDQ         $24, CX
	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), Z23
	VPMOVZXDQ    32(BX), Z24
	BUTTERFLY(Z0, Z2)
	MUL_0(Z2, Z23)
	BUTTERFLY(Z1, Z3)
	MUL_0(Z3, Z24)
	BUTTERFLY(Z4, Z6)
	MUL_0(Z6, Z23)
	BUTTERFLY(Z5, Z7)
	MUL_0(Z7, Z24)
	BUTTERFLY(Z8, Z10)
	MUL_0(Z10, Z23)
	BUTTERFLY(Z9, Z11)
	MUL_0(Z11, Z24)
	BUTTERFLY(Z12, Z14)
	MUL_0(Z14, Z23)
	BUTTERFLY(Z13, Z15)
	MUL_0(Z15, Z24)
	ADDQ         $24, CX
	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), Z23
	BUTTERFLY(Z0, Z1)
	MUL_0(Z1, Z23)
	BUTTERFLY(Z2, Z3)
	MUL_0(Z3, Z23)
	BUTTERFLY(Z4, Z5)
	MUL_0(Z5, Z23)
	BUTTERFLY(Z6, Z7)
	MUL_0(Z7, Z23)
	BUTTERFLY(Z8, Z9)
	MUL_0(Z9, Z23)
	BUTTERFLY(Z10, Z11)
	MUL_0(Z11, Z23)
	BUTTERFLY(Z12, Z13)
	MUL_0(Z13, Z23)
	BUTTERFLY(Z14, Z15)
	MUL_0(Z15, Z23)
	ADDQ         $24, CX
	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), Y23              // zero extend 4x uint32 to 4x uint64
	VINSERTI64X4 $1, Y23, Z23, Z23
	MOVQ         $0x0000000000000f0f, AX
	KMOVQ        AX, K1

#define PERMUTE4X4(in0, in1) \
	VSHUFI64X2 $0x000000000000004e, in1, in0, Z21 \
	VPBLENDMQ  in0, Z21, K1, in0                  \
	VPBLENDMQ  Z21, in1, K1, in1                  \

	PERMUTE4X4(Z0, Z1)
	BUTTERFLY(Z0, Z1)
	MUL_0(Z1, Z23)
	PERMUTE4X4(Z0, Z1)
	PERMUTE4X4(Z2, Z3)
	BUTTERFLY(Z2, Z3)
	MUL_0(Z3, Z23)
	PERMUTE4X4(Z2, Z3)
	PERMUTE4X4(Z4, Z5)
	BUTTERFLY(Z4, Z5)
	MUL_0(Z5, Z23)
	PERMUTE4X4(Z4, Z5)
	PERMUTE4X4(Z6, Z7)
	BUTTERFLY(Z6, Z7)
	MUL_0(Z7, Z23)
	PERMUTE4X4(Z6, Z7)
	PERMUTE4X4(Z8, Z9)
	BUTTERFLY(Z8, Z9)
	MUL_0(Z9, Z23)
	PERMUTE4X4(Z8, Z9)
	PERMUTE4X4(Z10, Z11)
	BUTTERFLY(Z10, Z11)
	MUL_0(Z11, Z23)
	PERMUTE4X4(Z10, Z11)
	PERMUTE4X4(Z12, Z13)
	BUTTERFLY(Z12, Z13)
	MUL_0(Z13, Z23)
	PERMUTE4X4(Z12, Z13)
	PERMUTE4X4(Z14, Z15)
	BUTTERFLY(Z14, Z15)
	MUL_0(Z15, Z23)
	PERMUTE4X4(Z14, Z15)
	ADDQ         $24, CX
	MOVQ         0(CX), BX
	VPMOVZXDQ    0(BX), X23                         // zero extend 2x uint32 to 2x uint64
	VINSERTI64X2 $1, X23, Z23, Z23
	VINSERTI64X2 $0x0000000000000002, X23, Z23, Z23
	VINSERTI64X2 $0x0000000000000003, X23, Z23, Z23
	MOVQ         $0x0000000000000033, AX
	KMOVQ        AX, K2
	MOVQ         路vInterleaveIndices+0(SB), DI
	VMOVDQU64    0(DI), Z30

#define PERMUTE2X2(in0, in1) \
	VMOVDQA64 Z30, Z29          \
	VPERMI2Q  in1, in0, Z29     \
	VPBLENDMQ in0, Z29, K2, in0 \
	VPBLENDMQ Z29, in1, K2, in1 \

	PERMUTE2X2(Z0, Z1)
	BUTTERFLY(Z0, Z1)
	MUL_0(Z1, Z23)
	PERMUTE2X2(Z0, Z1)
	PERMUTE2X2(Z2, Z3)
	BUTTERFLY(Z2, Z3)
	MUL_0(Z3, Z23)
	PERMUTE2X2(Z2, Z3)
	PERMUTE2X2(Z4, Z5)
	BUTTERFLY(Z4, Z5)
	MUL_0(Z5, Z23)
	PERMUTE2X2(Z4, Z5)
	PERMUTE2X2(Z6, Z7)
	BUTTERFLY(Z6, Z7)
	MUL_0(Z7, Z23)
	PERMUTE2X2(Z6, Z7)
	PERMUTE2X2(Z8, Z9)
	BUTTERFLY(Z8, Z9)
	MUL_0(Z9, Z23)
	PERMUTE2X2(Z8, Z9)
	PERMUTE2X2(Z10, Z11)
	BUTTERFLY(Z10, Z11)
	MUL_0(Z11, Z23)
	PERMUTE2X2(Z10, Z11)
	PERMUTE2X2(Z12, Z13)
	BUTTERFLY(Z12, Z13)
	MUL_0(Z13, Z23)
	PERMUTE2X2(Z12, Z13)
	PERMUTE2X2(Z14, Z15)
	BUTTERFLY(Z14, Z15)
	MUL_0(Z15, Z23)
	PERMUTE2X2(Z14, Z15)
	MOVQ  $0x0000000000005555, AX
	KMOVD AX, K3

#define PERMUTE1X1(in0, in1) \
	VPSHRDQ   $32, in1, in0, Z21 \
	VPBLENDMD in0, Z21, K3, in0  \
	VPBLENDMD Z21, in1, K3, in1  \

	MOVD         $const_q, AX
	VPBROADCASTD AX, Z17      // rebroadcast q, but on dword lanes

#define LASTBUTTERFLY(in0, in1) \
	VPADDD  in0, in1, Z21 \
	VPSUBD  in1, in0, in1 \
	VPSUBD  Z17, Z21, in0 \
	VPMINUD Z21, in0, in0 \
	VPADDD  Z17, in1, Z22 \
	VPMINUD Z22, in1, in1 \

#define PACK_DWORDS(in0, in1, in2, in3) \
	VPMOVQD      in0, in1          \
	VPMOVQD      in2, in3          \
	VINSERTI64X4 $1, in3, in0, in0 \

	PACK_DWORDS(Z0, Y0, Z1, Y1)
	PACK_DWORDS(Z2, Y2, Z3, Y3)
	PERMUTE1X1(Z0, Z2)
	LASTBUTTERFLY(Z0, Z2)
	PERMUTE1X1(Z0, Z2)
	PACK_DWORDS(Z4, Y4, Z5, Y5)
	PACK_DWORDS(Z6, Y6, Z7, Y7)
	PERMUTE1X1(Z4, Z6)
	LASTBUTTERFLY(Z4, Z6)
	PERMUTE1X1(Z4, Z6)
	PACK_DWORDS(Z8, Y8, Z9, Y9)
	PACK_DWORDS(Z10, Y10, Z11, Y11)
	PERMUTE1X1(Z8, Z10)
	LASTBUTTERFLY(Z8, Z10)
	PERMUTE1X1(Z8, Z10)
	PACK_DWORDS(Z12, Y12, Z13, Y13)
	PACK_DWORDS(Z14, Y14, Z15, Y15)
	PERMUTE1X1(Z12, Z14)
	LASTBUTTERFLY(Z12, Z14)
	PERMUTE1X1(Z12, Z14)

	// store a[:128] in memory
	VMOVDQA32 Z0, 0(R15)
	VMOVDQA32 Z2, 64(R15)
	VMOVDQA32 Z4, 128(R15)
	VMOVDQA32 Z6, 192(R15)
	VMOVDQA32 Z8, 256(R15)
	VMOVDQA32 Z10, 320(R15)
	VMOVDQA32 Z12, 384(R15)
	VMOVDQA32 Z14, 448(R15)
	RET
