//go:build !purego

// Code generated by gnark-crypto/generator. DO NOT EDIT.
// Refer to the generator for more documentation.

#include "textflag.h"
#include "funcdata.h"
#include "go_asm.h"

TEXT 路permutation24_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R15
	MOVQ         roundKeys+24(FP), R14
	VMOVDQU32    0(R15), Z2
	VMOVDQU32    64(R15), Y3
	MOVQ         路diag24+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VMOVDQU32    64(CX), Y20
	VPSRLQ       $32, Z18, Z19
	VPSRLQ       $32, Y20, Y21

#define ADD(in0, in1, in2, in3, in4) \
	VPADDD  in0, in1, in4 \
	VPSUBD  in2, in4, in3 \
	VPMINUD in4, in3, in4 \

#define MAT_MUL_M4(in0, in1, in2, in3, in4, in5) \
	VPSHUFD $0x000000000000004e, in0, in1 \
	ADD(in1, in0, in4, in5, in1)          \
	VPSHUFD $0x00000000000000b1, in1, in2 \
	ADD(in1, in2, in4, in5, in1)          \
	VPSHUFD $0x0000000000000039, in0, in3 \
	VPSLLD  $1, in3, in3                  \
	VPSUBD  in4, in3, in5                 \
	VPMINUD in3, in5, in3                 \
	ADD(in0, in1, in4, in5, in0)          \
	ADD(in0, in3, in4, in5, in0)          \

#define MAT_MUL_EXTERNAL() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	MAT_MUL_M4(Y3, Y6, Y7, Y8, Y0, Y11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	ADD(Y16, Y3, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Y3, Y16, Y0, Y9, Y3)            \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define MULD(in0, in1, in2, in3, in4, in5, in6, in7, in8, in9, in10) \
	VPSRLQ    $32, in0, in2  \
	VPSRLQ    $32, in1, in3  \
	VPMULUDQ  in0, in1, in4  \
	VPMULUDQ  in2, in3, in5  \
	VPMULUDQ  in4, in9, in6  \
	VPMULUDQ  in5, in9, in7  \
	VPMULUDQ  in6, in8, in6  \
	VPADDQ    in4, in6, in4  \
	VPMULUDQ  in7, in8, in7  \
	VPADDQ    in5, in7, in10 \
	VMOVSHDUP in4, K3, in10  \

#define REDUCE1Q(in0, in1, in2) \
	VPSUBD  in0, in1, in2 \
	VPMINUD in1, in2, in1 \

#define SBOX_FULL() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	REDUCE1Q(Z0, Z8, Z15)                                \
	MULD(Z8, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z9) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	MULD(Z2, Z9, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \
	MULD(Y3, Y3, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y8) \
	REDUCE1Q(Y0, Y8, Y15)                                \
	MULD(Y8, Y8, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y9) \
	MULD(Y3, Y8, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y3) \
	MULD(Y3, Y9, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y3) \
	REDUCE1Q(Y0, Y3, Y15)                                \

#define SBOX_PARTIAL() \
	MULD(Y5, Y5, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y8) \
	REDUCE1Q(Y0, Y8, Y15)                                \
	MULD(Y8, Y8, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y9) \
	MULD(Y5, Y8, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y5) \
	MULD(Y5, Y9, Y12, Y13, Y6, Y7, Y14, Y15, Y0, Y1, Y5) \
	REDUCE1Q(Y0, Y5, Y15)                                \

#define SUM_STATE() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y3, Y0, Y11, Y16)                  \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND() \
	VMOVDQU32 0(BX), Z4      \
	VMOVDQU32 64(BX), Y5     \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	ADD(Y3, Y5, Y0, Y8, Y3)  \
	SBOX_FULL()              \
	MAT_MUL_EXTERNAL()       \

	MAT_MUL_EXTERNAL()
	MOVQ 0(R14), BX
	FULL_ROUND()
	MOVQ 24(R14), BX
	FULL_ROUND()
	MOVQ 48(R14), BX
	FULL_ROUND()

	// loop over the partial rounds
	MOVQ $0x0000000000000013, SI // nb partial rounds --> 19
	MOVQ R14, DI
	ADDQ $0x0000000000000048, DI

loop_1:
	TESTQ     SI, SI
	JEQ       done_2
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Y3, Y12
	VPMULUDQ  Y3, Y20, Y6
	VPMULUDQ  Y12, Y21, Y7
	VPMULUDQ  Y6, Y1, Y14
	VPMULUDQ  Y7, Y1, Y15
	VPMULUDQ  Y14, Y0, Y14
	VPADDQ    Y6, Y14, Y6
	VPMULUDQ  Y15, Y0, Y15
	VPADDQ    Y7, Y15, Y9
	VMOVSHDUP Y6, K3, Y9
	VPSUBD    Y0, Y9, Y11
	VPMINUD   Y9, Y11, Y9
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADD(Y9, Y16, Y0, Y5, Y3)
	ADDQ      $24, DI
	JMP       loop_1

done_2:
	MOVQ      528(R14), BX
	FULL_ROUND()
	MOVQ      552(R14), BX
	FULL_ROUND()
	MOVQ      576(R14), BX
	FULL_ROUND()
	VMOVDQU32 Z2, 0(R15)
	VMOVDQU32 Y3, 64(R15)
	RET

TEXT 路permutation16_avx512(SB), NOSPLIT, $0-48
	MOVQ         $0x0000000000005555, AX
	KMOVD        AX, K3
	MOVQ         $1, AX
	KMOVQ        AX, K2
	MOVD         $const_q, AX
	VPBROADCASTD AX, Z0
	MOVD         $const_qInvNeg, AX
	VPBROADCASTD AX, Z1
	MOVQ         input+0(FP), R15
	MOVQ         roundKeys+24(FP), R14
	VMOVDQU32    0(R15), Z2
	MOVQ         路diag16+0(SB), CX
	VMOVDQU32    0(CX), Z18
	VPSRLQ       $32, Z18, Z19

#define MAT_MUL_EXTERNAL_16() \
	MAT_MUL_M4(Z2, Z6, Z7, Z8, Z0, Z11) \
	VEXTRACTI64X4 $1, Z2, Y16           \
	ADD(Y16, Y2, Y0, Y11, Y16)          \
	VSHUFF64X2    $1, Y16, Y16, Y17     \
	ADD(Y16, Y17, Y0, Y11, Y16)         \
	VINSERTI64X4  $1, Y16, Z16, Z16     \
	ADD(Z2, Z16, Z0, Z11, Z2)           \

#define SBOX_FULL_16() \
	MULD(Z2, Z2, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z8) \
	REDUCE1Q(Z0, Z8, Z15)                                \
	MULD(Z8, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z9) \
	MULD(Z2, Z8, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	MULD(Z2, Z9, Z12, Z13, Z6, Z7, Z14, Z15, Z0, Z1, Z2) \
	REDUCE1Q(Z0, Z2, Z15)                                \

#define SUM_STATE_16() \
	VEXTRACTI64X4 $1, Z2, Y16                   \
	ADD(Y16, Y10, Y0, Y11, Y16)                 \
	VSHUFF64X2    $1, Y16, Y16, Y17             \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x000000000000004e, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VPSHUFD       $0x00000000000000b1, Y16, Y17 \
	ADD(Y16, Y17, Y0, Y11, Y16)                 \
	VINSERTI64X4  $1, Y16, Z16, Z16             \

#define FULL_ROUND_16() \
	VMOVDQU32 0(BX), Z4      \
	ADD(Z2, Z4, Z0, Z11, Z2) \
	SBOX_FULL_16()           \
	MAT_MUL_EXTERNAL_16()    \

	MAT_MUL_EXTERNAL_16()
	MOVQ 0(R14), BX
	FULL_ROUND_16()
	MOVQ 24(R14), BX
	FULL_ROUND_16()
	MOVQ 48(R14), BX
	FULL_ROUND_16()

	// loop over the partial rounds
	MOVQ $0x000000000000000c, SI // nb partial rounds --> 12
	MOVQ R14, DI
	ADDQ $0x0000000000000048, DI

loop_3:
	TESTQ     SI, SI
	JEQ       done_4
	DECQ      SI
	MOVQ      0(DI), BX
	VMOVD     0(BX), X4
	VMOVDQA32 Z2, Z10
	ADD(X10, X4, X0, X14, X5)
	SBOX_PARTIAL()
	VPBLENDMD Z5, Z10, K2, Z10
	VPSRLQ    $32, Z2, Z12
	VPMULUDQ  Z12, Z19, Z8
	VPMULUDQ  Z8, Z1, Z15
	VPMULUDQ  Z15, Z0, Z15
	VPADDQ    Z8, Z15, Z8
	SUM_STATE_16()
	VPMULUDQ  Z10, Z18, Z6
	VPMULUDQ  Z6, Z1, Z14
	VPMULUDQ  Z14, Z0, Z14
	VPADDQ    Z6, Z14, Z6
	VMOVSHDUP Z6, K3, Z8
	VPSUBD    Z0, Z8, Z11
	VPMINUD   Z8, Z11, Z2
	ADD(Z2, Z16, Z0, Z11, Z2)
	ADDQ      $24, DI
	JMP       loop_3

done_4:
	MOVQ      360(R14), BX
	FULL_ROUND_16()
	MOVQ      384(R14), BX
	FULL_ROUND_16()
	MOVQ      408(R14), BX
	FULL_ROUND_16()
	VMOVDQU32 Z2, 0(R15)
	RET
