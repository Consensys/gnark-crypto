// Code generated by gnark-crypto/generator. DO NOT EDIT.
#include "textflag.h"
#include "funcdata.h"
#include "go_asm.h"

#define REDUCE(ra0, ra1, ra2, ra3, ra4, ra5, ra6, ra7, ra8, ra9, rb0, rb1, rb2, rb3, rb4, rb5, rb6, rb7, rb8, rb9, q0, q1, q2, q3, q4, q5, q6, q7, q8, q9) \
	MOVQ    ra0, rb0; \
	SUBQ    q0, ra0;  \
	MOVQ    ra1, rb1; \
	SBBQ    q1, ra1;  \
	MOVQ    ra2, rb2; \
	SBBQ    q2, ra2;  \
	MOVQ    ra3, rb3; \
	SBBQ    q3, ra3;  \
	MOVQ    ra4, rb4; \
	SBBQ    q4, ra4;  \
	MOVQ    ra5, rb5; \
	SBBQ    q5, ra5;  \
	MOVQ    ra6, rb6; \
	SBBQ    q6, ra6;  \
	MOVQ    ra7, rb7; \
	SBBQ    q7, ra7;  \
	MOVQ    ra8, rb8; \
	SBBQ    q8, ra8;  \
	MOVQ    ra9, rb9; \
	SBBQ    q9, ra9;  \
	CMOVQCS rb0, ra0; \
	CMOVQCS rb1, ra1; \
	CMOVQCS rb2, ra2; \
	CMOVQCS rb3, ra3; \
	CMOVQCS rb4, ra4; \
	CMOVQCS rb5, ra5; \
	CMOVQCS rb6, ra6; \
	CMOVQCS rb7, ra7; \
	CMOVQCS rb8, ra8; \
	CMOVQCS rb9, ra9; \

TEXT ·reduce(SB), $64-8
	MOVQ res+0(FP), AX
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	RET

// MulBy3(x *Element)
TEXT ·MulBy3(SB), $64-8
	MOVQ x+0(FP), AX
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12
	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ 0(AX), DX
	ADCQ 8(AX), CX
	ADCQ 16(AX), BX
	ADCQ 24(AX), SI
	ADCQ 32(AX), DI
	ADCQ 40(AX), R8
	ADCQ 48(AX), R9
	ADCQ 56(AX), R10
	ADCQ 64(AX), R11
	ADCQ 72(AX), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	RET

// MulBy5(x *Element)
TEXT ·MulBy5(SB), $64-8
	MOVQ x+0(FP), AX
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12
	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ 0(AX), DX
	ADCQ 8(AX), CX
	ADCQ 16(AX), BX
	ADCQ 24(AX), SI
	ADCQ 32(AX), DI
	ADCQ 40(AX), R8
	ADCQ 48(AX), R9
	ADCQ 56(AX), R10
	ADCQ 64(AX), R11
	ADCQ 72(AX), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	RET

// MulBy13(x *Element)
TEXT ·MulBy13(SB), $144-8
	MOVQ x+0(FP), AX
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12
	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (s8-72(SP),s9-80(SP),s10-88(SP),s11-96(SP),s12-104(SP),s13-112(SP),s14-120(SP),s15-128(SP),s16-136(SP),s17-144(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,s8-72(SP),s9-80(SP),s10-88(SP),s11-96(SP),s12-104(SP),s13-112(SP),s14-120(SP),s15-128(SP),s16-136(SP),s17-144(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ DX, s8-72(SP)
	MOVQ CX, s9-80(SP)
	MOVQ BX, s10-88(SP)
	MOVQ SI, s11-96(SP)
	MOVQ DI, s12-104(SP)
	MOVQ R8, s13-112(SP)
	MOVQ R9, s14-120(SP)
	MOVQ R10, s15-128(SP)
	MOVQ R11, s16-136(SP)
	MOVQ R12, s17-144(SP)
	ADDQ DX, DX
	ADCQ CX, CX
	ADCQ BX, BX
	ADCQ SI, SI
	ADCQ DI, DI
	ADCQ R8, R8
	ADCQ R9, R9
	ADCQ R10, R10
	ADCQ R11, R11
	ADCQ R12, R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ s8-72(SP), DX
	ADCQ s9-80(SP), CX
	ADCQ s10-88(SP), BX
	ADCQ s11-96(SP), SI
	ADCQ s12-104(SP), DI
	ADCQ s13-112(SP), R8
	ADCQ s14-120(SP), R9
	ADCQ s15-128(SP), R10
	ADCQ s16-136(SP), R11
	ADCQ s17-144(SP), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	ADDQ 0(AX), DX
	ADCQ 8(AX), CX
	ADCQ 16(AX), BX
	ADCQ 24(AX), SI
	ADCQ 32(AX), DI
	ADCQ 40(AX), R8
	ADCQ 48(AX), R9
	ADCQ 56(AX), R10
	ADCQ 64(AX), R11
	ADCQ 72(AX), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	RET

// Butterfly(a, b *Element) sets a = a + b; b = a - b
TEXT ·Butterfly(SB), $64-16
	MOVQ b+8(FP), AX
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12
	MOVQ a+0(FP), AX
	ADDQ 0(AX), DX
	ADCQ 8(AX), CX
	ADCQ 16(AX), BX
	ADCQ 24(AX), SI
	ADCQ 32(AX), DI
	ADCQ 40(AX), R8
	ADCQ 48(AX), R9
	ADCQ 56(AX), R10
	ADCQ 64(AX), R11
	ADCQ 72(AX), R12
	MOVQ DX, R13
	MOVQ CX, R14
	MOVQ BX, s0-8(SP)
	MOVQ SI, s1-16(SP)
	MOVQ DI, s2-24(SP)
	MOVQ R8, s3-32(SP)
	MOVQ R9, s4-40(SP)
	MOVQ R10, s5-48(SP)
	MOVQ R11, s6-56(SP)
	MOVQ R12, s7-64(SP)
	MOVQ 0(AX), DX
	MOVQ 8(AX), CX
	MOVQ 16(AX), BX
	MOVQ 24(AX), SI
	MOVQ 32(AX), DI
	MOVQ 40(AX), R8
	MOVQ 48(AX), R9
	MOVQ 56(AX), R10
	MOVQ 64(AX), R11
	MOVQ 72(AX), R12
	MOVQ b+8(FP), AX
	SUBQ 0(AX), DX
	SBBQ 8(AX), CX
	SBBQ 16(AX), BX
	SBBQ 24(AX), SI
	SBBQ 32(AX), DI
	SBBQ 40(AX), R8
	SBBQ 48(AX), R9
	SBBQ 56(AX), R10
	SBBQ 64(AX), R11
	SBBQ 72(AX), R12
	JCC  noReduce_1
	MOVQ $const_q0, AX
	ADDQ AX, DX
	MOVQ $const_q1, AX
	ADCQ AX, CX
	MOVQ $const_q2, AX
	ADCQ AX, BX
	MOVQ $const_q3, AX
	ADCQ AX, SI
	MOVQ $const_q4, AX
	ADCQ AX, DI
	MOVQ $const_q5, AX
	ADCQ AX, R8
	MOVQ $const_q6, AX
	ADCQ AX, R9
	MOVQ $const_q7, AX
	ADCQ AX, R10
	MOVQ $const_q8, AX
	ADCQ AX, R11
	MOVQ $const_q9, AX
	ADCQ AX, R12

noReduce_1:
	MOVQ b+8(FP), AX
	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	MOVQ R13, DX
	MOVQ R14, CX
	MOVQ s0-8(SP), BX
	MOVQ s1-16(SP), SI
	MOVQ s2-24(SP), DI
	MOVQ s3-32(SP), R8
	MOVQ s4-40(SP), R9
	MOVQ s5-48(SP), R10
	MOVQ s6-56(SP), R11
	MOVQ s7-64(SP), R12

	// reduce element(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12) using temp registers (R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP))
	REDUCE(DX,CX,BX,SI,DI,R8,R9,R10,R11,R12,R13,R14,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),s7-64(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ a+0(FP), AX
	MOVQ DX, 0(AX)
	MOVQ CX, 8(AX)
	MOVQ BX, 16(AX)
	MOVQ SI, 24(AX)
	MOVQ DI, 32(AX)
	MOVQ R8, 40(AX)
	MOVQ R9, 48(AX)
	MOVQ R10, 56(AX)
	MOVQ R11, 64(AX)
	MOVQ R12, 72(AX)
	RET

// mul(res, x, y *Element)
TEXT ·mul(SB), $56-24

	// Algorithm 2 of "Faster Montgomery Multiplication and Multi-Scalar-Multiplication for SNARKS"
	// by Y. El Housni and G. Botrel https://doi.org/10.46586/tches.v2023.i3.504-521
	// See github.com/consensys/gnark-crypto/internal/generator/field for more comments.

	NO_LOCAL_POINTERS
	CMPB ·supportAdx(SB), $1
	JNE  noAdx_2
	MOVQ x+8(FP), R12

	// A -> BP
	// t[0] -> R14
	// t[1] -> R13
	// t[2] -> CX
	// t[3] -> BX
	// t[4] -> SI
	// t[5] -> DI
	// t[6] -> R8
	// t[7] -> R9
	// t[8] -> R10
	// t[9] -> R11
#define MACC(in0, in1, in2) \
	ADCXQ in0, in1     \
	MULXQ in2, AX, in0 \
	ADOXQ AX, in1      \

#define DIV_SHIFT() \
	PUSHQ BP                         \
	MOVQ  $const_qInvNeg, DX         \
	IMULQ R14, DX                    \
	XORQ  AX, AX                     \
	MULXQ ·qElement+0(SB), AX, BP    \
	ADCXQ R14, AX                    \
	MOVQ  BP, R14                    \
	POPQ  BP                         \
	MACC(R13, R14, ·qElement+8(SB))  \
	MACC(CX, R13, ·qElement+16(SB))  \
	MACC(BX, CX, ·qElement+24(SB))   \
	MACC(SI, BX, ·qElement+32(SB))   \
	MACC(DI, SI, ·qElement+40(SB))   \
	MACC(R8, DI, ·qElement+48(SB))   \
	MACC(R9, R8, ·qElement+56(SB))   \
	MACC(R10, R9, ·qElement+64(SB))  \
	MACC(R11, R10, ·qElement+72(SB)) \
	MOVQ  $0, AX                     \
	ADCXQ AX, R11                    \
	ADOXQ BP, R11                    \

#define MUL_WORD_0() \
	XORQ  AX, AX           \
	MULXQ 0(R12), R14, R13 \
	MULXQ 8(R12), AX, CX   \
	ADOXQ AX, R13          \
	MULXQ 16(R12), AX, BX  \
	ADOXQ AX, CX           \
	MULXQ 24(R12), AX, SI  \
	ADOXQ AX, BX           \
	MULXQ 32(R12), AX, DI  \
	ADOXQ AX, SI           \
	MULXQ 40(R12), AX, R8  \
	ADOXQ AX, DI           \
	MULXQ 48(R12), AX, R9  \
	ADOXQ AX, R8           \
	MULXQ 56(R12), AX, R10 \
	ADOXQ AX, R9           \
	MULXQ 64(R12), AX, R11 \
	ADOXQ AX, R10          \
	MULXQ 72(R12), AX, BP  \
	ADOXQ AX, R11          \
	MOVQ  $0, AX           \
	ADOXQ AX, BP           \
	DIV_SHIFT()            \

#define MUL_WORD_N() \
	XORQ  AX, AX           \
	MULXQ 0(R12), AX, BP   \
	ADOXQ AX, R14          \
	MACC(BP, R13, 8(R12))  \
	MACC(BP, CX, 16(R12))  \
	MACC(BP, BX, 24(R12))  \
	MACC(BP, SI, 32(R12))  \
	MACC(BP, DI, 40(R12))  \
	MACC(BP, R8, 48(R12))  \
	MACC(BP, R9, 56(R12))  \
	MACC(BP, R10, 64(R12)) \
	MACC(BP, R11, 72(R12)) \
	MOVQ  $0, AX           \
	ADCXQ AX, BP           \
	ADOXQ AX, BP           \
	DIV_SHIFT()            \

	// mul body
	MOVQ y+16(FP), AX
	MOVQ 0(AX), DX
	MUL_WORD_0()
	MOVQ y+16(FP), AX
	MOVQ 8(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 16(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 24(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 32(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 40(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 48(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 56(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 64(AX), DX
	MUL_WORD_N()
	MOVQ y+16(FP), AX
	MOVQ 72(AX), DX
	MUL_WORD_N()

	// reduce element(R14,R13,CX,BX,SI,DI,R8,R9,R10,R11) using temp registers (R12,AX,DX,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP))
	REDUCE(R14,R13,CX,BX,SI,DI,R8,R9,R10,R11,R12,AX,DX,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ res+0(FP), AX
	MOVQ R14, 0(AX)
	MOVQ R13, 8(AX)
	MOVQ CX, 16(AX)
	MOVQ BX, 24(AX)
	MOVQ SI, 32(AX)
	MOVQ DI, 40(AX)
	MOVQ R8, 48(AX)
	MOVQ R9, 56(AX)
	MOVQ R10, 64(AX)
	MOVQ R11, 72(AX)
	RET

noAdx_2:
	MOVQ res+0(FP), AX
	MOVQ AX, (SP)
	MOVQ x+8(FP), AX
	MOVQ AX, 8(SP)
	MOVQ y+16(FP), AX
	MOVQ AX, 16(SP)
	CALL ·_mulGeneric(SB)
	RET

TEXT ·fromMont(SB), $56-8
	NO_LOCAL_POINTERS

	// Algorithm 2 of "Faster Montgomery Multiplication and Multi-Scalar-Multiplication for SNARKS"
	// by Y. El Housni and G. Botrel https://doi.org/10.46586/tches.v2023.i3.504-521
	// when y = 1 we have:
	// for i=0 to N-1
	// 		t[i] = x[i]
	// for i=0 to N-1
	// 		m := t[0]*q'[0] mod W
	// 		C,_ := t[0] + m*q[0]
	// 		for j=1 to N-1
	// 		    (C,t[j-1]) := t[j] + m*q[j] + C
	// 		t[N-1] = C
	CMPB ·supportAdx(SB), $1
	JNE  noAdx_3
	MOVQ res+0(FP), DX
	MOVQ 0(DX), R13
	MOVQ 8(DX), R14
	MOVQ 16(DX), CX
	MOVQ 24(DX), BX
	MOVQ 32(DX), SI
	MOVQ 40(DX), DI
	MOVQ 48(DX), R8
	MOVQ 56(DX), R9
	MOVQ 64(DX), R10
	MOVQ 72(DX), R11

#define FROMMONT_STEP() \
	XORQ  DX, DX                    \
	MOVQ  $const_qInvNeg, DX        \
	IMULQ R13, DX                   \
	XORQ  AX, AX                    \
	MULXQ ·qElement+0(SB), AX, BP   \
	ADCXQ R13, AX                   \
	MOVQ  BP, R13                   \
	ADCXQ R14, R13                  \
	MULXQ ·qElement+8(SB), AX, R14  \
	ADOXQ AX, R13                   \
	ADCXQ CX, R14                   \
	MULXQ ·qElement+16(SB), AX, CX  \
	ADOXQ AX, R14                   \
	ADCXQ BX, CX                    \
	MULXQ ·qElement+24(SB), AX, BX  \
	ADOXQ AX, CX                    \
	ADCXQ SI, BX                    \
	MULXQ ·qElement+32(SB), AX, SI  \
	ADOXQ AX, BX                    \
	ADCXQ DI, SI                    \
	MULXQ ·qElement+40(SB), AX, DI  \
	ADOXQ AX, SI                    \
	ADCXQ R8, DI                    \
	MULXQ ·qElement+48(SB), AX, R8  \
	ADOXQ AX, DI                    \
	ADCXQ R9, R8                    \
	MULXQ ·qElement+56(SB), AX, R9  \
	ADOXQ AX, R8                    \
	ADCXQ R10, R9                   \
	MULXQ ·qElement+64(SB), AX, R10 \
	ADOXQ AX, R9                    \
	ADCXQ R11, R10                  \
	MULXQ ·qElement+72(SB), AX, R11 \
	ADOXQ AX, R10                   \
	MOVQ  $0, AX                    \
	ADCXQ AX, R11                   \
	ADOXQ AX, R11                   \

	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()
	FROMMONT_STEP()

	// reduce element(R13,R14,CX,BX,SI,DI,R8,R9,R10,R11) using temp registers (R12,DX,AX,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP))
	REDUCE(R13,R14,CX,BX,SI,DI,R8,R9,R10,R11,R12,DX,AX,s0-8(SP),s1-16(SP),s2-24(SP),s3-32(SP),s4-40(SP),s5-48(SP),s6-56(SP),·qElement+0(SB),·qElement+8(SB),·qElement+16(SB),·qElement+24(SB),·qElement+32(SB),·qElement+40(SB),·qElement+48(SB),·qElement+56(SB),·qElement+64(SB),·qElement+72(SB))

	MOVQ res+0(FP), AX
	MOVQ R13, 0(AX)
	MOVQ R14, 8(AX)
	MOVQ CX, 16(AX)
	MOVQ BX, 24(AX)
	MOVQ SI, 32(AX)
	MOVQ DI, 40(AX)
	MOVQ R8, 48(AX)
	MOVQ R9, 56(AX)
	MOVQ R10, 64(AX)
	MOVQ R11, 72(AX)
	RET

noAdx_3:
	MOVQ res+0(FP), AX
	MOVQ AX, (SP)
	CALL ·_fromMontGeneric(SB)
	RET
