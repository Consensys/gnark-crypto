// Copyright 2020 ConsenSys Software Inc.
//
// Licensed under the Apache License, Version 2.0 (the "License");
// you may not use this file except in compliance with the License.
// You may obtain a copy of the License at
//
//     http://www.apache.org/licenses/LICENSE-2.0
//
// Unless required by applicable law or agreed to in writing, software
// distributed under the License is distributed on an "AS IS" BASIS,
// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
// See the License for the specific language governing permissions and
// limitations under the License.

// Code generated by consensys/gnark-crypto DO NOT EDIT

package integration

// /!\ WARNING /!\
// this code has not been audited and is provided as-is. In particular,
// there is no security guarantees such as constant time implementation
// or side-channel attack resistance
// /!\ WARNING /!\

import (
	"crypto/rand"
	"encoding/binary"
	"errors"
	"io"
	"math/big"
	"math/bits"
	"reflect"
	"strconv"
	"sync"
)

// e_nocarry_0678 represents a field element stored on 11 words (uint64)
// e_nocarry_0678 are assumed to be in Montgomery form in all methods
// field modulus q =
//
// 1058654062366210542707348261040635738628422176539104273545639609027559180696593547265625494794114854467881169431767411906628253351035205252788816853321990772981641735497865805932863530371880400200219371137
type e_nocarry_0678 [11]uint64

// Limbs number of 64 bits words needed to represent e_nocarry_0678
const Limbs = 11

// Bits number bits needed to represent e_nocarry_0678
const Bits = 678

// Bytes number bytes needed to represent e_nocarry_0678
const Bytes = Limbs * 8

// field modulus stored as big.Int
var _modulus big.Int

// Modulus returns q as a big.Int
// q =
//
// 1058654062366210542707348261040635738628422176539104273545639609027559180696593547265625494794114854467881169431767411906628253351035205252788816853321990772981641735497865805932863530371880400200219371137
func Modulus() *big.Int {
	return new(big.Int).Set(&_modulus)
}

// q (modulus)
var qe_nocarry_0678 = e_nocarry_0678{
	13700220646824224385,
	17887507975354087702,
	6486305308265069006,
	7792857504656332695,
	4055812195804746746,
	13375536045193962793,
	15181741591537266872,
	16189485693405468817,
	4219463025600115067,
	18419519222788691264,
	232036787125,
}

// rSquare
var rSquare = e_nocarry_0678{
	273606947743973706,
	3464412692890843633,
	8435940272544525640,
	5308656646191584475,
	17330634774425083023,
	9222672958909094740,
	16418759808934922843,
	9149088793907112252,
	2768222490739974539,
	8007561342473828858,
	217755447783,
}

var bigIntPool = sync.Pool{
	New: func() interface{} {
		return new(big.Int)
	},
}

func init() {
	_modulus.SetString("1058654062366210542707348261040635738628422176539104273545639609027559180696593547265625494794114854467881169431767411906628253351035205252788816853321990772981641735497865805932863530371880400200219371137", 10)
}

// SetUint64 z = v, sets z LSB to v (non-Montgomery form) and convert z to Montgomery form
func (z *e_nocarry_0678) SetUint64(v uint64) *e_nocarry_0678 {
	*z = e_nocarry_0678{v}
	return z.Mul(z, &rSquare) // z.ToMont()
}

// Set z = x
func (z *e_nocarry_0678) Set(x *e_nocarry_0678) *e_nocarry_0678 {
	z[0] = x[0]
	z[1] = x[1]
	z[2] = x[2]
	z[3] = x[3]
	z[4] = x[4]
	z[5] = x[5]
	z[6] = x[6]
	z[7] = x[7]
	z[8] = x[8]
	z[9] = x[9]
	z[10] = x[10]
	return z
}

// SetInterface converts provided interface into e_nocarry_0678
// returns an error if provided type is not supported
// supported types: e_nocarry_0678, *e_nocarry_0678, uint64, int, string (interpreted as base10 integer),
// *big.Int, big.Int, []byte
func (z *e_nocarry_0678) SetInterface(i1 interface{}) (*e_nocarry_0678, error) {
	switch c1 := i1.(type) {
	case e_nocarry_0678:
		return z.Set(&c1), nil
	case *e_nocarry_0678:
		return z.Set(c1), nil
	case uint64:
		return z.SetUint64(c1), nil
	case int:
		return z.SetString(strconv.Itoa(c1)), nil
	case string:
		return z.SetString(c1), nil
	case *big.Int:
		return z.SetBigInt(c1), nil
	case big.Int:
		return z.SetBigInt(&c1), nil
	case []byte:
		return z.SetBytes(c1), nil
	default:
		return nil, errors.New("can't set integration.e_nocarry_0678 from type " + reflect.TypeOf(i1).String())
	}
}

// SetZero z = 0
func (z *e_nocarry_0678) SetZero() *e_nocarry_0678 {
	z[0] = 0
	z[1] = 0
	z[2] = 0
	z[3] = 0
	z[4] = 0
	z[5] = 0
	z[6] = 0
	z[7] = 0
	z[8] = 0
	z[9] = 0
	z[10] = 0
	return z
}

// SetOne z = 1 (in Montgomery form)
func (z *e_nocarry_0678) SetOne() *e_nocarry_0678 {
	z[0] = 1524065517792215338
	z[1] = 4800134143431380907
	z[2] = 18337981507651457660
	z[3] = 6412496358938960977
	z[4] = 9040225342748635458
	z[5] = 14701590944609981104
	z[6] = 6728674352238750255
	z[7] = 8249970787276725507
	z[8] = 15052145014553235051
	z[9] = 16431850113554908022
	z[10] = 21813052973
	return z
}

// Div z = x*y^-1 mod q
func (z *e_nocarry_0678) Div(x, y *e_nocarry_0678) *e_nocarry_0678 {
	var yInv e_nocarry_0678
	yInv.Inverse(y)
	z.Mul(x, &yInv)
	return z
}

// Bit returns the i'th bit, with lsb == bit 0.
// It is the responsability of the caller to convert from Montgomery to Regular form if needed
func (z *e_nocarry_0678) Bit(i uint64) uint64 {
	j := i / 64
	if j >= 11 {
		return 0
	}
	return uint64(z[j] >> (i % 64) & 1)
}

// Equal returns z == x
func (z *e_nocarry_0678) Equal(x *e_nocarry_0678) bool {
	return (z[10] == x[10]) && (z[9] == x[9]) && (z[8] == x[8]) && (z[7] == x[7]) && (z[6] == x[6]) && (z[5] == x[5]) && (z[4] == x[4]) && (z[3] == x[3]) && (z[2] == x[2]) && (z[1] == x[1]) && (z[0] == x[0])
}

// IsZero returns z == 0
func (z *e_nocarry_0678) IsZero() bool {
	return (z[10] | z[9] | z[8] | z[7] | z[6] | z[5] | z[4] | z[3] | z[2] | z[1] | z[0]) == 0
}

// IsUint64 returns true if z[0] >= 0 and all other words are 0
func (z *e_nocarry_0678) IsUint64() bool {
	return (z[10] | z[9] | z[8] | z[7] | z[6] | z[5] | z[4] | z[3] | z[2] | z[1]) == 0
}

// Cmp compares (lexicographic order) z and x and returns:
//
//   -1 if z <  x
//    0 if z == x
//   +1 if z >  x
//
func (z *e_nocarry_0678) Cmp(x *e_nocarry_0678) int {
	_z := *z
	_x := *x
	_z.FromMont()
	_x.FromMont()
	if _z[10] > _x[10] {
		return 1
	} else if _z[10] < _x[10] {
		return -1
	}
	if _z[9] > _x[9] {
		return 1
	} else if _z[9] < _x[9] {
		return -1
	}
	if _z[8] > _x[8] {
		return 1
	} else if _z[8] < _x[8] {
		return -1
	}
	if _z[7] > _x[7] {
		return 1
	} else if _z[7] < _x[7] {
		return -1
	}
	if _z[6] > _x[6] {
		return 1
	} else if _z[6] < _x[6] {
		return -1
	}
	if _z[5] > _x[5] {
		return 1
	} else if _z[5] < _x[5] {
		return -1
	}
	if _z[4] > _x[4] {
		return 1
	} else if _z[4] < _x[4] {
		return -1
	}
	if _z[3] > _x[3] {
		return 1
	} else if _z[3] < _x[3] {
		return -1
	}
	if _z[2] > _x[2] {
		return 1
	} else if _z[2] < _x[2] {
		return -1
	}
	if _z[1] > _x[1] {
		return 1
	} else if _z[1] < _x[1] {
		return -1
	}
	if _z[0] > _x[0] {
		return 1
	} else if _z[0] < _x[0] {
		return -1
	}
	return 0
}

// LexicographicallyLargest returns true if this element is strictly lexicographically
// larger than its negation, false otherwise
func (z *e_nocarry_0678) LexicographicallyLargest() bool {
	// adapted from github.com/zkcrypto/bls12_381
	// we check if the element is larger than (q-1) / 2
	// if z - (((q -1) / 2) + 1) have no underflow, then z > (q-1) / 2

	_z := *z
	_z.FromMont()

	var b uint64
	_, b = bits.Sub64(_z[0], 6850110323412112193, 0)
	_, b = bits.Sub64(_z[1], 8943753987677043851, b)
	_, b = bits.Sub64(_z[2], 12466524690987310311, b)
	_, b = bits.Sub64(_z[3], 3896428752328166347, b)
	_, b = bits.Sub64(_z[4], 11251278134757149181, b)
	_, b = bits.Sub64(_z[5], 6687768022596981396, b)
	_, b = bits.Sub64(_z[6], 16814242832623409244, b)
	_, b = bits.Sub64(_z[7], 17318114883557510216, b)
	_, b = bits.Sub64(_z[8], 2109731512800057533, b)
	_, b = bits.Sub64(_z[9], 18433131648249121440, b)
	_, b = bits.Sub64(_z[10], 116018393562, b)

	return b == 0
}

// SetRandom sets z to a random element < q
func (z *e_nocarry_0678) SetRandom() (*e_nocarry_0678, error) {
	var bytes [88]byte
	if _, err := io.ReadFull(rand.Reader, bytes[:]); err != nil {
		return nil, err
	}
	z[0] = binary.BigEndian.Uint64(bytes[0:8])
	z[1] = binary.BigEndian.Uint64(bytes[8:16])
	z[2] = binary.BigEndian.Uint64(bytes[16:24])
	z[3] = binary.BigEndian.Uint64(bytes[24:32])
	z[4] = binary.BigEndian.Uint64(bytes[32:40])
	z[5] = binary.BigEndian.Uint64(bytes[40:48])
	z[6] = binary.BigEndian.Uint64(bytes[48:56])
	z[7] = binary.BigEndian.Uint64(bytes[56:64])
	z[8] = binary.BigEndian.Uint64(bytes[64:72])
	z[9] = binary.BigEndian.Uint64(bytes[72:80])
	z[10] = binary.BigEndian.Uint64(bytes[80:88])
	z[10] %= 232036787125

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}

	return z, nil
}

// One returns 1 (in montgommery form)
func One() e_nocarry_0678 {
	var one e_nocarry_0678
	one.SetOne()
	return one
}

// Halve sets z to z / 2 (mod p)
func (z *e_nocarry_0678) Halve() {
	if z[0]&1 == 1 {
		var carry uint64

		// z = z + q
		z[0], carry = bits.Add64(z[0], 13700220646824224385, 0)
		z[1], carry = bits.Add64(z[1], 17887507975354087702, carry)
		z[2], carry = bits.Add64(z[2], 6486305308265069006, carry)
		z[3], carry = bits.Add64(z[3], 7792857504656332695, carry)
		z[4], carry = bits.Add64(z[4], 4055812195804746746, carry)
		z[5], carry = bits.Add64(z[5], 13375536045193962793, carry)
		z[6], carry = bits.Add64(z[6], 15181741591537266872, carry)
		z[7], carry = bits.Add64(z[7], 16189485693405468817, carry)
		z[8], carry = bits.Add64(z[8], 4219463025600115067, carry)
		z[9], carry = bits.Add64(z[9], 18419519222788691264, carry)
		z[10], _ = bits.Add64(z[10], 232036787125, carry)

	}

	// z = z >> 1

	z[0] = z[0]>>1 | z[1]<<63
	z[1] = z[1]>>1 | z[2]<<63
	z[2] = z[2]>>1 | z[3]<<63
	z[3] = z[3]>>1 | z[4]<<63
	z[4] = z[4]>>1 | z[5]<<63
	z[5] = z[5]>>1 | z[6]<<63
	z[6] = z[6]>>1 | z[7]<<63
	z[7] = z[7]>>1 | z[8]<<63
	z[8] = z[8]>>1 | z[9]<<63
	z[9] = z[9]>>1 | z[10]<<63
	z[10] >>= 1

}

// API with assembly impl

// Mul z = x * y mod q
// see https://hackmd.io/@zkteam/modular_multiplication
func (z *e_nocarry_0678) Mul(x, y *e_nocarry_0678) *e_nocarry_0678 {
	mul(z, x, y)
	return z
}

// Square z = x * x mod q
// see https://hackmd.io/@zkteam/modular_multiplication
func (z *e_nocarry_0678) Square(x *e_nocarry_0678) *e_nocarry_0678 {
	mul(z, x, x)
	return z
}

// FromMont converts z in place (i.e. mutates) from Montgomery to regular representation
// sets and returns z = z * 1
func (z *e_nocarry_0678) FromMont() *e_nocarry_0678 {
	fromMont(z)
	return z
}

// Add z = x + y mod q
func (z *e_nocarry_0678) Add(x, y *e_nocarry_0678) *e_nocarry_0678 {
	add(z, x, y)
	return z
}

// Double z = x + x mod q, aka Lsh 1
func (z *e_nocarry_0678) Double(x *e_nocarry_0678) *e_nocarry_0678 {
	double(z, x)
	return z
}

// Sub  z = x - y mod q
func (z *e_nocarry_0678) Sub(x, y *e_nocarry_0678) *e_nocarry_0678 {
	sub(z, x, y)
	return z
}

// Neg z = q - x
func (z *e_nocarry_0678) Neg(x *e_nocarry_0678) *e_nocarry_0678 {
	neg(z, x)
	return z
}

// Generic (no ADX instructions, no AMD64) versions of multiplication and squaring algorithms

func _mulGeneric(z, x, y *e_nocarry_0678) {

	var t [11]uint64
	var c [3]uint64
	{
		// round 0
		v := x[0]
		c[1], c[0] = bits.Mul64(v, y[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd1(v, y[1], c[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd1(v, y[2], c[1])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd1(v, y[3], c[1])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd1(v, y[4], c[1])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd1(v, y[5], c[1])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd1(v, y[6], c[1])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd1(v, y[7], c[1])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd1(v, y[8], c[1])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd1(v, y[9], c[1])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd1(v, y[10], c[1])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 1
		v := x[1]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 2
		v := x[2]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 3
		v := x[3]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 4
		v := x[4]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 5
		v := x[5]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 6
		v := x[6]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 7
		v := x[7]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 8
		v := x[8]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 9
		v := x[9]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], t[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], t[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], t[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], t[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], t[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], t[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], t[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], t[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], t[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		t[10], t[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}
	{
		// round 10
		v := x[10]
		c[1], c[0] = madd1(v, y[0], t[0])
		m := c[0] * 15045236321440491135
		c[2] = madd0(m, 13700220646824224385, c[0])
		c[1], c[0] = madd2(v, y[1], c[1], t[1])
		c[2], z[0] = madd2(m, 17887507975354087702, c[2], c[0])
		c[1], c[0] = madd2(v, y[2], c[1], t[2])
		c[2], z[1] = madd2(m, 6486305308265069006, c[2], c[0])
		c[1], c[0] = madd2(v, y[3], c[1], t[3])
		c[2], z[2] = madd2(m, 7792857504656332695, c[2], c[0])
		c[1], c[0] = madd2(v, y[4], c[1], t[4])
		c[2], z[3] = madd2(m, 4055812195804746746, c[2], c[0])
		c[1], c[0] = madd2(v, y[5], c[1], t[5])
		c[2], z[4] = madd2(m, 13375536045193962793, c[2], c[0])
		c[1], c[0] = madd2(v, y[6], c[1], t[6])
		c[2], z[5] = madd2(m, 15181741591537266872, c[2], c[0])
		c[1], c[0] = madd2(v, y[7], c[1], t[7])
		c[2], z[6] = madd2(m, 16189485693405468817, c[2], c[0])
		c[1], c[0] = madd2(v, y[8], c[1], t[8])
		c[2], z[7] = madd2(m, 4219463025600115067, c[2], c[0])
		c[1], c[0] = madd2(v, y[9], c[1], t[9])
		c[2], z[8] = madd2(m, 18419519222788691264, c[2], c[0])
		c[1], c[0] = madd2(v, y[10], c[1], t[10])
		z[10], z[9] = madd3(m, 232036787125, c[0], c[2], c[1])
	}

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func _mulWGeneric(z, x *e_nocarry_0678, y uint64) {

	var t [11]uint64
	{
		// round 0
		c1, c0 := bits.Mul64(y, x[0])
		m := c0 * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, c0)
		c1, c0 = madd1(y, x[1], c1)
		c2, t[0] = madd2(m, 17887507975354087702, c2, c0)
		c1, c0 = madd1(y, x[2], c1)
		c2, t[1] = madd2(m, 6486305308265069006, c2, c0)
		c1, c0 = madd1(y, x[3], c1)
		c2, t[2] = madd2(m, 7792857504656332695, c2, c0)
		c1, c0 = madd1(y, x[4], c1)
		c2, t[3] = madd2(m, 4055812195804746746, c2, c0)
		c1, c0 = madd1(y, x[5], c1)
		c2, t[4] = madd2(m, 13375536045193962793, c2, c0)
		c1, c0 = madd1(y, x[6], c1)
		c2, t[5] = madd2(m, 15181741591537266872, c2, c0)
		c1, c0 = madd1(y, x[7], c1)
		c2, t[6] = madd2(m, 16189485693405468817, c2, c0)
		c1, c0 = madd1(y, x[8], c1)
		c2, t[7] = madd2(m, 4219463025600115067, c2, c0)
		c1, c0 = madd1(y, x[9], c1)
		c2, t[8] = madd2(m, 18419519222788691264, c2, c0)
		c1, c0 = madd1(y, x[10], c1)
		t[10], t[9] = madd3(m, 232036787125, c0, c2, c1)
	}
	{
		// round 1
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 2
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 3
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 4
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 5
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 6
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 7
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 8
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 9
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, t[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, t[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, t[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, t[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, t[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, t[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, t[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, t[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, t[8] = madd2(m, 18419519222788691264, c2, t[9])
		t[10], t[9] = madd2(m, 232036787125, t[10], c2)
	}
	{
		// round 10
		m := t[0] * 15045236321440491135
		c2 := madd0(m, 13700220646824224385, t[0])
		c2, z[0] = madd2(m, 17887507975354087702, c2, t[1])
		c2, z[1] = madd2(m, 6486305308265069006, c2, t[2])
		c2, z[2] = madd2(m, 7792857504656332695, c2, t[3])
		c2, z[3] = madd2(m, 4055812195804746746, c2, t[4])
		c2, z[4] = madd2(m, 13375536045193962793, c2, t[5])
		c2, z[5] = madd2(m, 15181741591537266872, c2, t[6])
		c2, z[6] = madd2(m, 16189485693405468817, c2, t[7])
		c2, z[7] = madd2(m, 4219463025600115067, c2, t[8])
		c2, z[8] = madd2(m, 18419519222788691264, c2, t[9])
		z[10], z[9] = madd2(m, 232036787125, t[10], c2)
	}

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func _fromMontGeneric(z *e_nocarry_0678) {
	// the following lines implement z = z * 1
	// with a modified CIOS montgomery multiplication
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}
	{
		// m = z[0]n'[0] mod W
		m := z[0] * 15045236321440491135
		C := madd0(m, 13700220646824224385, z[0])
		C, z[0] = madd2(m, 17887507975354087702, z[1], C)
		C, z[1] = madd2(m, 6486305308265069006, z[2], C)
		C, z[2] = madd2(m, 7792857504656332695, z[3], C)
		C, z[3] = madd2(m, 4055812195804746746, z[4], C)
		C, z[4] = madd2(m, 13375536045193962793, z[5], C)
		C, z[5] = madd2(m, 15181741591537266872, z[6], C)
		C, z[6] = madd2(m, 16189485693405468817, z[7], C)
		C, z[7] = madd2(m, 4219463025600115067, z[8], C)
		C, z[8] = madd2(m, 18419519222788691264, z[9], C)
		C, z[9] = madd2(m, 232036787125, z[10], C)
		z[10] = C
	}

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func _addGeneric(z, x, y *e_nocarry_0678) {
	var carry uint64

	z[0], carry = bits.Add64(x[0], y[0], 0)
	z[1], carry = bits.Add64(x[1], y[1], carry)
	z[2], carry = bits.Add64(x[2], y[2], carry)
	z[3], carry = bits.Add64(x[3], y[3], carry)
	z[4], carry = bits.Add64(x[4], y[4], carry)
	z[5], carry = bits.Add64(x[5], y[5], carry)
	z[6], carry = bits.Add64(x[6], y[6], carry)
	z[7], carry = bits.Add64(x[7], y[7], carry)
	z[8], carry = bits.Add64(x[8], y[8], carry)
	z[9], carry = bits.Add64(x[9], y[9], carry)
	z[10], _ = bits.Add64(x[10], y[10], carry)

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func _doubleGeneric(z, x *e_nocarry_0678) {
	var carry uint64

	z[0], carry = bits.Add64(x[0], x[0], 0)
	z[1], carry = bits.Add64(x[1], x[1], carry)
	z[2], carry = bits.Add64(x[2], x[2], carry)
	z[3], carry = bits.Add64(x[3], x[3], carry)
	z[4], carry = bits.Add64(x[4], x[4], carry)
	z[5], carry = bits.Add64(x[5], x[5], carry)
	z[6], carry = bits.Add64(x[6], x[6], carry)
	z[7], carry = bits.Add64(x[7], x[7], carry)
	z[8], carry = bits.Add64(x[8], x[8], carry)
	z[9], carry = bits.Add64(x[9], x[9], carry)
	z[10], _ = bits.Add64(x[10], x[10], carry)

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func _subGeneric(z, x, y *e_nocarry_0678) {
	var b uint64
	z[0], b = bits.Sub64(x[0], y[0], 0)
	z[1], b = bits.Sub64(x[1], y[1], b)
	z[2], b = bits.Sub64(x[2], y[2], b)
	z[3], b = bits.Sub64(x[3], y[3], b)
	z[4], b = bits.Sub64(x[4], y[4], b)
	z[5], b = bits.Sub64(x[5], y[5], b)
	z[6], b = bits.Sub64(x[6], y[6], b)
	z[7], b = bits.Sub64(x[7], y[7], b)
	z[8], b = bits.Sub64(x[8], y[8], b)
	z[9], b = bits.Sub64(x[9], y[9], b)
	z[10], b = bits.Sub64(x[10], y[10], b)
	if b != 0 {
		var c uint64
		z[0], c = bits.Add64(z[0], 13700220646824224385, 0)
		z[1], c = bits.Add64(z[1], 17887507975354087702, c)
		z[2], c = bits.Add64(z[2], 6486305308265069006, c)
		z[3], c = bits.Add64(z[3], 7792857504656332695, c)
		z[4], c = bits.Add64(z[4], 4055812195804746746, c)
		z[5], c = bits.Add64(z[5], 13375536045193962793, c)
		z[6], c = bits.Add64(z[6], 15181741591537266872, c)
		z[7], c = bits.Add64(z[7], 16189485693405468817, c)
		z[8], c = bits.Add64(z[8], 4219463025600115067, c)
		z[9], c = bits.Add64(z[9], 18419519222788691264, c)
		z[10], _ = bits.Add64(z[10], 232036787125, c)
	}
}

func _negGeneric(z, x *e_nocarry_0678) {
	if x.IsZero() {
		z.SetZero()
		return
	}
	var borrow uint64
	z[0], borrow = bits.Sub64(13700220646824224385, x[0], 0)
	z[1], borrow = bits.Sub64(17887507975354087702, x[1], borrow)
	z[2], borrow = bits.Sub64(6486305308265069006, x[2], borrow)
	z[3], borrow = bits.Sub64(7792857504656332695, x[3], borrow)
	z[4], borrow = bits.Sub64(4055812195804746746, x[4], borrow)
	z[5], borrow = bits.Sub64(13375536045193962793, x[5], borrow)
	z[6], borrow = bits.Sub64(15181741591537266872, x[6], borrow)
	z[7], borrow = bits.Sub64(16189485693405468817, x[7], borrow)
	z[8], borrow = bits.Sub64(4219463025600115067, x[8], borrow)
	z[9], borrow = bits.Sub64(18419519222788691264, x[9], borrow)
	z[10], _ = bits.Sub64(232036787125, x[10], borrow)
}

func _reduceGeneric(z *e_nocarry_0678) {

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
}

func mulByConstant(z *e_nocarry_0678, c uint8) {
	switch c {
	case 0:
		z.SetZero()
		return
	case 1:
		return
	case 2:
		z.Double(z)
		return
	case 3:
		_z := *z
		z.Double(z).Add(z, &_z)
	case 5:
		_z := *z
		z.Double(z).Double(z).Add(z, &_z)
	default:
		var y e_nocarry_0678
		y.SetUint64(uint64(c))
		z.Mul(z, &y)
	}
}

// BatchInvert returns a new slice with every element inverted.
// Uses Montgomery batch inversion trick
func BatchInvert(a []e_nocarry_0678) []e_nocarry_0678 {
	res := make([]e_nocarry_0678, len(a))
	if len(a) == 0 {
		return res
	}

	zeroes := make([]bool, len(a))
	accumulator := One()

	for i := 0; i < len(a); i++ {
		if a[i].IsZero() {
			zeroes[i] = true
			continue
		}
		res[i] = accumulator
		accumulator.Mul(&accumulator, &a[i])
	}

	accumulator.Inverse(&accumulator)

	for i := len(a) - 1; i >= 0; i-- {
		if zeroes[i] {
			continue
		}
		res[i].Mul(&res[i], &accumulator)
		accumulator.Mul(&accumulator, &a[i])
	}

	return res
}

func _butterflyGeneric(a, b *e_nocarry_0678) {
	t := *a
	a.Add(a, b)
	b.Sub(&t, b)
}

// BitLen returns the minimum number of bits needed to represent z
// returns 0 if z == 0
func (z *e_nocarry_0678) BitLen() int {
	if z[10] != 0 {
		return 640 + bits.Len64(z[10])
	}
	if z[9] != 0 {
		return 576 + bits.Len64(z[9])
	}
	if z[8] != 0 {
		return 512 + bits.Len64(z[8])
	}
	if z[7] != 0 {
		return 448 + bits.Len64(z[7])
	}
	if z[6] != 0 {
		return 384 + bits.Len64(z[6])
	}
	if z[5] != 0 {
		return 320 + bits.Len64(z[5])
	}
	if z[4] != 0 {
		return 256 + bits.Len64(z[4])
	}
	if z[3] != 0 {
		return 192 + bits.Len64(z[3])
	}
	if z[2] != 0 {
		return 128 + bits.Len64(z[2])
	}
	if z[1] != 0 {
		return 64 + bits.Len64(z[1])
	}
	return bits.Len64(z[0])
}

// Exp z = x^exponent mod q
func (z *e_nocarry_0678) Exp(x e_nocarry_0678, exponent *big.Int) *e_nocarry_0678 {
	var bZero big.Int
	if exponent.Cmp(&bZero) == 0 {
		return z.SetOne()
	}

	z.Set(&x)

	for i := exponent.BitLen() - 2; i >= 0; i-- {
		z.Square(z)
		if exponent.Bit(i) == 1 {
			z.Mul(z, &x)
		}
	}

	return z
}

// ToMont converts z to Montgomery form
// sets and returns z = z * r^2
func (z *e_nocarry_0678) ToMont() *e_nocarry_0678 {
	return z.Mul(z, &rSquare)
}

// ToRegular returns z in regular form (doesn't mutate z)
func (z e_nocarry_0678) ToRegular() e_nocarry_0678 {
	return *z.FromMont()
}

// String returns the string form of an e_nocarry_0678 in Montgomery form
func (z *e_nocarry_0678) String() string {
	zz := *z
	zz.FromMont()
	if zz.IsUint64() {
		return strconv.FormatUint(zz[0], 10)
	} else {
		var zzNeg e_nocarry_0678
		zzNeg.Neg(z)
		zzNeg.FromMont()
		if zzNeg.IsUint64() {
			return "-" + strconv.FormatUint(zzNeg[0], 10)
		}
	}
	vv := bigIntPool.Get().(*big.Int)
	defer bigIntPool.Put(vv)
	return zz.ToBigInt(vv).String()
}

// ToBigInt returns z as a big.Int in Montgomery form
func (z *e_nocarry_0678) ToBigInt(res *big.Int) *big.Int {
	var b [Limbs * 8]byte
	binary.BigEndian.PutUint64(b[80:88], z[0])
	binary.BigEndian.PutUint64(b[72:80], z[1])
	binary.BigEndian.PutUint64(b[64:72], z[2])
	binary.BigEndian.PutUint64(b[56:64], z[3])
	binary.BigEndian.PutUint64(b[48:56], z[4])
	binary.BigEndian.PutUint64(b[40:48], z[5])
	binary.BigEndian.PutUint64(b[32:40], z[6])
	binary.BigEndian.PutUint64(b[24:32], z[7])
	binary.BigEndian.PutUint64(b[16:24], z[8])
	binary.BigEndian.PutUint64(b[8:16], z[9])
	binary.BigEndian.PutUint64(b[0:8], z[10])

	return res.SetBytes(b[:])
}

// ToBigIntRegular returns z as a big.Int in regular form
func (z e_nocarry_0678) ToBigIntRegular(res *big.Int) *big.Int {
	z.FromMont()
	return z.ToBigInt(res)
}

// Bytes returns the regular (non montgomery) value
// of z as a big-endian byte array.
func (z *e_nocarry_0678) Bytes() (res [Limbs * 8]byte) {
	_z := z.ToRegular()
	binary.BigEndian.PutUint64(res[80:88], _z[0])
	binary.BigEndian.PutUint64(res[72:80], _z[1])
	binary.BigEndian.PutUint64(res[64:72], _z[2])
	binary.BigEndian.PutUint64(res[56:64], _z[3])
	binary.BigEndian.PutUint64(res[48:56], _z[4])
	binary.BigEndian.PutUint64(res[40:48], _z[5])
	binary.BigEndian.PutUint64(res[32:40], _z[6])
	binary.BigEndian.PutUint64(res[24:32], _z[7])
	binary.BigEndian.PutUint64(res[16:24], _z[8])
	binary.BigEndian.PutUint64(res[8:16], _z[9])
	binary.BigEndian.PutUint64(res[0:8], _z[10])

	return
}

// Marshal returns the regular (non montgomery) value
// of z as a big-endian byte slice.
func (z *e_nocarry_0678) Marshal() []byte {
	b := z.Bytes()
	return b[:]
}

// SetBytes interprets e as the bytes of a big-endian unsigned integer,
// sets z to that value (in Montgomery form), and returns z.
func (z *e_nocarry_0678) SetBytes(e []byte) *e_nocarry_0678 {
	// get a big int from our pool
	vv := bigIntPool.Get().(*big.Int)
	vv.SetBytes(e)

	// set big int
	z.SetBigInt(vv)

	// put temporary object back in pool
	bigIntPool.Put(vv)

	return z
}

// SetBigInt sets z to v (regular form) and returns z in Montgomery form
func (z *e_nocarry_0678) SetBigInt(v *big.Int) *e_nocarry_0678 {
	z.SetZero()

	var zero big.Int

	// fast path
	c := v.Cmp(&_modulus)
	if c == 0 {
		// v == 0
		return z
	} else if c != 1 && v.Cmp(&zero) != -1 {
		// 0 < v < q
		return z.setBigInt(v)
	}

	// get temporary big int from the pool
	vv := bigIntPool.Get().(*big.Int)

	// copy input + modular reduction
	vv.Set(v)
	vv.Mod(v, &_modulus)

	// set big int byte value
	z.setBigInt(vv)

	// release object into pool
	bigIntPool.Put(vv)
	return z
}

// setBigInt assumes 0 <= v < q
func (z *e_nocarry_0678) setBigInt(v *big.Int) *e_nocarry_0678 {
	vBits := v.Bits()

	if bits.UintSize == 64 {
		for i := 0; i < len(vBits); i++ {
			z[i] = uint64(vBits[i])
		}
	} else {
		for i := 0; i < len(vBits); i++ {
			if i%2 == 0 {
				z[i/2] = uint64(vBits[i])
			} else {
				z[i/2] |= uint64(vBits[i]) << 32
			}
		}
	}

	return z.ToMont()
}

// SetString creates a big.Int with s (in base 10) and calls SetBigInt on z
func (z *e_nocarry_0678) SetString(s string) *e_nocarry_0678 {
	// get temporary big int from the pool
	vv := bigIntPool.Get().(*big.Int)

	if _, ok := vv.SetString(s, 10); !ok {
		panic("e_nocarry_0678.SetString failed -> can't parse number in base10 into a big.Int")
	}
	z.SetBigInt(vv)

	// release object into pool
	bigIntPool.Put(vv)

	return z
}

var (
	_bLegendreExponente_nocarry_0678 *big.Int
	_bSqrtExponente_nocarry_0678     *big.Int
)

func init() {
	_bLegendreExponente_nocarry_0678, _ = new(big.Int).SetString("1b033c31daffcfa39237e64aa01d4745a20fe518bdf0564dbb35d9cc48e95830c545ad185c5ccfb9954f1c12949c2491da0b51c9fd3612e54e5b238bcbad01fe27edef5ce77c1e98dda1f93c8b5f107b0bb3371340", 16)
	const sqrtExponente_nocarry_0678 = "36067863b5ff9f47246fcc95403a8e8b441fca317be0ac9b766bb39891d2b0618a8b5a30b8b99f732a9e382529384923b416a393fa6c25ca9cb64717975a03fc4fdbdeb9cef83d31bb43f27916be20f617666e26"
	_bSqrtExponente_nocarry_0678, _ = new(big.Int).SetString(sqrtExponente_nocarry_0678, 16)
}

// Legendre returns the Legendre symbol of z (either +1, -1, or 0.)
func (z *e_nocarry_0678) Legendre() int {
	var l e_nocarry_0678
	// z^((q-1)/2)
	l.Exp(*z, _bLegendreExponente_nocarry_0678)

	if l.IsZero() {
		return 0
	}

	// if l == 1
	if (l[10] == 21813052973) && (l[9] == 16431850113554908022) && (l[8] == 15052145014553235051) && (l[7] == 8249970787276725507) && (l[6] == 6728674352238750255) && (l[5] == 14701590944609981104) && (l[4] == 9040225342748635458) && (l[3] == 6412496358938960977) && (l[2] == 18337981507651457660) && (l[1] == 4800134143431380907) && (l[0] == 1524065517792215338) {
		return 1
	}
	return -1
}

// Sqrt z = x mod q
// if the square root doesn't exist (x is not a square mod q)
// Sqrt leaves z unchanged and returns nil
func (z *e_nocarry_0678) Sqrt(x *e_nocarry_0678) *e_nocarry_0678 {
	// q  1 (mod 4)
	// see modSqrtTonelliShanks in math/big/int.go
	// using https://www.maa.org/sites/default/files/pdf/upload_library/22/Polya/07468342.di020786.02p0470a.pdf

	var y, b, t, w e_nocarry_0678
	// w = x^((s-1)/2))
	w.Exp(*x, _bSqrtExponente_nocarry_0678)

	// y = x^((s+1)/2)) = w * x
	y.Mul(x, &w)

	// b = x^s = w * w * x = y * x
	b.Mul(&w, &y)

	// g = nonResidue ^ s
	var g = e_nocarry_0678{
		7471151521925881588,
		7291261407360313756,
		7185608345594518870,
		17716871114029531393,
		11361034534266485856,
		6140863479667099398,
		17972983931288810535,
		18199615693407198066,
		4924584716324613363,
		17014288962846861858,
		186685363864,
	}
	r := uint64(7)

	// compute legendre symbol
	// t = x^((q-1)/2) = r-1 squaring of x^s
	t = b
	for i := uint64(0); i < r-1; i++ {
		t.Square(&t)
	}
	if t.IsZero() {
		return z.SetZero()
	}
	if !((t[10] == 21813052973) && (t[9] == 16431850113554908022) && (t[8] == 15052145014553235051) && (t[7] == 8249970787276725507) && (t[6] == 6728674352238750255) && (t[5] == 14701590944609981104) && (t[4] == 9040225342748635458) && (t[3] == 6412496358938960977) && (t[2] == 18337981507651457660) && (t[1] == 4800134143431380907) && (t[0] == 1524065517792215338)) {
		// t != 1, we don't have a square root
		return nil
	}
	for {
		var m uint64
		t = b

		// for t != 1
		for !((t[10] == 21813052973) && (t[9] == 16431850113554908022) && (t[8] == 15052145014553235051) && (t[7] == 8249970787276725507) && (t[6] == 6728674352238750255) && (t[5] == 14701590944609981104) && (t[4] == 9040225342748635458) && (t[3] == 6412496358938960977) && (t[2] == 18337981507651457660) && (t[1] == 4800134143431380907) && (t[0] == 1524065517792215338)) {
			t.Square(&t)
			m++
		}

		if m == 0 {
			return z.Set(&y)
		}
		// t = g^(2^(r-m-1)) mod q
		ge := int(r - m - 1)
		t = g
		for ge > 0 {
			t.Square(&t)
			ge--
		}

		g.Square(&t)
		y.Mul(&y, &t)
		b.Mul(&b, &g)
		r = m
	}
}

// Inverse z = x^-1 mod q
// Algorithm 16 in "Efficient Software-Implementation of Finite Fields with Applications to Cryptography"
// if x == 0, sets and returns z = x
func (z *e_nocarry_0678) InverseOld(x *e_nocarry_0678) *e_nocarry_0678 {
	if x.IsZero() {
		z.SetZero()
		return z
	}

	// initialize u = q
	var u = e_nocarry_0678{
		13700220646824224385,
		17887507975354087702,
		6486305308265069006,
		7792857504656332695,
		4055812195804746746,
		13375536045193962793,
		15181741591537266872,
		16189485693405468817,
		4219463025600115067,
		18419519222788691264,
		232036787125,
	}

	// initialize s = r^2
	var s = e_nocarry_0678{
		273606947743973706,
		3464412692890843633,
		8435940272544525640,
		5308656646191584475,
		17330634774425083023,
		9222672958909094740,
		16418759808934922843,
		9149088793907112252,
		2768222490739974539,
		8007561342473828858,
		217755447783,
	}

	// r = 0
	r := e_nocarry_0678{}

	v := *x

	var carry, borrow uint64
	var bigger bool

	for {
		for v[0]&1 == 0 {

			// v = v >> 1

			v[0] = v[0]>>1 | v[1]<<63
			v[1] = v[1]>>1 | v[2]<<63
			v[2] = v[2]>>1 | v[3]<<63
			v[3] = v[3]>>1 | v[4]<<63
			v[4] = v[4]>>1 | v[5]<<63
			v[5] = v[5]>>1 | v[6]<<63
			v[6] = v[6]>>1 | v[7]<<63
			v[7] = v[7]>>1 | v[8]<<63
			v[8] = v[8]>>1 | v[9]<<63
			v[9] = v[9]>>1 | v[10]<<63
			v[10] >>= 1

			if s[0]&1 == 1 {

				// s = s + q
				s[0], carry = bits.Add64(s[0], 13700220646824224385, 0)
				s[1], carry = bits.Add64(s[1], 17887507975354087702, carry)
				s[2], carry = bits.Add64(s[2], 6486305308265069006, carry)
				s[3], carry = bits.Add64(s[3], 7792857504656332695, carry)
				s[4], carry = bits.Add64(s[4], 4055812195804746746, carry)
				s[5], carry = bits.Add64(s[5], 13375536045193962793, carry)
				s[6], carry = bits.Add64(s[6], 15181741591537266872, carry)
				s[7], carry = bits.Add64(s[7], 16189485693405468817, carry)
				s[8], carry = bits.Add64(s[8], 4219463025600115067, carry)
				s[9], carry = bits.Add64(s[9], 18419519222788691264, carry)
				s[10], _ = bits.Add64(s[10], 232036787125, carry)

			}

			// s = s >> 1

			s[0] = s[0]>>1 | s[1]<<63
			s[1] = s[1]>>1 | s[2]<<63
			s[2] = s[2]>>1 | s[3]<<63
			s[3] = s[3]>>1 | s[4]<<63
			s[4] = s[4]>>1 | s[5]<<63
			s[5] = s[5]>>1 | s[6]<<63
			s[6] = s[6]>>1 | s[7]<<63
			s[7] = s[7]>>1 | s[8]<<63
			s[8] = s[8]>>1 | s[9]<<63
			s[9] = s[9]>>1 | s[10]<<63
			s[10] >>= 1

		}
		for u[0]&1 == 0 {

			// u = u >> 1

			u[0] = u[0]>>1 | u[1]<<63
			u[1] = u[1]>>1 | u[2]<<63
			u[2] = u[2]>>1 | u[3]<<63
			u[3] = u[3]>>1 | u[4]<<63
			u[4] = u[4]>>1 | u[5]<<63
			u[5] = u[5]>>1 | u[6]<<63
			u[6] = u[6]>>1 | u[7]<<63
			u[7] = u[7]>>1 | u[8]<<63
			u[8] = u[8]>>1 | u[9]<<63
			u[9] = u[9]>>1 | u[10]<<63
			u[10] >>= 1

			if r[0]&1 == 1 {

				// r = r + q
				r[0], carry = bits.Add64(r[0], 13700220646824224385, 0)
				r[1], carry = bits.Add64(r[1], 17887507975354087702, carry)
				r[2], carry = bits.Add64(r[2], 6486305308265069006, carry)
				r[3], carry = bits.Add64(r[3], 7792857504656332695, carry)
				r[4], carry = bits.Add64(r[4], 4055812195804746746, carry)
				r[5], carry = bits.Add64(r[5], 13375536045193962793, carry)
				r[6], carry = bits.Add64(r[6], 15181741591537266872, carry)
				r[7], carry = bits.Add64(r[7], 16189485693405468817, carry)
				r[8], carry = bits.Add64(r[8], 4219463025600115067, carry)
				r[9], carry = bits.Add64(r[9], 18419519222788691264, carry)
				r[10], _ = bits.Add64(r[10], 232036787125, carry)

			}

			// r = r >> 1

			r[0] = r[0]>>1 | r[1]<<63
			r[1] = r[1]>>1 | r[2]<<63
			r[2] = r[2]>>1 | r[3]<<63
			r[3] = r[3]>>1 | r[4]<<63
			r[4] = r[4]>>1 | r[5]<<63
			r[5] = r[5]>>1 | r[6]<<63
			r[6] = r[6]>>1 | r[7]<<63
			r[7] = r[7]>>1 | r[8]<<63
			r[8] = r[8]>>1 | r[9]<<63
			r[9] = r[9]>>1 | r[10]<<63
			r[10] >>= 1

		}

		// v >= u
		bigger = !(v[10] < u[10] || (v[10] == u[10] && (v[9] < u[9] || (v[9] == u[9] && (v[8] < u[8] || (v[8] == u[8] && (v[7] < u[7] || (v[7] == u[7] && (v[6] < u[6] || (v[6] == u[6] && (v[5] < u[5] || (v[5] == u[5] && (v[4] < u[4] || (v[4] == u[4] && (v[3] < u[3] || (v[3] == u[3] && (v[2] < u[2] || (v[2] == u[2] && (v[1] < u[1] || (v[1] == u[1] && (v[0] < u[0])))))))))))))))))))))

		if bigger {

			// v = v - u
			v[0], borrow = bits.Sub64(v[0], u[0], 0)
			v[1], borrow = bits.Sub64(v[1], u[1], borrow)
			v[2], borrow = bits.Sub64(v[2], u[2], borrow)
			v[3], borrow = bits.Sub64(v[3], u[3], borrow)
			v[4], borrow = bits.Sub64(v[4], u[4], borrow)
			v[5], borrow = bits.Sub64(v[5], u[5], borrow)
			v[6], borrow = bits.Sub64(v[6], u[6], borrow)
			v[7], borrow = bits.Sub64(v[7], u[7], borrow)
			v[8], borrow = bits.Sub64(v[8], u[8], borrow)
			v[9], borrow = bits.Sub64(v[9], u[9], borrow)
			v[10], _ = bits.Sub64(v[10], u[10], borrow)

			// s = s - r
			s[0], borrow = bits.Sub64(s[0], r[0], 0)
			s[1], borrow = bits.Sub64(s[1], r[1], borrow)
			s[2], borrow = bits.Sub64(s[2], r[2], borrow)
			s[3], borrow = bits.Sub64(s[3], r[3], borrow)
			s[4], borrow = bits.Sub64(s[4], r[4], borrow)
			s[5], borrow = bits.Sub64(s[5], r[5], borrow)
			s[6], borrow = bits.Sub64(s[6], r[6], borrow)
			s[7], borrow = bits.Sub64(s[7], r[7], borrow)
			s[8], borrow = bits.Sub64(s[8], r[8], borrow)
			s[9], borrow = bits.Sub64(s[9], r[9], borrow)
			s[10], borrow = bits.Sub64(s[10], r[10], borrow)

			if borrow == 1 {

				// s = s + q
				s[0], carry = bits.Add64(s[0], 13700220646824224385, 0)
				s[1], carry = bits.Add64(s[1], 17887507975354087702, carry)
				s[2], carry = bits.Add64(s[2], 6486305308265069006, carry)
				s[3], carry = bits.Add64(s[3], 7792857504656332695, carry)
				s[4], carry = bits.Add64(s[4], 4055812195804746746, carry)
				s[5], carry = bits.Add64(s[5], 13375536045193962793, carry)
				s[6], carry = bits.Add64(s[6], 15181741591537266872, carry)
				s[7], carry = bits.Add64(s[7], 16189485693405468817, carry)
				s[8], carry = bits.Add64(s[8], 4219463025600115067, carry)
				s[9], carry = bits.Add64(s[9], 18419519222788691264, carry)
				s[10], _ = bits.Add64(s[10], 232036787125, carry)

			}
		} else {

			// u = u - v
			u[0], borrow = bits.Sub64(u[0], v[0], 0)
			u[1], borrow = bits.Sub64(u[1], v[1], borrow)
			u[2], borrow = bits.Sub64(u[2], v[2], borrow)
			u[3], borrow = bits.Sub64(u[3], v[3], borrow)
			u[4], borrow = bits.Sub64(u[4], v[4], borrow)
			u[5], borrow = bits.Sub64(u[5], v[5], borrow)
			u[6], borrow = bits.Sub64(u[6], v[6], borrow)
			u[7], borrow = bits.Sub64(u[7], v[7], borrow)
			u[8], borrow = bits.Sub64(u[8], v[8], borrow)
			u[9], borrow = bits.Sub64(u[9], v[9], borrow)
			u[10], _ = bits.Sub64(u[10], v[10], borrow)

			// r = r - s
			r[0], borrow = bits.Sub64(r[0], s[0], 0)
			r[1], borrow = bits.Sub64(r[1], s[1], borrow)
			r[2], borrow = bits.Sub64(r[2], s[2], borrow)
			r[3], borrow = bits.Sub64(r[3], s[3], borrow)
			r[4], borrow = bits.Sub64(r[4], s[4], borrow)
			r[5], borrow = bits.Sub64(r[5], s[5], borrow)
			r[6], borrow = bits.Sub64(r[6], s[6], borrow)
			r[7], borrow = bits.Sub64(r[7], s[7], borrow)
			r[8], borrow = bits.Sub64(r[8], s[8], borrow)
			r[9], borrow = bits.Sub64(r[9], s[9], borrow)
			r[10], borrow = bits.Sub64(r[10], s[10], borrow)

			if borrow == 1 {

				// r = r + q
				r[0], carry = bits.Add64(r[0], 13700220646824224385, 0)
				r[1], carry = bits.Add64(r[1], 17887507975354087702, carry)
				r[2], carry = bits.Add64(r[2], 6486305308265069006, carry)
				r[3], carry = bits.Add64(r[3], 7792857504656332695, carry)
				r[4], carry = bits.Add64(r[4], 4055812195804746746, carry)
				r[5], carry = bits.Add64(r[5], 13375536045193962793, carry)
				r[6], carry = bits.Add64(r[6], 15181741591537266872, carry)
				r[7], carry = bits.Add64(r[7], 16189485693405468817, carry)
				r[8], carry = bits.Add64(r[8], 4219463025600115067, carry)
				r[9], carry = bits.Add64(r[9], 18419519222788691264, carry)
				r[10], _ = bits.Add64(r[10], 232036787125, carry)

			}
		}
		if (u[0] == 1) && (u[10]|u[9]|u[8]|u[7]|u[6]|u[5]|u[4]|u[3]|u[2]|u[1]) == 0 {
			z.Set(&r)
			return z
		}
		if (v[0] == 1) && (v[10]|v[9]|v[8]|v[7]|v[6]|v[5]|v[4]|v[3]|v[2]|v[1]) == 0 {
			z.Set(&s)
			return z
		}
	}

}

func max(a int, b int) int {
	if a > b {
		return a
	}
	return b
}

func min(a int, b int) int {
	if a < b {
		return a
	}
	return b
}

//Though we're defining k as a constant, this code "profoundly" assumes that the processor is 64 bit
const k = 32 // word size / 2
const signBitSelector = uint64(1) << 63
const approxLowBitsN = k - 1
const approxHighBitsN = k + 1

func approximate(x *e_nocarry_0678, n int) uint64 {

	if n <= 64 {
		return x[0]
	}

	const mask = (uint64(1) << (k - 1)) - 1 //k-1 ones
	lo := mask & x[0]

	hiWordIndex := (n - 1) / 64

	hiWordBitsAvailable := n - hiWordIndex*64
	hiWordBitsUsed := min(hiWordBitsAvailable, approxHighBitsN)

	mask_ := uint64(^((1 << (hiWordBitsAvailable - hiWordBitsUsed)) - 1))
	hi := (x[hiWordIndex] & mask_) << (64 - hiWordBitsAvailable)

	mask_ = ^(1<<(approxLowBitsN+hiWordBitsUsed) - 1)
	mid := (mask_ & x[hiWordIndex-1]) >> hiWordBitsUsed

	return lo | mid | hi
}

var inversionCorrectionFactor = e_nocarry_0678{
	7509468171905997000,
	17491972753664105529,
	14015555414725112608,
	14998197699851863260,
	2012517175989971816,
	14121676446286688605,
	13200009746707251625,
	17439129108675505349,
	15119993089879245411,
	15510422178801644501,
	105890066267,
}

func (z *e_nocarry_0678) Inverse(x *e_nocarry_0678) *e_nocarry_0678 {
	if x.IsZero() {
		z.SetZero()
		return z
	}

	var a = *x
	var b = qe_nocarry_0678
	var u = e_nocarry_0678{1}

	//Update factors: we get [u; v]:= [f0 g0; f1 g1] [u; v]
	var f0, g0, f1, g1 int64

	//Saved update factors to reduce the number of field multiplications
	var pf0, pg0, pf1, pg1 int64

	var i uint

	var v, s e_nocarry_0678

	const iterationN = 2 * ((2*Bits-2)/(2*k) + 1) // 2   (2 * field size - 1) / 2k 

	//Since u,v are updated every other iteration, we must make sure we terminate after evenly many iterations
	//This also lets us get away with half as many updates to u,v
	//To make this constant-time-ish, replace the condition with i < iterationN
	for i = 0; i&1 == 1 || !a.IsZero(); i++ {
		n := max(a.BitLen(), b.BitLen())
		aApprox, bApprox := approximate(&a, n), approximate(&b, n)

		// After 0 iterations, we have f  2 and f < 2
		f0, g0, f1, g1 = 1, 0, 0, 1

		for j := 0; j < approxLowBitsN; j++ {

			if aApprox&1 == 0 {
				aApprox /= 2
			} else {
				s, borrow := bits.Sub64(aApprox, bApprox, 0)
				if borrow == 1 {
					s = bApprox - aApprox
					bApprox = aApprox
					f0, f1 = f1, f0
					g0, g1 = g1, g0
				}

				aApprox = s / 2
				f0 -= f1
				g0 -= g1

				//Now |f| < 2 + 2 = 2
				//|f|  2 still
			}

			f1 *= 2
			g1 *= 2
			//|f|  2
		}

		s = a
		aHi := a.linearCombNonModular(&s, f0, &b, g0)
		if aHi&signBitSelector != 0 {
			// if aHi < 0
			f0, g0 = -f0, -g0
			aHi = a.neg(&a, aHi)
		}
		//right-shift a by k-1 bits
		a[0] = (a[0] >> approxLowBitsN) | ((a[1]) << approxHighBitsN)
		a[1] = (a[1] >> approxLowBitsN) | ((a[2]) << approxHighBitsN)
		a[2] = (a[2] >> approxLowBitsN) | ((a[3]) << approxHighBitsN)
		a[3] = (a[3] >> approxLowBitsN) | ((a[4]) << approxHighBitsN)
		a[4] = (a[4] >> approxLowBitsN) | ((a[5]) << approxHighBitsN)
		a[5] = (a[5] >> approxLowBitsN) | ((a[6]) << approxHighBitsN)
		a[6] = (a[6] >> approxLowBitsN) | ((a[7]) << approxHighBitsN)
		a[7] = (a[7] >> approxLowBitsN) | ((a[8]) << approxHighBitsN)
		a[8] = (a[8] >> approxLowBitsN) | ((a[9]) << approxHighBitsN)
		a[9] = (a[9] >> approxLowBitsN) | ((a[10]) << approxHighBitsN)
		a[10] = (a[10] >> approxLowBitsN) | (aHi << approxHighBitsN)

		bHi := b.linearCombNonModular(&s, f1, &b, g1)
		if bHi&signBitSelector != 0 {
			// if bHi < 0
			f1, g1 = -f1, -g1
			bHi = b.neg(&b, bHi)
		}
		//right-shift b by k-1 bits
		b[0] = (b[0] >> approxLowBitsN) | ((b[1]) << approxHighBitsN)
		b[1] = (b[1] >> approxLowBitsN) | ((b[2]) << approxHighBitsN)
		b[2] = (b[2] >> approxLowBitsN) | ((b[3]) << approxHighBitsN)
		b[3] = (b[3] >> approxLowBitsN) | ((b[4]) << approxHighBitsN)
		b[4] = (b[4] >> approxLowBitsN) | ((b[5]) << approxHighBitsN)
		b[5] = (b[5] >> approxLowBitsN) | ((b[6]) << approxHighBitsN)
		b[6] = (b[6] >> approxLowBitsN) | ((b[7]) << approxHighBitsN)
		b[7] = (b[7] >> approxLowBitsN) | ((b[8]) << approxHighBitsN)
		b[8] = (b[8] >> approxLowBitsN) | ((b[9]) << approxHighBitsN)
		b[9] = (b[9] >> approxLowBitsN) | ((b[10]) << approxHighBitsN)
		b[10] = (b[10] >> approxLowBitsN) | (bHi << approxHighBitsN)

		if i&1 == 1 {
			//Combine current update factors with previously stored ones
			// [f, g; f, g]  [f, g; f, g] [pf, pg; pf, pg]
			// We have |f|, |g|, |pf|, |pf|  2, and that |pf_i| < 2 for i  {0, 1}
			// Then for the new value we get |f| < 2  2 + 2  2 = 2
			// Which leaves us with an extra bit for the sign
			f0, g0, f1, g1 = f0*pf0+g0*pf1,
				f0*pg0+g0*pg1,
				f1*pf0+g1*pf1,
				f1*pg0+g1*pg1

			s = u
			u.linearCombSosSigned(&u, f0, &v, g0)
			v.linearCombSosSigned(&s, f1, &v, g1)

		} else {
			//Save update factors
			pf0, pg0, pf1, pg1 = f0, g0, f1, g1
		}
	}

	if i > iterationN {
		panic("more iterations than expected")
	}

	//For every iteration that we miss, v is not being multiplied by 2
	const pSq int64 = 1 << (2 * (k - 1))
	//If the function is constant-time ish, this loop will not run (probably no need to take it out explicitly)
	for ; i < iterationN; i += 2 {
		v.mulWSigned(&v, pSq)
	}

	z.Mul(&v, &inversionCorrectionFactor)
	return z
}

func (z *e_nocarry_0678) linearCombSosSigned(x *e_nocarry_0678, xC int64, y *e_nocarry_0678, yC int64) {
	hi := z.linearCombNonModular(x, xC, y, yC)
	z.montReduceSigned(z, hi)
}

//montReduceSigned SOS algorithm; xHi must be at most 63 bits long. Last bit of xHi may be used as a sign bit
func (z *e_nocarry_0678) montReduceSigned(x *e_nocarry_0678, xHi uint64) {

	const qInvNegLsw uint64 = 15045236321440491135
	const signBitRemover = ^signBitSelector
	neg := xHi&signBitSelector != 0
	//the SOS implementation requires that most significant bit is 0
	// Let X be xHi*r + x
	// note that if X is negative we would have initially stored it as 2 r + X
	xHi &= signBitRemover
	// with this a negative X is now represented as 2 r + X

	var t [2*Limbs - 1]uint64
	var C uint64

	m := x[0] * qInvNegLsw

	C = madd0(m, qe_nocarry_0678[0], x[0])
	C, t[1] = madd2(m, qe_nocarry_0678[1], x[1], C)
	C, t[2] = madd2(m, qe_nocarry_0678[2], x[2], C)
	C, t[3] = madd2(m, qe_nocarry_0678[3], x[3], C)
	C, t[4] = madd2(m, qe_nocarry_0678[4], x[4], C)
	C, t[5] = madd2(m, qe_nocarry_0678[5], x[5], C)
	C, t[6] = madd2(m, qe_nocarry_0678[6], x[6], C)
	C, t[7] = madd2(m, qe_nocarry_0678[7], x[7], C)
	C, t[8] = madd2(m, qe_nocarry_0678[8], x[8], C)
	C, t[9] = madd2(m, qe_nocarry_0678[9], x[9], C)
	C, t[10] = madd2(m, qe_nocarry_0678[10], x[10], C)

	// the high word of m * qe_nocarry_0678[10] is at most 62 bits
	// x[10] + C is at most 65 bits (high word at most 1 bit)
	// Thus the resulting C will be at most 63 bits
	t[11] = xHi + C
	// xHi and C are 63 bits, therefore no overflow

	{
		const i = 1
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 2
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 3
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 4
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 5
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 6
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 7
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 8
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 9
		m = t[i] * qInvNegLsw

		//TODO: Is it better to hard-code the values of qe_nocarry_0678 as the "reduce" template does?
		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, t[i+1] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, t[i+2] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, t[i+3] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, t[i+4] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, t[i+5] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, t[i+6] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, t[i+7] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, t[i+8] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, t[i+9] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		C, t[i+10] = madd2(m, qe_nocarry_0678[10], t[i+10], C)

		t[i+Limbs] += C
	}
	{
		const i = 10
		m := t[i] * qInvNegLsw

		C = madd0(m, qe_nocarry_0678[0], t[i+0])
		C, z[0] = madd2(m, qe_nocarry_0678[1], t[i+1], C)
		C, z[1] = madd2(m, qe_nocarry_0678[2], t[i+2], C)
		C, z[2] = madd2(m, qe_nocarry_0678[3], t[i+3], C)
		C, z[3] = madd2(m, qe_nocarry_0678[4], t[i+4], C)
		C, z[4] = madd2(m, qe_nocarry_0678[5], t[i+5], C)
		C, z[5] = madd2(m, qe_nocarry_0678[6], t[i+6], C)
		C, z[6] = madd2(m, qe_nocarry_0678[7], t[i+7], C)
		C, z[7] = madd2(m, qe_nocarry_0678[8], t[i+8], C)
		C, z[8] = madd2(m, qe_nocarry_0678[9], t[i+9], C)
		z[10], z[9] = madd2(m, qe_nocarry_0678[10], t[i+10], C)
	}

	// if z > q --> z -= q
	// note: this is NOT constant time
	if !(z[10] < 232036787125 || (z[10] == 232036787125 && (z[9] < 18419519222788691264 || (z[9] == 18419519222788691264 && (z[8] < 4219463025600115067 || (z[8] == 4219463025600115067 && (z[7] < 16189485693405468817 || (z[7] == 16189485693405468817 && (z[6] < 15181741591537266872 || (z[6] == 15181741591537266872 && (z[5] < 13375536045193962793 || (z[5] == 13375536045193962793 && (z[4] < 4055812195804746746 || (z[4] == 4055812195804746746 && (z[3] < 7792857504656332695 || (z[3] == 7792857504656332695 && (z[2] < 6486305308265069006 || (z[2] == 6486305308265069006 && (z[1] < 17887507975354087702 || (z[1] == 17887507975354087702 && (z[0] < 13700220646824224385))))))))))))))))))))) {
		var b uint64
		z[0], b = bits.Sub64(z[0], 13700220646824224385, 0)
		z[1], b = bits.Sub64(z[1], 17887507975354087702, b)
		z[2], b = bits.Sub64(z[2], 6486305308265069006, b)
		z[3], b = bits.Sub64(z[3], 7792857504656332695, b)
		z[4], b = bits.Sub64(z[4], 4055812195804746746, b)
		z[5], b = bits.Sub64(z[5], 13375536045193962793, b)
		z[6], b = bits.Sub64(z[6], 15181741591537266872, b)
		z[7], b = bits.Sub64(z[7], 16189485693405468817, b)
		z[8], b = bits.Sub64(z[8], 4219463025600115067, b)
		z[9], b = bits.Sub64(z[9], 18419519222788691264, b)
		z[10], _ = bits.Sub64(z[10], 232036787125, b)
	}
	if neg {
		//We have computed ( 2 r + X ) r = 2 + X r instead
		var b uint64
		z[0], b = bits.Sub64(z[0], signBitSelector, 0)
		z[1], b = bits.Sub64(z[1], 0, b)
		z[2], b = bits.Sub64(z[2], 0, b)
		z[3], b = bits.Sub64(z[3], 0, b)
		z[4], b = bits.Sub64(z[4], 0, b)
		z[5], b = bits.Sub64(z[5], 0, b)
		z[6], b = bits.Sub64(z[6], 0, b)
		z[7], b = bits.Sub64(z[7], 0, b)
		z[8], b = bits.Sub64(z[8], 0, b)
		z[9], b = bits.Sub64(z[9], 0, b)
		z[10], b = bits.Sub64(z[10], 0, b)

		//Occurs iff x == 0 && xHi < 0, i.e. X = rX' for -2  X' < 0
		if b != 0 {
			// z[10] = -1
			//negative: add q
			const neg1 = 0xFFFFFFFFFFFFFFFF

			b = 0
			z[0], b = bits.Add64(z[0], 13700220646824224385, b)
			z[1], b = bits.Add64(z[1], 17887507975354087702, b)
			z[2], b = bits.Add64(z[2], 6486305308265069006, b)
			z[3], b = bits.Add64(z[3], 7792857504656332695, b)
			z[4], b = bits.Add64(z[4], 4055812195804746746, b)
			z[5], b = bits.Add64(z[5], 13375536045193962793, b)
			z[6], b = bits.Add64(z[6], 15181741591537266872, b)
			z[7], b = bits.Add64(z[7], 16189485693405468817, b)
			z[8], b = bits.Add64(z[8], 4219463025600115067, b)
			z[9], b = bits.Add64(z[9], 18419519222788691264, b)
			z[10], _ = bits.Add64(neg1, 232036787125, b)
		}
	}
}

// mulWSigned mul word signed (w/ montgomery reduction)
func (z *e_nocarry_0678) mulWSigned(x *e_nocarry_0678, y int64) {
	m := y >> 63
	_mulWGeneric(z, x, uint64((y^m)-m))
	//multiply by abs(y)
	if y < 0 {
		z.Neg(z)
	}
}

// regular multiplication by one word regular (non montgomery)
// Fewer additions than the branch-free for positive y. Could be faster on some architectures
func (z *e_nocarry_0678) mulWRegularBr(x *e_nocarry_0678, y int64) uint64 {

	// w := abs(y)
	m := y >> 63
	w := uint64((y ^ m) - m)

	var c uint64
	c, z[0] = bits.Mul64(x[0], w)
	c, z[1] = madd1(x[1], w, c)
	c, z[2] = madd1(x[2], w, c)
	c, z[3] = madd1(x[3], w, c)
	c, z[4] = madd1(x[4], w, c)
	c, z[5] = madd1(x[5], w, c)
	c, z[6] = madd1(x[6], w, c)
	c, z[7] = madd1(x[7], w, c)
	c, z[8] = madd1(x[8], w, c)
	c, z[9] = madd1(x[9], w, c)
	c, z[10] = madd1(x[10], w, c)

	if y < 0 {
		c = z.neg(z, c)
	}

	return c
}

func (z *e_nocarry_0678) neg(x *e_nocarry_0678, xHi uint64) uint64 {
	b := uint64(0)

	z[0], b = bits.Sub64(0, x[0], 0)
	z[1], b = bits.Sub64(0, x[1], b)
	z[2], b = bits.Sub64(0, x[2], b)
	z[3], b = bits.Sub64(0, x[3], b)
	z[4], b = bits.Sub64(0, x[4], b)
	z[5], b = bits.Sub64(0, x[5], b)
	z[6], b = bits.Sub64(0, x[6], b)
	z[7], b = bits.Sub64(0, x[7], b)
	z[8], b = bits.Sub64(0, x[8], b)
	z[9], b = bits.Sub64(0, x[9], b)
	z[10], b = bits.Sub64(0, x[10], b)
	xHi, _ = bits.Sub64(0, xHi, b)

	return xHi
}

// mulWRegular branch-free regular multiplication by one word (non montgomery)
func (z *e_nocarry_0678) mulWRegular(x *e_nocarry_0678, y int64) uint64 {

	w := uint64(y)
	allNeg := uint64(y >> 63) // -1 if y < 0, 0 o.w

	//s[0], s[1] so results are not stored immediately in z.
	//x[i] will be needed in the i+1 th iteration. We don't want to overwrite it in case x = z
	var s [2]uint64
	var h [2]uint64

	h[0], s[0] = bits.Mul64(x[0], w)

	c := uint64(0)
	b := uint64(0)

	{
		const curI = 1 % 2
		const prevI = 1 - curI
		const iMinusOne = 1 - 1

		h[curI], s[curI] = bits.Mul64(x[1], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 2 % 2
		const prevI = 1 - curI
		const iMinusOne = 2 - 1

		h[curI], s[curI] = bits.Mul64(x[2], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 3 % 2
		const prevI = 1 - curI
		const iMinusOne = 3 - 1

		h[curI], s[curI] = bits.Mul64(x[3], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 4 % 2
		const prevI = 1 - curI
		const iMinusOne = 4 - 1

		h[curI], s[curI] = bits.Mul64(x[4], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 5 % 2
		const prevI = 1 - curI
		const iMinusOne = 5 - 1

		h[curI], s[curI] = bits.Mul64(x[5], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 6 % 2
		const prevI = 1 - curI
		const iMinusOne = 6 - 1

		h[curI], s[curI] = bits.Mul64(x[6], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 7 % 2
		const prevI = 1 - curI
		const iMinusOne = 7 - 1

		h[curI], s[curI] = bits.Mul64(x[7], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 8 % 2
		const prevI = 1 - curI
		const iMinusOne = 8 - 1

		h[curI], s[curI] = bits.Mul64(x[8], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 9 % 2
		const prevI = 1 - curI
		const iMinusOne = 9 - 1

		h[curI], s[curI] = bits.Mul64(x[9], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}

	{
		const curI = 10 % 2
		const prevI = 1 - curI
		const iMinusOne = 10 - 1

		h[curI], s[curI] = bits.Mul64(x[10], w)
		s[curI], c = bits.Add64(s[curI], h[prevI], c)
		s[curI], b = bits.Sub64(s[curI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]
	}
	{
		const curI = 11 % 2
		const prevI = 1 - curI
		const iMinusOne = 10

		s[curI], _ = bits.Sub64(h[prevI], allNeg&x[iMinusOne], b)
		z[iMinusOne] = s[prevI]

		return s[curI] + c
	}
}

//Requires NoCarry
func (z *e_nocarry_0678) linearCombNonModular(x *e_nocarry_0678, xC int64, y *e_nocarry_0678, yC int64) uint64 {
	var yTimes e_nocarry_0678

	yHi := yTimes.mulWRegular(y, yC)
	xHi := z.mulWRegular(x, xC)

	carry := uint64(0)
	z[0], carry = bits.Add64(z[0], yTimes[0], carry)
	z[1], carry = bits.Add64(z[1], yTimes[1], carry)
	z[2], carry = bits.Add64(z[2], yTimes[2], carry)
	z[3], carry = bits.Add64(z[3], yTimes[3], carry)
	z[4], carry = bits.Add64(z[4], yTimes[4], carry)
	z[5], carry = bits.Add64(z[5], yTimes[5], carry)
	z[6], carry = bits.Add64(z[6], yTimes[6], carry)
	z[7], carry = bits.Add64(z[7], yTimes[7], carry)
	z[8], carry = bits.Add64(z[8], yTimes[8], carry)
	z[9], carry = bits.Add64(z[9], yTimes[9], carry)
	z[10], carry = bits.Add64(z[10], yTimes[10], carry)

	yHi, _ = bits.Add64(xHi, yHi, carry)

	return yHi
}
