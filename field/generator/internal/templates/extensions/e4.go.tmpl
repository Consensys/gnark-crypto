import (
	"math/big"
	"math/bits"
	"unsafe"

	fr "{{ .FieldPackagePath }}"
	{{- if .IsKoalaBear}}
		"github.com/consensys/gnark-crypto/utils/cpu"
	{{- end}}
)

type Vector []E4

// E4 is a degree two finite field extension of fr2
type E4 struct {
	B0, B1 E2
}

// Equal returns true if z equals x, false otherwise
func (z *E4) Equal(x *E4) bool {
	return z.B0.Equal(&x.B0) && z.B1.Equal(&x.B1)
}

// Cmp compares (lexicographic order) z and x and returns:
//
//	-1 if z <  x
//	 0 if z == x
//	+1 if z >  x
func (z *E4) Cmp(x *E4) int {
	if a1 := z.B1.Cmp(&x.B1); a1 != 0 {
		return a1
	}
	return z.B0.Cmp(&x.B0)
}

// LexicographicallyLargest returns true if this element is strictly lexicographically
// larger than its negation, false otherwise
func (z *E4) LexicographicallyLargest() bool {
	// adapted from github.com/zkcrypto/bls12_381
	if z.B1.IsZero() {
		return z.B0.LexicographicallyLargest()
	}
	return z.B1.LexicographicallyLargest()
}

// String puts E4 in string form
func (z *E4) String() string {
	return (z.B0.String() + "+(" + z.B1.String() + ")*v")
}

// SetString sets a E4 from string
func (z *E4) SetString(s0, s1, s2, s3 string) *E4 {
	z.B0.SetString(s0, s1)
	z.B1.SetString(s2, s3)
	return z
}

// Set copies x into z and returns z
func (z *E4) Set(x *E4) *E4 {
	z.B0 = x.B0
	z.B1 = x.B1
	return z
}

// SetZero sets an E4 elmt to zero
func (z *E4) SetZero() *E4 {
	z.B0.SetZero()
	z.B1.SetZero()
	return z
}

// SetOne sets z to 1 in Montgomery form and returns z
func (z *E4) SetOne() *E4 {
	*z = E4{}
	z.B0.A0.SetOne()
	return z
}

// MulByElement multiplies an element in E4 by an element in fr
func (z *E4) MulByElement(x *E4, y *fr.Element) *E4 {
	z.B0.MulByElement(&x.B0, y)
	z.B1.MulByElement(&x.B1, y)
	return z
}

// MulByE2 multiplies an element in E4 by an element in E2
func (z *E4) MulByE2(x *E4, y *E2) *E4 {
	var yCopy E2
	yCopy.Set(y)
	z.B0.Mul(&x.B0, &yCopy)
	z.B1.Mul(&x.B1, &yCopy)
	return z
}

// Add sets z=x+y in E4 and returns z
func (z *E4) Add(x, y *E4) *E4 {
	z.B0.Add(&x.B0, &y.B0)
	z.B1.Add(&x.B1, &y.B1)
	return z
}

// Sub sets z to x-y and returns z
func (z *E4) Sub(x, y *E4) *E4 {
	z.B0.Sub(&x.B0, &y.B0)
	z.B1.Sub(&x.B1, &y.B1)
	return z
}

// Double sets z=2*x and returns z
func (z *E4) Double(x *E4) *E4 {
	z.B0.Double(&x.B0)
	z.B1.Double(&x.B1)
	return z
}

// Neg negates an E4 element
func (z *E4) Neg(x *E4) *E4 {
	z.B0.Neg(&x.B0)
	z.B1.Neg(&x.B1)
	return z
}

// SetRandom used only in tests
func (z *E4) SetRandom() (*E4, error) {
	if _, err := z.B0.SetRandom(); err != nil {
		return nil, err
	}
	if _, err := z.B1.SetRandom(); err != nil {
		return nil, err
	}
	return z, nil
}

// MustSetRandom sets the element to a random value.
// It panics if reading from crypto/rand fails.
func (z *E4) MustSetRandom() *E4 {
	if _, err := z.SetRandom(); err != nil {
		panic(err)
	}
	return z
}

// IsZero returns true if z is zero, false otherwise
func (z *E4) IsZero() bool {
	return z.B0.IsZero() && z.B1.IsZero()
}

// IsOne returns true if z is one, false otherwise
func (z *E4) IsOne() bool {
	return z.B0.IsOne() && z.B1.IsZero()
}

// MulByNonResidue mul x by (0,1)
func (z *E4) MulByNonResidue(x *E4) *E4 {
	z.B1, z.B0 = x.B0, x.B1
	z.B0.MulByNonResidue(&z.B0)
	return z
}

// Mul sets z=x*y in E4 and returns z
func (z *E4) Mul(x, y *E4) *E4 {
	var a, b, c, d E2
	a.Add(&x.B0, &x.B1)
	b.Add(&y.B0, &y.B1)
	d.Mul(&x.B0, &y.B0)
	c.Mul(&x.B1, &y.B1)
	a.Mul(&a, &b)
	var bc E2
	bc.Add(&d, &c)
	z.B1.Sub(&a, &bc)
	z.B0.MulByNonResidue(&c).Add(&z.B0, &d)
	return z
}

// Square sets z=x*x in E4 and returns z
func (z *E4) Square(x *E4) *E4 {
	// same as mul, but we remove duplicate add and simplify multiplications with squaring
	// note: this is more efficient than Algorithm 22 from https://eprint.iacr.org/2010/354.pdf
	var a, c, d E2
	a.Add(&x.B0, &x.B1)
	d.Square(&x.B0)
	c.Square(&x.B1)
	a.Square(&a)
	var bc E2
	bc.Add(&d, &c)
	z.B1.Sub(&a, &bc)
	z.B0.MulByNonResidue(&c).Add(&z.B0, &d)

	return z
}

// Inverse sets z to the inverse of x in E4 and returns z
//
// if x == 0, sets and returns z = x
func (z *E4) Inverse(x *E4) *E4 {
	// Algorithm 23 from https://eprint.iacr.org/2010/354.pdf

	var t0, t1, tmp E2
	t0.Square(&x.B0)
	t1.Square(&x.B1)
	tmp.MulByNonResidue(&t1)
	t0.Sub(&t0, &tmp)
	t1.Inverse(&t0)
	z.B0.Mul(&x.B0, &t1)
	z.B1.Mul(&x.B1, &t1).Neg(&z.B1)

	return z
}

// Exp sets z=xᵏ (mod q⁴) and returns it
func (z *E4) Exp(x E4, k *big.Int) *E4 {
	if k.IsInt64() {
		return z.ExpInt64(x, k.Int64())
	}

	e := k
	if k.Sign() == -1 {
		// negative k, we invert
		// if k < 0: xᵏ (mod q⁴) == (x⁻¹)ᵏ (mod q⁴)
		x.Inverse(&x)

		// we negate k in a temp big.Int since
		// Int.Bit(_) of k and -k is different
		e = bigIntPool.Get().(*big.Int)
		defer bigIntPool.Put(e)
		e.Neg(k)
	}

	z.SetOne()
	b := e.Bytes()
	for i := 0; i < len(b); i++ {
		w := b[i]
		for j := 0; j < 8; j++ {
			z.Square(z)
			if (w & (0b10000000 >> j)) != 0 {
				z.Mul(z, &x)
			}
		}
	}

	return z
}

// ExpInt64 sets z=xᵏ (mod q⁴) and returns it, where k is an int64
func (z *E4) ExpInt64(x E4, k int64) *E4 {
	if k == 0 {
		return z.SetOne()
	}

	exp := k
	if k < 0 {
		x.Inverse(&x)
		exp = -k // if k == math.MinInt64, -k overflows, but uint64(-k) is correct
	}

	z.Set(&x)

	// Use bits.Len64 to iterate only over significant bits
	for i := bits.Len64(uint64(exp)) - 2; i >= 0; i-- {
		z.Square(z)
		if (uint64(exp)>>uint(i))&1 != 0 {
			z.Mul(z, &x)
		}
	}

	return z
}


// Conjugate sets z to x conjugated and returns z
func (z *E4) Conjugate(x *E4) *E4 {
	z.B0 = x.B0
	z.B1.Neg(&x.B1)
	return z
}

func (z *E4) Halve() {

	z.B0.A0.Halve()
	z.B0.A1.Halve()
	z.B1.A0.Halve()
	z.B1.A1.Halve()
}

// norm sets x to the norm of z
func (z *E4) norm(x *E2) {
	var tmp E2
	tmp.Square(&z.B1).MulByNonResidue(&tmp)
	x.Square(&z.B0).Sub(x, &tmp)
}

// Legendre returns the Legendre symbol of z
func (z *E4) Legendre() int {
	var n E2
	z.norm(&n)
	return n.Legendre()
}

// Sqrt sets z to the square root of and returns z
// The function does not test whether the square root
// exists or not, it's up to the caller to call
// Legendre beforehand.
// cf https://eprint.iacr.org/2012/685.pdf (algo 10)
func (z *E4) Sqrt(x *E4) *E4 {

	// precomputation
	var b, c, d, e, f, x0, _g E4
	var _b, o E2

	// c must be a non square (p = 1 mod 4)
	c.B1.SetOne()

	q := fr.Modulus()
	var exp, one big.Int
	one.SetUint64(1)
	exp.Mul(q, q).Sub(&exp, &one).Rsh(&exp, 1)
	d.Exp(c, &exp)
	e.Mul(&d, &c).Inverse(&e)
	f.Mul(&d, &c).Square(&f)

	// computation
	exp.Rsh(&exp, 1)
	b.Exp(*x, &exp)
	b.norm(&_b)
	o.SetOne()
	if _b.Equal(&o) {
		x0.Square(&b).Mul(&x0, x)
		_b.Set(&x0.B0).Sqrt(&_b)
		_g.B0.Set(&_b)
		z.Conjugate(&b).Mul(z, &_g)
		return z
	}
	x0.Square(&b).Mul(&x0, x).Mul(&x0, &f)
	_b.Set(&x0.B0).Sqrt(&_b)
	_g.B0.Set(&_b)
	z.Conjugate(&b).Mul(z, &_g).Mul(z, &e)

	return z
}

// BatchInvertE4 returns a new slice with every element in a inverted.
// It uses Montgomery batch inversion trick.
//
// if a[i] == 0, returns result[i] = a[i]
func BatchInvertE4(a []E4) []E4 {
	res := make([]E4, len(a))
	if len(a) == 0 {
		return res
	}

	zeroes := make([]bool, len(a))
	var accumulator E4
	accumulator.SetOne()

	for i := 0; i < len(a); i++ {
		if a[i].IsZero() {
			zeroes[i] = true
			continue
		}
		res[i].Set(&accumulator)
		accumulator.Mul(&accumulator, &a[i])
	}

	accumulator.Inverse(&accumulator)

	for i := len(a) - 1; i >= 0; i-- {
		if zeroes[i] {
			continue
		}
		res[i].Mul(&res[i], &accumulator)
		accumulator.Mul(&accumulator, &a[i])
	}

	return res
}

// Div divides an element in E4 by an element in E4
func (z *E4) Div(x *E4, y *E4) *E4 {
	var r E4
	r.Inverse(y).Mul(x, &r)
	return z.Set(&r)
}

// Butterfly computes the butterfly operation on two E4 elements
func Butterfly(a, b *E4) {
	fr.Butterfly(&a.B0.A0, &b.B0.A0)
	fr.Butterfly(&a.B0.A1, &b.B0.A1)

	fr.Butterfly(&a.B1.A0, &b.B1.A0)
	fr.Butterfly(&a.B1.A1, &b.B1.A1)
}

// Vector operations

func (vector Vector) Add(a, b Vector) {
	N := len(a)
	if N != len(b) || N != len(vector) {
		panic("vector.Add: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			vectorAddGeneric(vector, a, b)
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorAdd_avx512(&vector[0], &a[0], &b[0], nr)
		if r != 0 {
			vectorAddGeneric(vector[N-r:], a[N-r:], b[N-r:])
		}
	{{- else}}
		vectorAddGeneric(vector, a, b)
	{{- end}}
}

func (vector Vector) Sub(a, b Vector) {
	N := len(a)
	if N != len(b) || N != len(vector) {
		panic("vector.Sub: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			vectorSubGeneric(vector, a, b)
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorSub_avx512(&vector[0], &a[0], &b[0], nr)
		if r != 0 {
			vectorSubGeneric(vector[N-r:], a[N-r:], b[N-r:])
		}
	{{- else}}
		vectorSubGeneric(vector, a, b)
	{{- end}}
}

func (vector Vector) Mul(a, b Vector) {
	N := len(a)
	if N != len(b) || N != len(vector) {
		panic("vector.Mul: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 16
		if !cpu.SupportAVX512 || N < blockSize {
			vectorMulGeneric(vector, a, b)
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorMul_avx512(&vector[0], &a[0], &b[0], nr)
		if r != 0 {
			vectorMulGeneric(vector[N-r:], a[N-r:], b[N-r:])
		}
	{{- else}}
		vectorMulGeneric(vector, a, b)
	{{- end}}
}

func (vector Vector) ScalarMul(a Vector, b *E4) {
	N := len(a)
	if N != len(vector) {
		panic("vector.ScalarMul: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 16
		if !cpu.SupportAVX512 || N < blockSize {
			vectorScalarMulGeneric(vector, a, b)
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorScalarMul_avx512(&vector[0], &a[0], b, nr)
		if r != 0 {
			vectorScalarMulGeneric(vector[N-r:], a[N-r:], b)
		}
	{{- else}}
		vectorScalarMulGeneric(vector, a, b)
	{{- end}}
}

// Sum computes the sum of all elements in the vector.
func (vector Vector) Sum() E4 {
	{{- if .IsKoalaBear}}
		const blockSize = 2
		N := len(vector)
		if !cpu.SupportAVX512 || N < blockSize {
			return vectorSumGeneric(vector)
		}

		r := N % blockSize
		nr := uint64(N - r)

		var res E4
		var t [4]uint64 // stores the accumulators (not reduced mod q)
		vectorSum_avx512(&t, &vector[0], uint64(nr))
		res.B0.A0[0] = uint32(t[0] % q)
		res.B0.A1[0] = uint32(t[1] % q)
		res.B1.A0[0] = uint32(t[2] % q)
		res.B1.A1[0] = uint32(t[3] % q)

		if r != 0 { // blockSize == 2; so we just add the last odd element
			res.Add(&res, &vector[len(vector)-1])
		}

		return res
	{{- else}}
		return vectorSumGeneric(vector)
	{{- end}}
}

func (vector Vector) InnerProductByElement(a fr.Vector) E4 {
	N := len(vector)
	if len(a) != N {
		panic("vector.InnerProduct: vectors don't have the same length")
	}

	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			return vectorInnerProductByElementGeneric(vector, a)
		}
		r := N % blockSize
		nr := uint64(N - r)
		var res E4
		vectorInnerProductByElement_avx512(&res, &vector[0], &a[0], nr)
		if r != 0 {
			partialResult := vectorInnerProductByElementGeneric(vector[N-r:], a[N-r:])
			res.Add(&res, &partialResult)
		}
		return res
	{{- else}}
		return vectorInnerProductByElementGeneric(vector, a)
	{{- end}}
}

func (vector Vector) InnerProduct(a Vector) E4 {
	N := len(vector)
	if len(a) != N {
		panic("vector.InnerProduct: vectors don't have the same length")
	}

	{{- if .IsKoalaBear}}
		const blockSize = 16
		if !cpu.SupportAVX512 || N < blockSize {
			return vectorInnerProductGeneric(vector, a)
		}
		var t[8*4]uint64 // accumulators
		r := N % blockSize
		nr := uint64(N - r)
		vectorInnerProduct_avx512(&t, &vector[0], &a[0], nr)

		// reduce accumulator
		for i := 1; i < 8; i++ {
			t[0] += (t[i] % q)
		}
		for i := 9; i < 16; i++ {
			t[8] += (t[i] % q)
		}
		for i := 17; i < 24; i++ {
			t[16] += (t[i] % q)
		}
		for i := 25; i < 32; i++ {
			t[24] += (t[i] % q)
		}

		var res E4
		res.B0.A0[0] = uint32(t[0] % q)
		res.B0.A1[0] = uint32(t[8] % q)
		res.B1.A0[0] = uint32(t[16] % q)
		res.B1.A1[0] = uint32(t[24] % q)

		if r != 0 {
			partialResult := vectorInnerProductGeneric(vector[N-r:], a[N-r:])
			res.Add(&res, &partialResult)
		}

		return res
	{{- else}}
		return vectorInnerProductGeneric(vector, a)
	{{- end}}
}

func (vector Vector) MulByElement(a Vector, b fr.Vector) {
	N := len(vector)
	if len(a) != N || len(b) != N {
		panic("vector.MulByElement: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			vectorMulByElementGeneric(vector, a, b)
			return
		}

		r := N % blockSize
		nr := uint64(N - r)

		vectorMulByElement_avx512(&vector[0], &a[0], &b[0], nr)
		if r != 0 {
			// call vectorMulByElementGeneric on the rest
			start := N - r
			vectorMulByElementGeneric(vector[start:], a[start:], b[start:])
		}

	{{- else}}
		vectorMulByElementGeneric(vector, a, b)
	{{- end}}
}

// Butterfly computes the in-place butterfly operation on two vectors of E4 elements
// If other overlaps with vector, result is undefined, caller should use a temp vector.
func (vector Vector) Butterfly(other Vector) {
	N := len(other)
	if N != len(vector) {
		panic("vector.Butterfly: vectors don't have the same length")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			vectorButterflyGeneric(vector, other)
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorButterfly_avx512(&vector[0], &other[0], nr)
		if r != 0 {
			vectorButterflyGeneric(vector[N-r:], other[N-r:])
		}
	{{- else}}
		vectorButterflyGeneric(vector, other)
	{{- end}}
}

// ButterflyPair computes the in-place butterfly operation of each pair in the vector
// vector[0], vector[1]; vector[2], vector[3]; ...
func (vector Vector) ButterflyPair() {
	N := len(vector)
	if N%2 != 0 {
		panic("vector.ButterflyPair: vector length must be even")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N < blockSize {
			for i := 0; i < N; i += 2 {
				Butterfly(&vector[i], &vector[i+1])
			}
			return
		}
		r := N % blockSize
		nr := uint64(N - r)
		vectorButterflyPair_avx512(&vector[0], nr)
		if r != 0 {
			for i := N - r; i < N; i += 2 {
				Butterfly(&vector[i], &vector[i+1])
			}
		}
	{{- else}}
		for i := 0; i < N; i += 2 {
			Butterfly(&vector[i], &vector[i+1])
		}
	{{- end}}
}

func (vector Vector) ScalarMulByElement(a Vector, b *fr.Element) {
	if len(a) != len(vector) {
		panic("vector.ScalarMulByElement: vectors don't have the same length")
	}
	if len(vector) == 0 {
		return
	}

	// for this one, since mul by element scales each coordinates, we cast a to a fr.Vector,
	// and call the already optimized fr.Vector.ScalarMul
	M := len(a) * 4
	vBase := fr.Vector(unsafe.Slice((*fr.Element)(unsafe.Pointer(&a[0])), M))
	vRes := fr.Vector(unsafe.Slice((*fr.Element)(unsafe.Pointer(&vector[0])), M))
	vRes.ScalarMul(vBase, b)
}

// Exp sets vector[i] = a[i]ᵏ for all i
func (vector Vector) Exp(a Vector, k int64) {
	N := len(a)
	if N != len(vector) {
		panic("vector.Exp: vectors don't have the same length")
	}
	if k == 0 {
		for i := range vector {
			vector[i].SetOne()
		}
		return
	}
	base := a
	exp := k
	if k < 0 {
		// call batch inverse
		base = BatchInvertE4(a)
		exp = -k // if k == math.MinInt64, -k overflows, but uint64(-k) is correct
	} else if N > 0 {
		// ensure that vector and a are not the same slice; else we need to copy a into base
		v0 := &vector[0] // #nosec G602 we check that N > 0 above
		a0 := &a[0] // #nosec G602 we check that N > 0 above
		if v0 == a0 {
			base = make(Vector, N)
			copy(base, a)
		}
	}

	copy(vector, base)

	// Use bits.Len64 to iterate only over significant bits
	for i := bits.Len64(uint64(exp)) - 2; i >= 0; i-- {
		vector.Mul(vector, vector)
		if (uint64(exp)>>uint(i))&1 != 0 {
			vector.Mul(vector, base)
		}
	}
}
 
// MulAccByElement multiplies each element of the vector v by the E4 element alpha,
// accumulating the result in the same vector.
func (vector Vector) MulAccByElement(scale []fr.Element, alpha *E4)  {
	N := len(vector)
	if N != len(scale) {
		panic("MulAccByElement: len(vector) != len(scale)")
	}
	{{- if .IsKoalaBear}}
		const blockSize = 4
		if !cpu.SupportAVX512 || N%blockSize != 0 {
			vectorMulAccByElementGeneric(vector, scale, alpha)
			return
		}
		mulAccByElement_avx512(alpha, &scale[0], &vector[0], uint64(N))
	{{- else}}
		vectorMulAccByElementGeneric(vector, scale, alpha)
	{{- end}}
}


func vectorAddGeneric(res, a, b Vector) {
	for i := 0; i < len(res); i++ {
		res[i].Add(&a[i], &b[i])
	}
}
func vectorSubGeneric(res, a, b Vector) {
	for i := 0; i < len(res); i++ {
		res[i].Sub(&a[i], &b[i])
	}
}
func vectorMulGeneric(res, a, b Vector) {
	for i := 0; i < len(res); i++ {
		res[i].Mul(&a[i], &b[i])
	}
}
func vectorScalarMulGeneric(res, a Vector, b *E4) {
	for i := 0; i < len(res); i++ {
		res[i].Mul(&a[i], b)
	}
}

func vectorInnerProductGeneric(a, b Vector) E4 {
	var res, tmp E4
	for i := 0; i < len(a); i++ {
		tmp.Mul(&a[i], &b[i])
		res.Add(&res, &tmp)
	}
	return res
}

func vectorSumGeneric(v Vector) E4 {
	var sum E4
	for i := 0; i < len(v); i++ {
		sum.Add(&sum, &v[i])
	}
	return sum
}

func vectorMulAccByElementGeneric(v Vector, scale []fr.Element, alpha *E4) {
	var tmp E4
	for i := 0; i < len(v); i++ {
		tmp.MulByElement(alpha, &scale[i])
		v[i].Add(&v[i], &tmp)
	}
}

func vectorInnerProductByElementGeneric(a Vector, b fr.Vector) E4 {
	var res, tmp E4
	for i := 0; i < len(a); i++ {
		tmp.MulByElement(&a[i], &b[i])
		res.Add(&res, &tmp)
	}
	return res
}

func vectorMulByElementGeneric(res, a Vector, b fr.Vector) {
	for i := 0; i < len(res); i++ {
		res[i].MulByElement(&a[i], &b[i])
	}
}

func vectorButterflyGeneric(a, b Vector) {
	for i := 0; i < len(a); i++ {
		Butterfly(&a[i], &b[i])
	}
}
